Besides being "one of the 7 meta-questions every site should ask", it's just plain important. An "AI Stackexchange" site has been tried before, at least once, and possibly a few times. And in the past, it's been killed for lack of activity.
So, how do we promote this site well enough to attract a critical mass of participants? And how do we get people to participate?
b2A1I9n14a1r18y25_g7l12o15b2e5How do we promote this site?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I guess the first step is to clearly define its scope.b2A1I9n14a1r18y25_g7l12o15b2e5[A Recipe to Promote your Site](http://blog.stackoverflow.com/2010/08/a-recipe-to-promote-your-site/)b2A1I9n14a1r18y25_g7l12o15b2e5Related: http://meta.ai.stackexchange.com/questions/22/can-we-send-messages-to-young-researchers-who-have-recently-published-papers-in


















I think this will be a crucial thing to figure out.  On the one hand, I think it's important to be as inclusive as possible, and avoid being overly pedantic and stay away from the extreme degree of elitism that infects many stackexchange sites.  BUT.. on the other hand, we want the site to be of interest to everyone from hobbyists to serious academic researchers.   

The one thing I think we need to be leery of, is having the site become overly oriented towards trans-humanism, Singularity, etc.  I think those things are on-topic, but I suspect it would be easy to drift into a place where we're more fringe-science / sci-fi than serious AI research.   Exactly how to strike that balance, I'm afraid I don't really know.  
b2A1I9n14a1r18y25_g7l12o15b2e5How broadly should we define "on topic"?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I'm going to close this as tenuously "too broad" for now. We may eventually need to enumerate some bullet points for the help center, but we've found over the the years that an early what's-on-topic discussion tends to be better served by focusing on very specific concerns you see in actual practice. In contrast, broad "list everything here" discussions tend to elicit a lot of premature *rule making* and often create a site that has more *prohibitions* than problems that turn up in actual practice.b2A1I9n14a1r18y25_g7l12o15b2e5Considering that this doesn't even have any answers yet, I'd say closing the question is the premature activity.  Communities are pretty good at figuring this stuff out, just let the system work.b2A1I9n14a1r18y25_g7l12o15b2e5mindcrime, I can understand the desire to figure out where all the fences go now, but is there a reason to reopen this despite the hard-earned lessons of the past? I'm not saying *don't have these conversations;* I'm just saying this particular all-in-one-thread approach tends to serve as *The* Definitive Signpost that says "anything you don't see here is off topic, period." That is simply my experience launching 157 of these things. Better to start out with a more-open mindset and tackle problems as they come up. Overall, we've found this creates a more-approachable community.b2A1I9n14a1r18y25_g7l12o15b2e5" I can understand the desire to figure out where all the fences go now"
But there's not.. a discussion like this is ongoing, and ideally will be ongoing for the life of the community.   But at this early phase you want to "rough in" the broad brush strokes. Nobody is raising a call to have some bullet-point checklist of the "13 criteria for an allowable post on ai.se"  :-)  But we also want to make sure that we that a question like "what's the best chemical for cleaning a brake caliper during a rebuild" are off-topic.  And yes, that's a little bit of hyperbole, just to make the point.b2A1I9n14a1r18y25_g7l12o15b2e5`...ideally will be ongoing for the life of the community.` Unfortunately too many meta posts don't work out that way. They have a limited window of malleability before they become a stick to beat new users over the head with. The Community Team used to huddle up trying to figure out how new sites can go wrong before they even launched — we even encouraged new sites to do the same — until we realized **we don't NEED these forced rules discussions.** Use the site. If something swerves off off your mental model of how this should work, have at it. But in the meantime, don't fret it. Enjoy.


















Are all questions asked on stats and data science SE also on topic here? Or is there some rule such as (on-topic in stats or data science SE implies off-topic here)?

Data science and the stats SE already have a huge overlap (>~80%), I am worried to have a third SE that also significantly overlaps with them.



As a side note, many other SE have an AI tags, e.g.:


https://philosophy.stackexchange.com/questions/tagged/artificial-intelligencehttps://philosophy.stackexchange.com/questions/tagged/artificial-intelligence
https://worldbuilding.stackexchange.com/questions/tagged/artificial-intelligencehttps://worldbuilding.stackexchange.com/questions/tagged/artificial-intelligence (for the most sci-fi questions)
https://cstheory.stackexchange.com/questions/tagged/ai.artificial-intelhttps://cstheory.stackexchange.com/questions/tagged/ai.artificial-intel
https://cs.stackexchange.com/questions/tagged/artificial-intelligencehttps://cs.stackexchange.com/questions/tagged/artificial-intelligence
https://cogsci.stackexchange.com/questions/tagged/artificial-intelligencehttps://cogsci.stackexchange.com/questions/tagged/artificial-intelligence
https://hsm.stackexchange.com/questions/tagged/artificial-intelligencehttps://hsm.stackexchange.com/questions/tagged/artificial-intelligence
https://stackoverflow.com/questions/tagged/artificial-intelligencehttps://stackoverflow.com/questions/tagged/artificial-intelligence
https://gamedev.stackexchange.com/questions/tagged/aihttps://gamedev.stackexchange.com/questions/tagged/ai

b2A1I9n14a1r18y25_g7l12o15b2e5Are all questions asked on stats and data science SE also on topic here?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5http://discuss.area51.stackexchange.com/questions/24014/will-machine-learning-be-considered-as-on-topicb2A1I9n14a1r18y25_g7l12o15b2e5It's a good question!  Given that so much of what's "hot" and "trendy" in the overall rubric of AI these days is probabilistic / machine learning approaches, I wonder how much is left that people are actively talking about, if we declare all of that stuff off-topic.  Obviously there *are* other things to talk about, but are there people out there looking to have those discussions exclusively?b2A1I9n14a1r18y25_g7l12o15b2e5Relatedly, what's the right action if a question is already asked in one of those sites? Link to the answer there in an answer here, mark as duplicate, write a new answer here?b2A1I9n14a1r18y25_g7l12o15b2e5Related: [Is asking about AI algorithm recommendation on-topic?](http://meta.ai.stackexchange.com/q/71/8)


















I think the answer is "yes".  To the user asking a question, closing it feels like a very hostile action and makes the site seem unfriendly and not welcoming.  My feeling is that marginal questions should not be closed explicitly, but should simply remain open but voted to an appropriate score (including negative, even very negative).  

The questions I'd close are the ones that are just gratuitously bad, in terms of being completely off-topic (eg, "how do I rebuild a Holley carburetor?"), or that having attacking / discriminatory language, obvious trolling (slashdot level stuff... GNAA references, etc.), and the like.  

IOW, I'd rely on up/down votes for almost all moderation and save the "close hammer" for extreme situations. 

Thoughts? 
b2A1I9n14a1r18y25_g7l12o15b2e5Should we be *extremely* slow to CLOSE questions?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Thanks for raising this subject.  As a pro-tem mod, I'm tending to hold off in particular on questions in areas where I don't have applied experience, and then following the lead of the mods or expert contributors with the relevant backgrounds.  In other words, if I'm uncertain about a question, I'll wait to see if it gets upvotes.  In many cases, questions that have been flagged for closure have garnered useful answers.


















No, data science and the implementation of artificial intelligence are off-topic. https://area51.meta.stackexchange.com/a/24016/136466A community manager explicitly said so in the Area 51 discussions for this site. There have been at least two AI sites on SE before, and they've all failed. We need to bring something new to the table, especially in the private beta stage. Once that's over, we can consider whether we can bring a new viewpoint to such questions.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Thanks. This would mean we should close the majority of questions that have been asked so far. (which is fine with me). I'll come back once things get stabilized :)b2A1I9n14a1r18y25_g7l12o15b2e5"Somebody said so" isn't much justification for deciding what a community driven site is about.  Even if that person works for SE.   The community ultimately dictates what it's interested in!  

Personally I'm extremely skeptical that there are enough people who want to talk about nothing but philosophy of AI to keep a site alive.   Ruling everything implementation related off-topic is consigning this site to the trash-bin from the get-to, IMO.b2A1I9n14a1r18y25_g7l12o15b2e5@mindcrime Taking advice from a community manager is probably the best plan. The site should be community-driven, but an extra site covering things that already have a good home elsewhere would be community-driven right out of existence. Again, it's very easy to get a site closed in private beta if it's not constructive for the network.b2A1I9n14a1r18y25_g7l12o15b2e5Yeah, part of the problem is, they kinda screwed up by not just calling the existing Data Science SE site "Artificial Intelligence".  Or, perhaps, by not calling this one "Artificial General Intelligence" or something to make the distinction more obvious.   Given that almost everybody considers ML a subset of AI, people *are* going to come here wanting to talk about ML.  Heck, it's already happening.  So if you push those people aside.... what's left?b2A1I9n14a1r18y25_g7l12o15b2e5@mindcrime (people who want to talk about nothing but philosophy of AI can already do so on http://philosophy.stackexchange.com/questions/tagged/artificial-intelligence )b2A1I9n14a1r18y25_g7l12o15b2e5So... no reason to talk implementation here, and no reason to talk philosophy.  And my one question trying to get some discussion going around the legal side of things has been downvoted already.   So what are we going to talk about exactly? :-)b2A1I9n14a1r18y25_g7l12o15b2e5@mindcrime Your legal question was downvoted because it asked for off-site resources. Also, there's a difference between implementation and academics - the *applied* (implementation) stuff is for Data Science, but we can discuss the more theoretical aspects of AI here.b2A1I9n14a1r18y25_g7l12o15b2e5@mindcrime I didn't see your question but there is law SE anyway :) http://law.stackexchange.com/


















Definitely not. In some minutes we can see lots of questions asking for specific technical solutions about neural networks and genetic algorithms. I agree with Ben that we need to make this site different and start migrating all these questions to other sites, where there is already an answer to most of them.

Why would we want to ask them again?
(apart from rush for reputation)
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5"Why would we want to ask them again?" -> maybe Datascience SE could answer that one…


















As you might know sites remain in private beta for three weeks:  

https://hardwarerecs.meta.stackexchange.com/a/75/237We've extended the private betas to last about three weeks total.  

https://meta.stackexchange.com/a/266555/226369Usually new communities are concerned that we didn't give them enough time.  

And I think in this three weeks, the core users should try their best to enrich the site's content.
I think we should ask questions that are easily google-enabled and a usual concern for most of artificial intelligence researchers that are even asked before in other forums (local forums maybe). This way, after the end of private beta if someone googles that question and sees that are site has better answered the question, they'll rely on our site and it is more probable to become a member of the site and ask their future questions in the site.
Any way are questions should not be opinion-based, subjective, etc.
In fact I'm not an expert or research-level student. I'm a remote sensing student with some experience in photogrammetry and programming with OpenGL API on C++. 
So I cannot add good questions myself but I'm really curious about everything related to accelerating the code and real-time programming.
Anyway since I'm an Iranian, I wanted to know if it's OK to translate good and popular questions in Iranian artificial intelligence forum which have the features of a good question that have introduced before or discussed about?  

http://blog.stackoverflow.com/2010/07/area-51-asking-the-first-questions/Your New Site: Asking the First Questions
http://blog.stackoverflow.com/2010/09/good-subjective-bad-subjective/Good Subjective, Bad Subjective
http://blog.stackoverflow.com/2011/01/real-questions-have-answers/Real Questions Have Answers
http://blog.stackoverflow.com/2011/02/are-some-questions-too-simple/Are Some Questions Too Simple?  

in order to enrich the content?
I think this way any Iranian who tries to google that question in English and then enters this site will see that the quality of answers is better here (because in these 3 weeks experts should try their best to add comprehensive answers) will be a fan of http://ai.stackexchange.comai.stackexchange.com.
b2A1I9n14a1r18y25_g7l12o15b2e5Is this OK to ask questions that have been asked before on local artificial intelligence forums?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Related: http://meta.ai.stackexchange.com/questions/1124/can-i-steal-a-question-from-a-closed-site


















I'm seeing a lot of answers from people along the lines of "AI is just bits and bytes and ultimately cannot be smarter than its creator because its creator would have to use their brain to make something smarter than themselves, which isn't possible."

It's kind of baffling to me to see these answers, especially in regards to the singularity, on a forum dedicated to AI. There is already image recognition that can recognize objects more accurately than humans, IBM's Watson can diagnose lung cancer at a rate much more accurately than human physicians, and Google's Alpha Go beat the Go world champion, even while experts were predicting that AI wouldn't succeed at doing this for another 10 years.

At the same time, I am completely certain that any of the individual programmers of Alpha Go would not have succeeded in defeating the Go champion of the world. I'm also fairly certain that the Watson programmers would not do better than Watson or a human physician at identifying lung cancer. These are already cases of the AI being more intelligent than its programmer, albeit in domain-specific cases.

Therefore, it seems wholly lazy and uncreative for people to provide such answers that AI cannot be more intelligent than a single creator and therefore human-level AI and beyond is not possible. I think it does not contribute to the discussion.
b2A1I9n14a1r18y25_g7l12o15b2e5Should we discourage answers that say AI can't be smarter than its creator?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5It was my opinion against Hawking opinion which I don't agree. Define then 'more intelligent'. Fastest computation or every day problem solving? The 'intelligence' cannot be easily measured. If you think AI can be smarter than human, prove it then. Or disprove opposite.b2A1I9n14a1r18y25_g7l12o15b2e5I define more intelligent to be more capable. We already see examples of AI programs being more capable than their creators. While I can't prove that an AI can be wholly more intelligent than a human, there are multiple viable pathways already set forth for getting there within the next decade. Yours is also not the first such answer, I already saw multiple ones like it today.b2A1I9n14a1r18y25_g7l12o15b2e5I flagged this and cast a vote to close this question because this sort of thing is expressly forbidden by StackExchange rules. Not only is it totally opinion-based and certain to "solicit debate, arguments, polling, or extended discussion," but it clearly stacks the deck in favor of one particular point of view. It's even blatantly offensive, with loaded accusations that the opponents are "wholly lazy and uncreative."


















If an answer is wrong, it should be downvoted, plain and simple. Clearly we want to discourage wrong information, and downvotes are designed to point out incorrect, irrelevant, or otherwise poor content. You seem to have really good examples that show such answers are wrong, so please feel free to mention them in a comment when downvoting!
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Whether or not any A.I. can out-think its creator is a primarily opinion-based question that's likely to stir intense debate. StackExchange discourages those kinds of questions for good reason; however, if that policy is not going to be enforced here, we might as well not make matters worse by automatically downvoting one point of view. Philosophers, theologians, A.I. researchers, biologists etc. can't even agree on what "intelligence" consists of, so how can we define what "wrong information" is for this question? It smacks more of forcing an unpopular minority opinion to keep silent.b2A1I9n14a1r18y25_g7l12o15b2e5@SQLServerSteve Perhaps I should have been more explicit in that I don't know the answer to that specific question - I'm saying that if one believes an answer is wrong, the thing to do is downvote.b2A1I9n14a1r18y25_g7l12o15b2e5I don't think that's true of opinion-based questions. The problem here is a deep philosophical one; it's not like looking up what the right parameter is for a Python function, or how to translate a particular English word into French or Swahili, or the right conditions for conducting a goodness-of-fit test. Most questions on StackExchange have crisp, definite answers of that kind, so downvoting ones perceived to be incorrect is usually right. Here - or in any other opinion-based question - downvoting or closing unpopular answers silences the minority permanently.b2A1I9n14a1r18y25_g7l12o15b2e5That is one of the many reasons StackExchange bans opinion-based questions: it degrades the voting system into a popularity contest, which has the secondary effect of preventing minority opinions that could turn out to be the correct answer from ever being heard. if we lived in medieval times, doctors in favor of bleeding could downvote their opponents into oblivion, but we're discussing matters that are a lot harder to reason about than bleeding, which is just a matter of science.The definition of intelligence is a matter of philosophy that has stumped some of the smartest minds in history...b2A1I9n14a1r18y25_g7l12o15b2e5In this field, there's always going to be a dangerous bias towards overestimating the accomplishments of A.I.; the voting system should not get intentionally coopted in service of that default outlook. There has to be some form of checks and balances to guard against excessive enthusiasm, but policies of this kind would remove them even before the site is out of private beta. Just how often do you hear anyone in the A.I. community say, "This can't be done" or "We're far behind where we should be" or "this is not 'intelligence'?" Those viewpoints must be expressible without retaliation.


















Experience with many beta sites from the start and through initial pro-tem moderation suggests that yes, for questions that could be on topic, let's give the benefit of the doubt in the early stages to help growth.

For posts that are definitely off topic, close them down as fast as possible, though - and a good way to do this in the Public Beta stage before we hit critical mass is to have frequent use of the chat room and point the CM's or mods at such questions.

Once we have a good number of folks with close privileges, it gets easier and I'd agree that normal voting should carry it from there.

The corollary to this is that we must use our votes. Upvote good posts, and downvote the bad ones - this helps make sure the good ones are seen and their owners rewarded, but also gets us that critical mass of users with the necessary privileges as fast as possible.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Everyone has close privileges during a private beta, so we can close/reopen stuff right now.b2A1I9n14a1r18y25_g7l12o15b2e5I'll clarify that - cheers :-)


















As Franck neatly put: First step would be to clearly define the scope of the site.

Next, there are very active Data Science, AI and ML communities on Reddit and other community sites like facebook groups, etc; and they would be an excellent way to get new users.

And as AI is a very hot topic right now, we would be getting traffic and users as long as we keep the scope well pruned and the posts well curated.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5AI is hot right now, but there are also lots of places one can have conversations (like Reddit, for example).  So we need to figure out how to get people here specifically, if we want a community on this site in particular.

One idea I had was finding a way to reach out to students taking the various MOOC's on AI and AI related topics.  Yes, it might mean getting some "homework questions" but we could possibly attract some really enthusiastic participants.  But how to reach them in particular?b2A1I9n14a1r18y25_g7l12o15b2e5Awesome. I am currently doing Udacity's ML nano-degree.  Would make it a point to post in the course forum :)b2A1I9n14a1r18y25_g7l12o15b2e5Is there any discussion for a scope definition already?


















To answer the title question, easy-to-Google questions are not OK for the private beta. Flooding the site with trivial questions and simple answers is a great way to demolish any chance of attracting big-name experts. Artificial intelligence site proposals have already failed a couple times - once explicitly https://blog.stackoverflow.com/2010/12/no-artificial-intelligence-in-area-51/because of terribad pedestrian questions.

If we want to survive and grow, we have to keep quality high. We can do that by downvoting low-effort questions and closing non-constructive questions (e.g. requests for off-site resources). And of course, we'll need to dig into the literature to see what kinds of good questions we can explore.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5In order to encourage downvoting of poor questions, it helps to up-vote the remainder, so people have enough rep to spend on down-votes.b2A1I9n14a1r18y25_g7l12o15b2e5@SeanHoulihane On private beta sites, anyone can downvote, even with 1 rep. Still, upvoting good content is critical too.b2A1I9n14a1r18y25_g7l12o15b2e5`AI has become the new baseline for “failed to make it out of private beta”` → ouch! Great link, those are indeed things to know!b2A1I9n14a1r18y25_g7l12o15b2e5**Artificial intelligence site proposals have already failed a couple times - once explicitly because of terribad pedestrian questions.**

Interesting.. I felt it failed for the exact opposite reason... over emphasis on building an "experts only" (in practice, if not in word) site, which was so hostile to newbies and hobbyists that it ran them all off.  And guess what... there just aren't *that* many "AI experts" out there!  If we go down this path again, we'll once again be sacrificing the "good enough" in the unnecessary pursuit off "perfect".b2A1I9n14a1r18y25_g7l12o15b2e5I'd add "general reference", such as questions that can be answered by the most basic textbooks on the matter at hand.


















The latter is the canonical way to refer to the field, and its unclear when, if ever, [deep-network] would be preferable. Its a small change, but it'd help avoid very odd sounding questions like https://ai.stackexchange.com/q/96/109"What is Deep Network?"
b2A1I9n14a1r18y25_g7l12o15b2e5Should the [deep-network] tag be replaced by [deep-learning]?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Sorry, I'm kinda new to this AI stuff. I started working with AI two months ago, so I don't know all the terms. :/ (I had the "very odd sounding" question.)b2A1I9n14a1r18y25_g7l12o15b2e5No worries! Just want to get the right terms out there to aid in your future learnings :)


















Most Stack Exchange sites (including this one) are English-only, and it's not expected that users will be able to use other languages. Therefore, if there are resources that are not available in English, it would be very good to make them accessible to English speakers somewhere, and this site would be a fine place for doing so. 

Make sure, of course, that the question is good (i.e. well-researched, not trivially Google-able in English) and constructive (i.e. on-topic). To avoid accusations of cross-language plagiarism, try to paraphrase rather than translating word-for-word. In the same vein, link back to the original site when you draw heavily from it. That's all part of being a good Internet citizen. If you can improve the answer by drawing from additional sources, that's great too!

Relevant SE blog post: https://blog.stackoverflow.com/2011/02/are-some-questions-too-simple/Are some questions too simple?
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5but here is not a place to provide resources, here is a place for question that you encounter during your research or project. And as I have seen on iranian forums most of them, don't have real expert question. Most of them are explanations about the applications of AI and also solutions for famous AI problems like `Travelling salesman problem`. Anyway since I haven't committed to this proposal, I'm not forced to ask 10 questions in this 3 weeks. But since I'm going to learn AI myself in the near future because of its application in remote sensing, this site will be really helpful for me.b2A1I9n14a1r18y25_g7l12o15b2e5@sepideh Right, you shouldn't *just* link to the external site; you should include its information and then cite it.b2A1I9n14a1r18y25_g7l12o15b2e5But I think the idea of this question can be really helpful for those who have committed to the proposal as far as they consider your advises. You won't have ten real expert questions in 21 days but you can translate ten real expert questions asked in local forums to english and let international experts add comprehensive answers which are better than the answers in that local forum.


















Stack Exchange sites have a mechanism called "intrinsic tag blacklisting" that's intended to do exactly this - prevent the tag that simply describes the topic from being used.

However, the way the system works means that it doesn't always work. The system takes the URL slug before .stackexchange.com, and blacklists that as an intrinsic tag. For this site, that means that the https://ai.stackexchange.com/questions/tagged/aiai tag is blacklisted, but https://ai.stackexchange.com/questions/tagged/artificial-intelligenceartificial-intelligence is not. That's the explanation of the bug.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5This isn't a 'bug' *per se.* We simply **try not to anticipate every problem** before they occur in actual practice. The private beta fleshes out these "problems" very quickly, so letting this stuff come up organically works way, *way* better than a community team huddling up trying to imagine all the ways this site can go wrong before it even launches. This 'bug' is largely philosophical... and by design.


















During the private beta we have the opportunity to send Emails via stack exchange:
https://i.stack.imgur.com/2c4CE.jpg
And because stackexchange is already well-known on the net, it is more probable that our invitation will be read and clicked on. And I don't think there would be any academic mail server which rejects mail sent by the domain stackexchange.com.
As you know http://www.scimagojr.com/journalrank.php?category=1702there are a lot of artificial intelligence related journals, I want to see if it is useful or allowed to use the emails of some of those young researchers who have published papers in this journals recently and introduce them this new site?
Because my friends or the people that I have met directly will always notice the emails sent by me personally but a stranger may consider it a spam.
b2A1I9n14a1r18y25_g7l12o15b2e5Can we send messages to young researchers who have recently published papers in artificial intelligence related journals during the private beta?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Related: [What kind of experts are we trying to attract?](http://meta.ai.stackexchange.com/q/40/8)b2A1I9n14a1r18y25_g7l12o15b2e5Was this strategy helpful? Did you attract any young researcher to the site through this? If yes, what was the text of the email that you sent to them?b2A1I9n14a1r18y25_g7l12o15b2e5Has anybody tried doing this yet?


















I asked a question that was meant to discuss artificial intelligence in general. I tagged it https://ai.stackexchange.com/questions/tagged/artificial-intelligenceartificial-intelligence, and someone fairly pointed out that that's redundant. I changed it to https://ai.stackexchange.com/questions/tagged/agiagi, because the question referred specifically to how https://ai.stackexchange.com/questions/tagged/optimizationoptimization applies to artificial intelligence, but I'm not sure that was right.

Should the https://ai.stackexchange.com/questions/tagged/agiagi tag refer only to questions that reference Artificial General Intelligence specifically, or can it be used for questions that could be related to AGI in more indirect ways? 
b2A1I9n14a1r18y25_g7l12o15b2e5What's the best use of the [agi] tag?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5And by the way, is AGI different than or the same as "Strong AI"? If they're the same, which one is preferred? Should we exclude one of the two tags?


















https://ai.stackexchange.com/questions/tagged/artificial-intelligenceartificial-intelligence is what SE calls an intrinsic tag, as is https://ai.stackexchange.com/questions/tagged/aiai.

Intrinsic tags are effectively pointless tags on a site, ie this site is about artificial intelligence, so does not need a tag on artificial intelligence. Likewise, https://ai.stackexchange.com/questions/tagged/programmingprogramming is not needed on Programming.SE

https://ai.stackexchange.com/questions/tagged/optimizationoptimization is much more relevant, as it is a specific class of questions within the site scope.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I'm asking about the [tag:agi] tag, not the intrinsic tag.


















I was going to answer a question about reinforcement learning and wanted to show some formulas using the same notation I use on CrossValidated, for instance:

$r_{t+1}+\gamma \max_a Q(s_{t+1},a)$

But it is currently not supported, at least the way I tried it. Can we have support for LaTeX formatting here?

Examples:


https://ai.stackexchange.com/q/157What artificial intelligence strategies are useful for summarization?

b2A1I9n14a1r18y25_g7l12o15b2e5Can we have LaTeX formatting support?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5You'll need a *very* good reason / a lot of feature use because LaTeX is very _*mumble mumble* expensive *mumble mumble*_.b2A1I9n14a1r18y25_g7l12o15b2e5Extremely urgent, please !!!


















While it might be nice to have for some questions, most questions you would need LaTeX for should be off-topic here. This site is not meant for machine learning questions, as Cross Validated and Data Science Stack Exchange sufficiently cover those subjects. 

See: https://ai.meta.stackexchange.com/questions/4/are-all-questions-asked-on-stats-and-data-science-se-also-on-topic-here?cb=1Are all questions asked on stats and data science SE also on topic here?


  Note: I posted this answer when I didn't know very much about AI, and I have misunderstood or missed some of the parts of AI that should be on-topic here, I am now of the opinion that we should have LaTeX here. I'll leave this answer here because of the votes (and vote balance) on it, but I don't agree myself anymore with it. So please count an extra downvote from me.

b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5This is a good reason *against*. A very good reason, in fact.b2A1I9n14a1r18y25_g7l12o15b2e5I disagree @wizzwizz4 . We want to attract experts in AI, and experts in AI speak math. While the questions here might be different from those in crossvalidated and datascience, the audience is expected to have a big overlapb2A1I9n14a1r18y25_g7l12o15b2e5@Harsh I agree, which is why I said "it might be nice to have [it] for some questions".b2A1I9n14a1r18y25_g7l12o15b2e5@Harsh Please post an answer with your opinion, so people can vote on it too.b2A1I9n14a1r18y25_g7l12o15b2e5"While it might be nice to have for some questions, most questions you would need LaTeX for should be off-topic here." -- that's just not true.  It is not the case that you only need math if you're talking about machine learning.  Math is the language of science in general.  If we want to talk real, serious science here, we should have MathJax here.


















If deep-learning is preferred, then deep-network should be set up as a https://meta.stackexchange.com/a/70718/135236tag synonym for it, that way if anyone tries to use it, it gets mapped to the preferred name.  We need someone with 1250 reputation to do that.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Is there some reputation threshold to be able to do that? Can't find that option :-/b2A1I9n14a1r18y25_g7l12o15b2e5@zergylord Yes 1250 is the required reputation.  I've linked to the meta answer that talks about them.


















We have a //chat.stackexchange.com/rooms/43371/artificial-intelligencechatroom. At the moment it doesn't really have a name. Other sites' chatroom names include:


Super User's "Root Access"
PPCG's "The Nineteenth Byte"
Blender's "The Renderfarm"
Pets' "The Litterbox"
Travel's "You Are Here"
Aviation's "The Hangar"


So, what should we call ours?

While we're at it, what should we name our resident feed bots (Main and Meta)?
b2A1I9n14a1r18y25_g7l12o15b2e5What should we name our chatroom?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Do we have a winner here? I'd like solving the halting problem here :-)b2A1I9n14a1r18y25_g7l12o15b2e5@EricPlaton I think we should wait until just before we graduate, then put all the suggestions for the names of each bot into a polling service like strawpoll (to avoid the FGITW effect).


















Turing Testing Room

A play on the term "Turing test" (an examination of how well a machine mimics natural conversation with a human): tests taken by human students are usually administered in a testing room.

Questions on the main site are currently posted to the ticker, so we don't see the username, but if that's changed, it could be called https://en.wikipedia.org/wiki/MultivacMultivac after the computer from some of Asimov's stories. We could call the meta bot https://en.wikipedia.org/wiki/Watson_(computer)Watson.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5They are associated with a pseudo-account. http://chat.stackexchange.com/users/-585/ai-questionsb2A1I9n14a1r18y25_g7l12o15b2e5Might be a bit too wordy, but I like the Turing test reference. Seems like a good fit for a chatroom.b2A1I9n14a1r18y25_g7l12o15b2e5For the past few months I've been using The Nineteenth Byte to make sure I still pass the Turing Test, so a dedicated room would be much appreciated. Erm, I mean, I'm not a bot, of course.


















A core goal of the private beta is to generate high-quality content that will attract experts. We are also given the opportunity to invite experts by email to the private beta. My question is simple: exactly what kind of experts are we trying to attract?

According to https://ai.meta.stackexchange.com/questions/4/are-all-questions-asked-on-stats-and-data-science-se-also-on-topic-here?cb=1 this question , data science and the implementation of artificial intelligence are off-topic. The problem is that we don't want to become a duplicate of Stats or Data Science SE. The question links to https://area51.meta.stackexchange.com/questions/24014/will-machine-learning-be-considered-as-on-topic/24016#24016this answer on Area 51 which says that this site is for questions in the "academic humanities arena". This seems to suggest that we want experts in academic humanities.

However, most experts in the field of artificial intelligence are experts of implementation. They are applied mathematicians and computer scientists who are trying to make artificial intelligence a reality. The recent advances in artificial intelligence, like https://deepmind.com/alpha-go Alpha Go, have been the result of breakthroughs in implementation.

If this site is about humanities-style questions about Artificial Intelligence, then what appeal does it have to the type of people who created Alpha Go, who are primarily computer scientists and mathematicians? I'm not convinced they have special expertise about the ramifications of Artifical Intelligence on human society, politics, law, etc.

Perhaps we need to redefine what this site is about. I think a place to look for inspiration is Math SE and MathOverflow. One is about mathematics at any level, while the other is a site for research level mathematicians. Maybe Artificial Intelligence SE should be to Data Science SE and Stats SE what MathOverflow is to Math SE. That is, it should be a site about tackling research level AI problems with the tools of data science and statistics. 

This means that we'll have to seriously elevate the quality of our questions and answers to attract real AI experts. But at least we'll have  experts to attract.
b2A1I9n14a1r18y25_g7l12o15b2e5What kind of experts are we trying to attract?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I wholeheartedly agree with you! As an AI implementation person, I never felt comfortable posting to Data Science or Statistics, as their common use cases (e.g. exploratory data analysis) are quite far removed from those of AI. A expert-level site allowing for AI specific theoretical and  implementational issues is definitely what I thought I was signing up for. Disallowing all implementation questions doesn't leave much outside of pop science and Bostrom's books.b2A1I9n14a1r18y25_g7l12o15b2e5That's also what I thought when I saw Artificial Intelligence. It didn't really cross my mind that I was signing up for a humanities-oriented site.b2A1I9n14a1r18y25_g7l12o15b2e5"I'm not convinced they have special expertise about the ramifications of Artifical Intelligence on human society, politics, law, etc." They do, however, have experience with the implementation of AI, meaning they can understand its strengths, weaknesses, and quirks. That's useful knowledge to have if someone wants to predict AI's impact on human society, politics, etc.b2A1I9n14a1r18y25_g7l12o15b2e5@zergylord I never had any issue with stats SE: what kind of of implementation questions don't fit there (aside from pure programming or hardware questions)?b2A1I9n14a1r18y25_g7l12o15b2e5@FranckDernoncourt Maybe something like deep reinforcement learning?b2A1I9n14a1r18y25_g7l12o15b2e5@bpachev on-topic on CVb2A1I9n14a1r18y25_g7l12o15b2e5@FranckDernoncourt That's true, but I think that zergylord's point is that most CV users can't help with those type of questions, and so it would be good to have an expert-level site. Like Math SE and MathOverflow.b2A1I9n14a1r18y25_g7l12o15b2e5@bpachev I see. There are already some strong statisticians and ML folks in CV though.


















Automata

Study of abstract machines as well as the computational problems that can be solved using them.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Automata brings to mind mechanical machines, not artificial intelligence. (p.s. I didn't downvote, just explaining a possible reason)


















The Singularity

I probably don't need to explain that :-)

And for the bots, how about Daneel and Giskard?
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5+1 for The Singularity. The bots could be HAL and Computer (as in Star Trek).


















First up, when I posted https://ai.meta.stackexchange.com/a/7/75my answer to the question you reference, I was just passing along the information given to us by Robert Cartaino. I'm not wedded to that opinion.

I think all the scientists working on AI would be helpful here even though we're not working on implementation. This is what the original Area 51 Discussion post said (excerpted):


  Data Science is an applied site for all the programmers/statisticians/mathematicians who are trying to make this stuff work.


There's some leeway there. Specifically, technical questions seem to be OK, as long as they're not super in depth about the math or programming. There are also "why" questions (as opposed to "how") that are very interesting and educational. I like https://ai.stackexchange.com/q/92/75this question a lot. Scientists are welcome.

We don't have to limit ourselves to the philosophy and practical effects of AI, though they're in scope. Philosophers are welcome too.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5As a note, Robert Cartaino's opinion was not any kind of consensus, back when it appeared. Let's keep in mind there is quite some division, which is probably good to find the best balance...b2A1I9n14a1r18y25_g7l12o15b2e5@EricPlaton Indeed, and I think we can broaden our scope a little after the private beta stage. Right now, we need to show that we bring something new to the SE network.b2A1I9n14a1r18y25_g7l12o15b2e5Of course the site would benefit from AI researchers. However, this site isn't  going to attract them. Why would they decide to contribute a significant amount of time to something that will give them zero to little help?


















First there is a need to distinguish modeling from implementation. They are not exactly the same, although strongly related. This was a very difficult lesson to learn among mathematicians and early programmers, notably in the 70s (mathematical proofs can demand a lot of non-trivial programming work to make them "computable", as in runnable on a computer).

As for Machine Learning (by far the most active AI category), modeling belongs to Data Science SE---perhaps the one thing that most people agree on. Implementation should be out of there, as the issues and focus differ (but again, they are related).

Now, should implementation issues be in AI SE, or StackOverflow? The recurring example is TensorFlow, who's home page states that questions should go to StackOverflow. And we should respect that...

But we should keep in mind that the TensorFlow team will choose SO, because it is the largest community, and because the team has something else to do rather than experimenting with hardly visible communities. Well, size matters. We may think that if AI SE becomes big enough on the implementation side, the TensorFlow team (and other major frameworks) may move actually.

In fact, I think now that implementation questions would benefit from a dedicated site (my view has evolved since the Area 51 definition phase). I have replied and tried to reply to several SO questions related to ML tools, and I think some are out of place compared to other questions. For example, https://stackoverflow.com/questions/38321024/why-this-simple-tensorflow-code-is-not-successful-convnetjs-using-tensorflow/38368469#comment64172189_38368469some TensorFlow questions are not really programming questions, and not really framework questions. I mean, there is background knowledge on graph construction and execution, as well as background knowledge about statistics and probabilities that are really necessary to make meaningful contributions.

This is not to say that all questions are out of place on SO. https://stackoverflow.com/questions/38297581/tensorflow-gpu-utilization-is-almost-always-at-0#comment64124967_38297581Some are really framework issues or (Python) programming issues, and they are good there.

Based on this opinion, I think the site should be interested in implementation experts, whether they work on ML or Expert Systems (or both?).

See also some threads on Area 51 like https://area51.meta.stackexchange.com/questions/23789/the-example-questions-will-not-attract-expertsthis one and https://area51.meta.stackexchange.com/a/23528/69948this one.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Related: [Should AI programming questions be on-topic?](http://meta.ai.stackexchange.com/q/1139/8)b2A1I9n14a1r18y25_g7l12o15b2e5I tend to think exactly the opposite of this answer: AI surely handles the modeling and development of the algorithms, and DS handles issues of implementation and deployment. As mentioned in Ben N.'s answer, the Data science site views itself as "applied" and I think this is consistent with the views of AI researchers as well.



















  I'm seeing a lot of answers from people along the lines of "AI is just bits and bytes and ultimately cannot be smarter than its creator because its creator would have to use their brain to make something smarter than themselves, which isn't possible."


I think this argument is a bit unclear and needs some refinement. It is true that AI can indeed be smarter than the creator at certain tasks (AlphaGo being better at Go than the programmers of AlphaGo, for instance). What I think this argument is really saying is:


  "AI is just bits and bytes programmed by its creator. The creator would be able to know how the AI works, otherwise he would be unable to create it in the first place. Therefore, the creator can be said to be superior to that of its creation, since the creator can understand its creation."


That seems like a more logical premise. Sure, AlphaGo is better at Go than the programmers of AlphaGo, but AlphaGo's programmers actually knows how AlphaGo operates. This type of argument was made in the paper http://kryten.mm.rpi.edu/lovelace.pdfCreativity, the Turing Test, and the (better) Lovelace Test, which specifically argues that  AIs cannot be creative since programmers are able to figure out what their creations (AIs) are doing. Another paper http://arxiv.org/pdf/1410.6142v3.pdf"The Lovelace 2.0 Test of Artificial Creativity and Intelligence" saw this argument as so self-evidently true that it tried to create a weaker version of the Lovelace Test to identify and measure AI creativity.

The programmers, basically, know how their program works. That doesn't mean the program is less intelligent than the programmers. Just that the programmers can understand why their programs behave the way they do, given enough time and patience.

Either way, I would not support discouraging answers such as these, if only because this view does have support within the AI scholarly community. If you have experts who hold this view, then we should let this view be given exposure.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5While I don't agree with the view, having made an AI using an animal's brain mapping and not fully understanding how its decisions were being made, I can support not discouraging it because the scholarly community doesn't yet see things that way.


















Back Propagation
A reference to backpropagation neural networks. We could use this name because in our chatroom, ideas will be propagated back and forth.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I think we should avoid names which explicitly reference neural networks. They are not all there is to AI, by far, and anyway, don't we want to discourage overly technical questions? To me it would seem pretty weird to say "sorry, questions about how backpropagation works are off-topic here, go to Data Science", yet have a chatroom literally named "Back Propagation".


















The question you link is a perfectly valid question in the philosophy of artificial intelligence. Philosophy is the other large part of AI, together with technology, so they should be on-topic here.

However, one should be careful when answering these questions, that one does not base the answer on own opinions. One should reference what philosophers have said in the past, like one of the answers on the question you link mentions the Trolley problem.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5So you suggest that answers in the thread I link (for example) add references? I do agree that contributes well, by I have seen quite many SE sites where they don't even bother, yet they seem to do well (a pity, I think). If we concur as a community to require citations and references, I am all for it.


















Note: This post is (nearly) identical to https://languagelearning.meta.stackexchange.com/questions/6/vote-early-vote-oftenthis one on Language Learning.SE.
I would like to echo a post that https://tex.meta.stackexchange.com/questions/12/vote-early-and-oftenScott Morrison made on Meta.Tex.SE:

I'm a moderator from MathOverflow, and this "question" is actually unsolicited advice, based on our experience from the initial launch of MathOverflow.

We should encourage everyone to vote positively as often as possible!

Every Stack Exchange site will eventually end up with a different "base level" of voting --- that is, the expected number of upvotes for a question of a given level of excellence. (This effect occurs because people see a good question, but already with a certain number of votes, and think "oh, I would have upvoted this, but it already has enough".)
It's easy for us to affect this "base level" by encouraging high levels of upvoting now. We're setting the standards, and this really will have an effect.
(On MathOverflow, we were very active about this early on, specifically encouraging all the initial round of users to vote early and often. You can compare statistics, and see that the average vote total for a MathOverflow question is much higher than on any of the other SE 1.0 sites.)
In case it's not obvious: the rationale for wanting this base level to be high is that it provides better positive feedback to good contributors."

Especially in the beginning, let us vote early, and vote often. More voting always helps. Downvotes, too, are good – we want to weed out the wheat from the chaff here, and get rid of poor questions and answers.
b2A1I9n14a1r18y25_g7l12o15b2e5Vote Early, Vote Often!b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5The reason that I'm posting this: I noticed there are barely any Nice Question or Nice Answer badges awarded, while on other sites we had several Good Question and Good Answer badges during the private beta. This is a sign that we are not voting enough.b2A1I9n14a1r18y25_g7l12o15b2e5Or a sign there is no good enough question or compelling enough answer! I agree with you on more dynamic, but let's vote with our heads too (I mean, we can still type with our fingers). Edit: I did not see @Ben N's post, which argues similarly.


















During this private beta, you actually can downvote infinitely - the minimum rep for that privilege in this stage is 1. I think we're still subject to the https://blog.stackoverflow.com/2010/03/important-reputation-rule-changes/"upvote one thing for every two things you downvote" rule, though, but that shouldn't be limiting, especially considering you have to have cast 300 votes before it takes effect.

It looks like you've already figured out what to do with nonconstructive answers and questions: downvote. For answers, you'll take a little hit of 1 point, but if it means saving the site from drivel, that's a fine price to pay. Questions that can only be answered subjectively can be closed as primarily opinion-based.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Thank you. I did not know about the capability in private beta. Let's get to work...


















Few examples:


https://ai.stackexchange.com/q/209/8https://ai.stackexchange.com/q/209/8
https://ai.stackexchange.com/q/68/8What genetic algorithm designs are there that includes models of epigenetics?
https://ai.stackexchange.com/q/181/8https://ai.stackexchange.com/q/181/8
https://ai.stackexchange.com/q/1611/8What are good APIs out there for (untrained) intent detection?

b2A1I9n14a1r18y25_g7l12o15b2e5Is asking about AI algorithms or frameworks recommendation on-topic?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5FYI  [Are all questions asked on stats and data science SE also on topic here?](http://meta.ai.stackexchange.com/q/4/4)


















For FSM's sake, not this again.  Please, no... stop with the "let's attract experts" verbiage.  I mean, don't get me wrong.. of course we want experts, but we don't want only experts and we don't want to anoint "experts" with some special degree of relevance.  This is a HUGE part of what made it so hard to have a successful ai.se before... we chased away the good, in pursuit of the perfect. 
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Good point. The point of my question is that the only experts in AI are experts in subject matter that is off-topic for this site, therefore there are no experts to attract..


















How should we as a site treat answers which are simply copy-pasted from another source, (whether with or without attribution)? Particularly those which show little understanding of the topic on the part of the poster.

I won't name anyone, but I've seen an answer where the user apparently simply copy-pasted the first paragraph of the first relevant google result, which didn't even really answer the original question. Afterwards, they admitted to know nothing about the topic themselves. 

To me, this seems wrong. What is the general stance on this sort of answers?

(To the person in question, if they recognize themselves: Sorry about this, but I think this sort of thing needs to be discussed.)
b2A1I9n14a1r18y25_g7l12o15b2e5Should we discourage copy-paste answers?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5They should use quote, if they forgot, suggest an edit. Then post a link to the source.b2A1I9n14a1r18y25_g7l12o15b2e5@kenorb I don't think this is a text-formatting issue... or something fixed by dropping in a bit of attribution.b2A1I9n14a1r18y25_g7l12o15b2e5Ok, I see I'm the cause of a lot of issues on meta, and I'm sorry. Feel free to remove me from beta if you wish.


















At one point I thought I got it, but then I lost again.
Few highlights:

https://ai.meta.stackexchange.com/a/46https://ai.meta.stackexchange.com/a/46

modeling belongs to Data Science SE
I think the site should be interested in implementation experts.


https://ai.meta.stackexchange.com/a/7https://ai.meta.stackexchange.com/a/7

No, data science and the implementation of artificial intelligence are off-topic.


https://ai.meta.stackexchange.com/a/72https://ai.meta.stackexchange.com/a/72

suggest that "programming" and "implementation problems" be explicitly listed as outside the scope of this site



Obvious points are:

data science questions belong to https://datascience.stackexchange.com/Data Science site,
programming questions belong http://stackoverflow.comStack Overflow.

What about AI implementation and modelling? Above quotes are a bit contradictory.
So what's on-topic exactly, https://ai.stackexchange.com/q/1297/8AI modelling or implementation, or none of it?
If none of it, what should be?
b2A1I9n14a1r18y25_g7l12o15b2e5What should be on-topic, modelling or implementation, or anything else?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I think we should also be more clear on what we mean by "implementation", since it seems to me that not everyone can agree on a definition. In my opinion, programming questions and questions about the inner workings of basic algorithms (e.g. Viterbi, backpropagation, etc) should be definitely off-topic here. But on the other hand, if we want to be able to discuss AI, some basic level of knowledge about how these things work is certainly necessary.


















Post consists almost entirely of content copied from elsewhere should NOT be considered a useful 'answer' in the context of this site. 

Copying answers from external sources without permission is not allowed (and quoting or linking back to that site does not make that okay). Even posting an answer copied almost entirely from reusable content should be frowned upon, or even flagged to be removed. 

This site was created to add something unique (and better) to the Internet. If we're simply copying stuff that's already out there, why bother? We're just adding another barrier between the folks searching for this stuff and the original source of the content.

Answers should create something original and useful for this community specifically. That is why we bring together individual communities of experts to host these topics. 

And vetting is a big part of this site. Your best content should be rising to the top. Please stop up-voting these posts!
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5**Thank you** for the last sentence. I'm not really a fan of "vote early, vote often" exactly because it's too frequently interpreted as encouragement to upvote anything.b2A1I9n14a1r18y25_g7l12o15b2e5@BenN I believe that a hard-to-find quote that answers a question is worth upvoting. Also, depending on the source, might give increased credibility.b2A1I9n14a1r18y25_g7l12o15b2e5@FranckDernoncourt Indeed, trusted supporting evidence is excellent. Correctly-cited excerpts are great for that purpose. Copying answers wholesale is what's being discouraged here.b2A1I9n14a1r18y25_g7l12o15b2e5@BenN I agree that copying answers that do not appropriately address the question is to be discouraged. But I think Robert was discouraging any copy pasted answer  "Post consists almost entirely of content copied from elsewhere should NOT be considered a useful 'answer' in the context of this site."b2A1I9n14a1r18y25_g7l12o15b2e5@FranckDernoncourt I just don't see the value in turning every simple piece of **sage advice** into a mile-long treatise just to cover the 1-in-1000 exception. That's why everything in this system has become so flippin' complicated. 50,000 landmines behind the simplest action... adding little actual value at all. Is it just me? b2A1I9n14a1r18y25_g7l12o15b2e5@RobertCartaino I simply think we should clearly distinguish bad answers from copy pasted answers.


















Programming, algorithm, modeling, math, philosophy, and history questions should the off-topic, as they are already on-topic in https://ai.meta.stackexchange.com/q/4/4other SE, such as Stats and Data Science.

Data science and the Stats SE already have a huge overlap (>~80%), and I am worried to have a third SE that also significantly overlaps with them. Personally, it would further demotivate me to write any answer, as it gets tiring to copy-paste content, and updating duplicated answers is a pain.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Maybe instead of writing answers, you can ask questions which you think are off-topic on the other sites (since you've good understanding what's on-topic there) to show some good examples of such questions for others.b2A1I9n14a1r18y25_g7l12o15b2e5@kenorb It's hard to come up with such questions :) I see only a handful amongst the existing questions that could qualify, but I am not even sure.


















I think we should discourage the use of LaTeX, but should allow it. Our goal is to attract experts in AI, and the language of AI (today) is math. Like that post in the OP (which I wrote, btw), I think math makes a lot of concepts easier to understand. 

I think this SE should focus on the design aspects of AI and AI research instead of the programming and libraries (those questions should go to Data Science) or the statistics (those should go to Cross Validated), but some mathematics is often a core component of AI theory.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Please explain why you think we should *discourage* the use of LaTeX?


















In these early days, how can we attract attention to the best questions? The current front page does not accurately reflect this. Keeping in mind that our goal is to invite experts, I think it would be great if we could manually curate a list of questions that we can tout as ideal questions for this SE. 

(We could create a community wiki here with the answers as we discuss how to proceed)
b2A1I9n14a1r18y25_g7l12o15b2e5How can we highlight good questions?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I agree with you, and perhaps I should remove my biased list from the question and put it in an answer. I do not want to move attention away from the question in the titleb2A1I9n14a1r18y25_g7l12o15b2e5Sounds good, I moved my comment.


















To give examples of questions I think are good, and that we should promote, in order with the best questions at the top:


https://ai.stackexchange.com/questions/92/how-is-it-possible-that-deep-neural-networks-are-so-easily-fooledHow is it possible that deep neural networks are so easily fooled? I would not have put "easily" in the title, but it is an excellent question that the AI experts I know spend a lot of time thinking about.
https://ai.stackexchange.com/questions/1294/how-does-hintons-capsules-theory-workHow does Hinton's "capsules theory" work?
https://ai.stackexchange.com/questions/77/is-lisp-still-being-used-to-tackle-ai-problemsIs Lisp still being used to tackle AI problems?
https://ai.stackexchange.com/questions/227/what-is-the-difference-between-mlp-and-rbfWhat is the difference between MLP and RBF? : This can go to Crossvalidated but I'd argue it's out of place there and more at home here. Though it is a comparison of two specific algorithms, it reflects wider design issues in AI algorithms.


Others may disagree on this list, but I'd like to put up here the questions I think are more on-topic here than I think in other SEs. Some overlap is inevitable.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5All the questions you mention except for the third one Lisp are very much on-topic on stats and data science SE. The Lisp question might be on-topic on data science or stats, but unsure.b2A1I9n14a1r18y25_g7l12o15b2e5@FranckDernoncourt They sure are.  The third one would be closed off though.


















The Dropout


  A technique of reducing overfitting in neural networks. The term "dropout" refers to dropping out units in a neural network.

b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I don't think most people would get that reference. I think "college dropout" is what jumps to mind first.


















There is a constant war between spammers and website operators, to prevent websites from spam. CAPTCHA's are the tools to protect sites, and are the front line of this arms race.

This is an area of AI research that is directly relevant to the public.  

The question is if we should allow postings about how to defeat CAPTCHA's. They are probably in scope, but we don't want to help spammers.

https://xkcd.com/810/Obligatory XKCD link.

We may get some inspiration from Security.SE. They have some experience in dealing with ethical issues. Over there, they have an explicit close reason for questions about hacking other systems: 


  Questions asking us to break the security of a specific system for you are off-topic unless they demonstrate an understanding of the concepts involved and clearly identify a specific problem. 


Maybe we need a similar close reason or off-topic flag?
b2A1I9n14a1r18y25_g7l12o15b2e5Should we allow postings about defeating CAPTCHA's?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Is that Security.SE quote really the same thing? The way I understand it is that it is mainly meant to stop questions like "I want to hack example.com. Help me!". Aside from that, there's plenty of "abusable" posts over there...b2A1I9n14a1r18y25_g7l12o15b2e5As for the CAPTCHA's, wouldn't any descriptions which were detailed enough to be useful to spammers be off-topic anyway? I mean, just saying what the general approach is doesn't really help anyone.b2A1I9n14a1r18y25_g7l12o15b2e5@InquisitiveLurker It is one example of how they deal with possibly unethical issues. Note that it is not explicitly ruling out "black hat" activity. I think we can take some inspiration from them - from this close reason and other ethical issues they've dealt with. Even if we decide that we are _not_ going to follow their lead, at least we'll have considered why not.


















Escaping local optima is an extremely ubiquitous problem (in case it's unclear - there are vastly more applications than backprop), leading to many open questions (a great deal of metaheuristics research, indisputably part of AI, is concerned with this). 

So, it is much more open-ended (and therefore subject to heuristic/AI solutions) than the more pedestrian questions (with procedural anwers) about e.g. backprop that appear to be within the AI SE remit.

Hence, I'd say it is definitely on topic ;-)
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I'd say that those are exactly the reasons why it should NOT be here, but rather on Data Science. It's really more of a mathematical/optimization topic than AI. You wouldn't talk about differential equations on Physics.SE either, even though a lot of the subject involves them.b2A1I9n14a1r18y25_g7l12o15b2e5@InquisitiveLurker - state space search has always been one of the pillars of AI. Optimization needn't be "of a numerical value" nor is it terribly strongly connected to data science as a discipline.b2A1I9n14a1r18y25_g7l12o15b2e5@InquisitiveLurker please make your opinion an answer, so people can vote. Lets see which way the rest of the community leansb2A1I9n14a1r18y25_g7l12o15b2e5I feel I am still not getting sufficient clarity on what is on-topic here vs. Data Science and Cross Validated SE sites.b2A1I9n14a1r18y25_g7l12o15b2e5@Harsh I've written it now.


















The question is off-topic, as it's about how to the use of machine learning algorithms. (the other questions on neural nets, their architectures, backpropogation, are also off-topic).

Programming, algorithm, modeling, math, philosophy, and history questions should the off-topic, as they are already on-topic in https://ai.meta.stackexchange.com/q/4/4other SE, such as Stats and Data Science.

Data science and the Stats SE already have a huge overlap (>~80%), and I am worried to have a third SE that also significantly overlaps with them. Personally, it would further demotivate me to write any answer, as it gets tiring to copy-paste content, and updating duplicated answers is a pain.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Thanks for clarifying, Frank. So, if questions regarding Gradient Descent and Monte Carlo search which are one of the most imp. algos. of neural nets and in understanding the Alpha Go bot respectively, I don't really get the scope of the site :(b2A1I9n14a1r18y25_g7l12o15b2e5I personally believe that the (entirely healthy) difference in perspectives on this is indicative of a deeper issue in AI: many areas that were historically AI but are now claimed to be 'solved problems' are in fact not. See my answer to the question about OCR on the main site for more on this. One way of clarifying the scope of this site might usefully be *any* area where heuristics are still required - this would avoid artificial demarcations by technique.b2A1I9n14a1r18y25_g7l12o15b2e5"Programming, algorithm, modeling, math, philosophy, and history questions should the off-topic, as they are already on-topic in other SE" So... what's left for us? I'm yet to to see a question about AI that is NOT on-topic on ANY other SE site.


















Personally, I consider gradient descent something akin to what something like differential equations is to physics - a useful piece of mathematics that has a large array of applications, but not really an AI topic by itself.



When we talk about AI, there are different levels of detail and "technicalness" we can go into and I believe it's necessary to draw the line somewhere.

To illustrate what I mean, let me use the example of self-driving cars:


There's the concept of the self-driving car itself
The car has some sort of computer-vision system
That system might involve a neural network
That network needs to be trained somehow - there are different algorithms for that
One of the most common ones is backpropagation
Backpropagation often uses gradient descent
Gradient descent is an optimization algorithm
and so on...


We could look at an AI problem at any of those levels. But at some point, it becomes no longer really about AI but rather about mathematics or statistics. And those topics are already covered well by other sites.

Basically, what I believe is that this site should mainly concentrate on the top few lines of that list, and leave the rest to more appropriate venues.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5A nice decomposition, but AI is arguably not so 'top down' in practice. At the lower levels, we often lack good heuristics. This then is an AI problem in it's own right. By all means, let's direct people to other sites when the best solution method is well understood, but let's not prevent discussion of a gamut of AI alternatives. Restricting the site to a top level 'systems' view would preclude discussion of some open research issues which might best not be pigeonholed as 'about mathematics or statistics'.b2A1I9n14a1r18y25_g7l12o15b2e5@InquisitiveLurker Since you've explained technologies behind self-driving cars, you may want to answer this question: [What technologies are needed for a self-driving car?](http://ai.stackexchange.com/q/1592/8)


















So, can someone help me understand what the scope of the site is?

https://ai.stackexchange.com/q/1358/101I ask a question about Monte Carlo search, which is one of the core algorithms behind the Go playing AI bot, AlphaGo, and it is closed off as off-topic, citing this reason This question does not appear to be about artificial intelligence.

So, my question is: Why isn't it about AI? Isn't AlphaGo an AI bot? Why does asking about an AI algorithm of an AI bot make it off-topic?

Can someone(maybe one of the close-voters) take the example of AlphaGo and explain what an on-topic question and an off-topic question(<-- You can use mine if you want to.) would look like?

https://ai.meta.stackexchange.com/q/1091/101I already asked a question about the scope of this site, citing another example, where I'm yet to get a clear answer.

If all the questions get closed as on-topic in DS and CV, then why do we even have this site? (Sorry if I sound rude, but I really want this site to grow. So, the early we sought out our scope, the better.)
b2A1I9n14a1r18y25_g7l12o15b2e5Do we really have a scope or not?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I respectfully suggest that we should be doing more to get a handle on this. In the short term, we will lose interested posters, in the longer term potentially the entire undertaking. I'm finding it difficult to see where the necessity for such strict demarcations actually arises. If it's possible to take a useful AI-based perspective on any question, what's the big deal? Attempting to restrict this site to the 'top levels' of AGI won't leave anything meaningful to talk about.


















I was one of the close voters.

First up, the close message you see is the generic off-topic message - we only get one reason under the "off-topic" branch of the close dialogs because we currently have no moderators to create and approve off-topic reasons. Therefore, anything deemed off-topic will get that one message. It's not that your question wasn't about AI, it wasn't about AI as defined in the help center (or, again, since we have no moderators yet, as defined on meta).

Your question, in my understanding, is about specific algorithms and how they work. We're not really into the math/statistics/implementation on this site, because those are already well covered by existing places.

I think that the question could be reopened if it was adjusted to ask something like "Why is Alpha Go's approach more appropriate for games than existing technologies?" Then the question wouldn't be about a specific algorithm, but answers could still dive in if they wanted.

As for whether we have a scope, we're still working on that, as evidenced by our abundance of meta posts about topicality! I think we do have at least some sketches of what should by on- and off-topic, though.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Monte Carlo search **is a heuristic search algorithm**. So, it is clearly an AI algorithm. So, why is asking about an AI algo. off-topic in an AI site?b2A1I9n14a1r18y25_g7l12o15b2e5@Dawny33 This AI site [isn't about algorithms and implementation](http://discuss.area51.stackexchange.com/a/24016/136466). (Admittedly, the name is somewhat confusing then.) Those things are covered by existing sites.b2A1I9n14a1r18y25_g7l12o15b2e5The thing is: If we close down all the algorithm-related and stats related posts on the site, close to 60% of the current posts need to be closed down.  And that would definitely lead to a premature death of the site.b2A1I9n14a1r18y25_g7l12o15b2e5@Dawny33 Unfortunately, duplicating existing sites would also result in the site being closed. To survive, we have to show that we bring something new.b2A1I9n14a1r18y25_g7l12o15b2e5We've continued this discussion in [chat](http://chat.stackexchange.com/rooms/43371/artificial-intelligence). Pl go through it for further context :)  cc @BenN


















The initial scope on http://area51.stackexchange.com/proposals/93481/artificial-intelligenceArea 51 proposal was:


  Conceptual questions about life and challenges in a world where "cognitive" functions can be mimicked in purely digital environment.


Of course this isn't a strict rule, because the final scope is defined by community based on the questions being asked, so if you have any great question related to AI, please ask. So after some time this site can find a distinct and unique scope in comparison to other existing http://stackexchange.com/sites#science-questionsperdaynetwork sites.

However please note that the questions about https://stackoverflow.com/programming, https://ai.meta.stackexchange.com/q/71/8algorithms, https://stats.stackexchange.com/questions/tagged/machine-learningimplementation and https://datascience.stackexchange.com/questions/tagged/machine-learningdata modelling are already on-topic on the other dedicated sites and are likely to be off-topic here in order to avoid https://ai.meta.stackexchange.com/q/4/8huge overlap.



Basically the scope is still about artificial intelligence, but coming from the technical background, asking the right question could be challenging (because we've already a lot of sites dedicated to different aspects of AI). You can think about it like https://softwareengineering.stackexchange.com/Programmers SE site, but without asking actual programming questions.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5"questions about programming, algorithms, implementation and data modelling can be asked on other sites".
Here's a potential issue with that: even if the *questions* don't feature such things, the answers almost will certainly have to, otherwise there's really not so much to say. AI is cross-disciplinary, and hence necessarily cross-site - let's embrace that, rather than create too much a stick to beat posters (and ourselves) with.b2A1I9n14a1r18y25_g7l12o15b2e5Updated post to be less strict, let me know if that helps.b2A1I9n14a1r18y25_g7l12o15b2e5that's very accommodating of you, but it still doesn't work for me personally. That said, I'd rather see consensus than "have my own way". To take the specific restriction at the top of your post, it just seems highly likely to me that people who hear that Monte Carlo Tree Search is used in *insert latest AI news story* will be coming to AI SE first, only to be sent to a less AI-focused site.

I should add the rider that I very much respect the effort that people have put in to get the site this far. I hope we can find something that both suits everyone and actually works.b2A1I9n14a1r18y25_g7l12o15b2e5For me this doesn't work either, so we can hope it's going to be changed.b2A1I9n14a1r18y25_g7l12o15b2e5"...questions about programming, algorithms, implementation and data modelling are already on-topic on the other dedicated sites and are likely to be off-topic here in order to avoid huge overlap...." That might mean that the niche becomes very small if the scope is defined as everything AI - everything AI already included somewhere else. While it increases focus it decreases the total size and means considerable work closing questions when askers miss the fine points. A criticial mass might not be reached. Just want to point out the disadvantages of this approach, next to the advantages.b2A1I9n14a1r18y25_g7l12o15b2e5Thats a very stupid scope to be blunt: No AI experts are going to be drawn to this scope, it's essentially only useful for the worldbuilding audience, which already has a popular SE site. If this is going to be called AI SE, it needs to be a place attractive to actual AI experts in the field, not just science fiction enthusiasts speculating about challenges of a world with AI. Questions about fundamental AI design needs to be on-topic. Not programming questions. Just structural, fundamental design questions.


















Add bounties.

What else can you do? Adding bounties to questions puts them in a special category on the front page. If you want, you could even have two users who 'bounce' a bounty to each other on  few questions, to make sure that they stay there in the 'featured' tab.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5"If you want, you could even have two users who 'bounce' a bounty to each other on few questions, to make sure that they stay there in the 'featured' tab." – I'm quite sure that is considered abuse of the bounty system.b2A1I9n14a1r18y25_g7l12o15b2e5@wythagoras some top users did it on meta. And it's not *creating* extra rep, it's just bouncing.


















As you point out, it is a copy-paste without attribution, which is a https://ai.stackexchange.com/help/licensingviolation of the Stack Exchange rules.

So it should be flagged, using a custom moderator flag to explain the situation.

I have raised that flag.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I have already flagged it.b2A1I9n14a1r18y25_g7l12o15b2e5@VishnuJK Good! That's all we need to do. I flagged it  after I saw your comment yesterday. It may take a while before the flag gets handled, because currently our only moderators are SE employees. This will get better after we have some more moderators (during/after public beta).


















I think we should have first the list of questions which are off-topic here, and on-topic there. If we've enough number of them, the migration target probably can be added later on. For now you can flag each question for moderation, so it can be migrated manually when accepted.

However as far as I've checked, there are only 73 questions tagged with https://stats.stackexchange.com/questions/tagged/artificial-intelligenceartificial-intelligence on Stat.SE where 1/3 of them are still unanswered (24), so I believe some questions about artificial intelligence probably are better suited here. Unless they're specifically related to https://stats.stackexchange.com/questions/tagged/machine-learningmachine-learning where, again, 40% of them are unanswered which make us think where they really belong.

On the other hand, using/programming/implementing AI, at the same time doesn't make me expert on statistics aka cross-validation/rotation estimation model, which to be honest, I don't know nothing about.

And it's not only me:


  statistical learning is not the path to AI (Artificial Intelligence)


Source: https://www.quora.com/I-once-heard-statistical-learning-is-not-the-path-to-AI-Artificial-Intelligence-what-are-the-arguments-that-support-this-statement-claimQuora.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5"1/3 of them are still unanswered (24), so I believe some questions about artificial intelligence probably are better suited here" -> unfortunately ~60% of all questions on CV are unanswered, so that doesn't mean that AI isn't ok there, just that we need more experts on CV.b2A1I9n14a1r18y25_g7l12o15b2e5The main idea behind add CV as a migration target would be to have more understandable closure flags.


















Plagiarism is unethical, IMHO: if you're providing a link to a source, it's more than enough. But if you want to provide a cite, then it must be referenced and marked up in appropriate manner
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Links can die, it's better to copy if the license allows it.


















Should the following question based on this http://arstechnica.co.uk/security/2016/02/the-nsas-skynet-program-may-be-killing-thousands-of-innocent-people/article be on-topic or not?


Is it true that NSA's Skynet AI program killed thousands of innocent people?


And why?
b2A1I9n14a1r18y25_g7l12o15b2e5Is asking whether an article's claims are trustworthy on-topic?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5That would be on topic over on Skeptics, though :-)


















I think the tags are different. Let me explain with an example:

definitions: What is a deep neural network?

Terminology: Would this (< Insert some tech. behind some AI product/bot >) be a deep neural network or a RNN?
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5What about this [question](http://ai.stackexchange.com/q/1515/8), which one it is?b2A1I9n14a1r18y25_g7l12o15b2e5@kenorb It's asking about differences, so it's `definition`. If it talked about some algorithm, and asked to name/identify it, then it'd be `terminology` :)


















Can I ask questions that were asked on the closed site as my own? What if I give attribution?
b2A1I9n14a1r18y25_g7l12o15b2e5Can I steal a question from a closed site?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I was checking the old dumps some time ago, but at the first look I haven't seen some good candidates. So it's great you've found some.


















A lot of questions are still focused on the technology part of Artificial Intelligence. However, a lot of those questions might fit better on stats.SE, or Data Science.SE. So what is left for this site?

The answer is that there is more than enough left for this site, we just have to explore it. In the past week, over 40 papers tagged Artificial Intelligence have been posted on http://arxiv.org/list/cs.AI/recentarXiv. I am sure there are a lot of papers there where we can ask good questions about, that are not on topic on stats.SE or Data.SE. So explore arXiv and ask good questions!
b2A1I9n14a1r18y25_g7l12o15b2e5Where can we find the science part of Artificial Intelligence?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5How many of these 40 papers match the scope of [cs.SE]? (My guess: most of those that don't fit [stats.SE], [datascience.SE] or [SO].)b2A1I9n14a1r18y25_g7l12o15b2e5@Raphael Some of them do. You are more familiar with the Computer Science site than I am, so you probably know what kind of AI questions are asked there.b2A1I9n14a1r18y25_g7l12o15b2e5Unfortunately, I have little expertise in AI of any flavor. You can probably make more sense of [our list](http://cs.stackexchange.com/questions/tagged/artificial-intelligence). We don't get too many AI questions, but I think most material that would be published in CS or mathematical journals would be ontopic. Plus, my opinion on what constitutes CS is not necessarily that of a majority; many papers published in CS journals are not CS in my eyes, e.g. such that (only) present or use pieces of software.


















I'm of the opinion that we should allow ML and AI research-style questions here, of the sort that would also could be on-topic at Cross Validated but would be less likely to hit their intended audience there than they would here.

That is, I don't think there is a difference in topics so much as there is a difference between clusters of people who care about those topics, and the perspectives that they bring and the sort of questions and answers that they'll consider interestingly on-topic. 
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I think the comment on 'perspective' nails it.


















It's a tricky question.
This is NOT a site review, but a personal observation having followed this subject on the network for some time.
I think we've done a better job at scoping out something fundamentally more useful as a site. The formative question is whether we have a suitable audience to actually build out this space. But that has to happen here and now; they won't just show up later.
Stack Exchange is billed as a network of practitioners helping their peers solve everyday problems. Unfortunately, a large percentage of the questions being asked here sit squarely in the curiosity-seekers space. Questions mostly wallow conspicuously in played-out subjects which "real" AI researches have stopped asking a long ago — Is this AI? What does concept mean? When are we going to get there? When is AI going to do {x}?
I won't pass judgement on whether we've given up on actually building a peer-review site. I talked about some of this in https://blog.stackoverflow.com/2010/12/no-artificial-intelligence-in-area-51/no artificial intelligence in Area 51.
There are certainly at least a few very knowledgeable people in this community — actual researchers working in this field — but there's a bifurcation of posts from folks with active experience and someone just showing up with whatever they find in a cursory Google search. The problem is that the community either doesn't know the difference, or doesn't care to vote up one over the other. It's hard to fault anyone for trying valiantly to get something going here, but watching something from Wikipedia being voted on with equal alacrity is somewhat… discouraging.
Have we brought something new to the network?
Probably. Questions here don't generally fit elsewhere.
Have we created something useful?
Hard to say; that's a big question for the final review.
Does this a address a peer group prevalent in this space?
That does not seem likely —  If you read https://blog.stackoverflow.com/2010/07/area-51-asking-the-first-questions/Asking the First Questions, I suspect that ship will have sailed by time we reach public beta.
Have we improved the Internet in general?
My suspicion is the lack of true peer review in this space will make most of what is posted here about status quo with what you can already find elsewhere. That is by no means certain; that is just my observation.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5"The problem is that the community either doesn't know the difference, or doesn't care to vote up one over the other." It's probably some of both. It can take an extra shred of effort to figure out which answer is well-researched. Also, it's uncomfortable taking the one-point hit for downvoting an answer, but we need to be doing more of that (cf. entirely copied answers getting upvotes).


















I wanted to ask which method for spamming detection would be more suitable for certain scenario, Naïve Bayes or Artificial Neural Networks, but then I've found 4 sites where https://en.wikipedia.org/wiki/Naive_Bayes_classifierBayes classifiers can be on-topic:


https://stats.stackexchange.com/questions/tagged/naive-bayesStats.SE -> 316 questions (1/3 unanswered),
https://datascience.stackexchange.com/questions/tagged/naive-bayes-classifierDataScience.SE -> 17 questions (4 unanswered)
https://math.stackexchange.com/questions/tagged/naive-bayesMath.SE -> 35 questions (half unanswered),
https://cs.stackexchange.com/questions/tagged/bayesian-statisticsCS.SE -> 13 questions about bayesian statistics (no specific tag for classifiers),
https://cstheory.stackexchange.com/search?q=BayesCSTheory.SE -> 17 results on Bayes word, no tags for it at all.


But then I've found that Wikipedia page for https://en.wikipedia.org/wiki/Naive_Bayes_classifierNaive Bayes classifier says:


  In machine learning, naive Bayes classifiers are ...


It doesn't say in statistics as oppose to https://en.wikipedia.org/wiki/Sampling_(statistics)'sampling' (as example), where we can read:


  In statistics, quality assurance, and survey methodology, sampling is 


It says specifically in machine learning, not statistics, which further more, the machine learning is a sub-field of Artificial Intelligence (as suggested in this http://cs.colby.edu/courses/S15/cs251/LectureNotes/Lecture_15_MLandDMintro_03_09_2015.pdfpaper or https://area51.meta.stackexchange.com/q/9502/61861here):


  Machine learning, a branch of artificial intelligence, is about the construction and study of systems that can learn from data.


To make it more tricky, the https://en.wikipedia.org/wiki/Machine_learningmachine learning is also a subfield of computer science (as per wiki page). But on the other hand I'm not interested discussing math equations which I'm seeing a lot on https://stats.stackexchange.com/q/151179/12989CS.SE, because I'm looking for more practical oriented answers, not theories. Secondly they've not specific tags for these classifiers. I'm also not studying this topic (on academia level), but I'm doing this as a hobby, or more specifically, investigating practical problem solutions in my app stack.

Based on above logic, does it mean asking AI.SE is the most suitable place to ask practical questions about spamming detection using Bayes classifiers?
b2A1I9n14a1r18y25_g7l12o15b2e5Where to ask about Bayes classifiers for spamming detection? How to draw a line between CS and AI?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Your searches are not really accurate, since there are a lot of search results that are about Bayes' theorem, an important theorem on conditional probability, which is hence discussed a lot on stats and math. I am unsure whether Bayes classifiers would be on-topic on math.SE -  it depends on how theoretical and mathematical the question would be. But "Bayes classifier" (between quotes, so only exact matches) still gives 212 results on stats.b2A1I9n14a1r18y25_g7l12o15b2e5It gives 22 questions (31 results) on math.SE, most questions are unanswered. However, none are closed. Data Science also has [a few of them](http://datascience.stackexchange.com/search?q=%22Bayes+classifier%22). It looks like you are more likely to get an answer there than on math.SE.b2A1I9n14a1r18y25_g7l12o15b2e5I've narrowed down the results for Bayes classifiers only.


















I think most questions about Naive Bayes classifier belong on stats.SE or data.SE. 

It is part of data mining and data science, and it is probably on-topic on data.SE. Some examples of posts on data.SE that appear to be similiar to the question you want to ask:


https://datascience.stackexchange.com/questions/1197/how-can-i-classify-text-considering-word-order-instead-of-just-using-a-bag-of-wHow can I classify text considering word order, instead of just using a bag-of-words approach?
https://datascience.stackexchange.com/questions/6464/spam-detection-in-social-media/6466#6466Spam detection in social media. This question uses another method, but Bayes is suggested in an answer.


A question on stats.SE that is similiar: https://stats.stackexchange.com/questions/50765/simple-text-classifier-classification-taking-forever/50792#50792Simple text classifier: classification taking forever?

The point is, a theoretical question about the Naive Bayes classifier will probably belong on stats.SE since it involves probability and statistics. An applied question would probably be better on data.SE. 

Also, your wiki argument is not a really good one, since anyone can add or remove such sentence. Here is one from an other language that start with such sentence:


  En teoría de la probabilidad y minería de datos, un clasificador Bayesiano [...]  (In the theory of probability and data mining, a Bayes classifier [...])

b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Practical in what sense? So implementation attempt of spam filter is Data Science? Isn't science not too strong word for trying to find out about spam detection methods? I'm not studying science, I'm IT guy who wants to know more about available spam detection techniques using AI.b2A1I9n14a1r18y25_g7l12o15b2e5@kenorb The names chosen were probably not the best one, unfortunately. Data Science is a proposal in the Technology category, see http://area51.stackexchange.com/proposals/55053/data-science. On the other hand, this site is in the Science category, see http://area51.stackexchange.com/proposals/93481/artificial-intelligence.


















Upvote only good questions.

Down- and/or close-vote all bad questions.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5This does not answer the question. The question is how to *bring extra attention* to the best questions.b2A1I9n14a1r18y25_g7l12o15b2e5I think it does, since the SE platform works off of votes (and bounties). In my experiencing, mediocre questions can become upvoted and downvotes rarely happen, thus leaving the field very even. More accentuated voting helps with that.


















You can see that http://area51.stackexchange.com/proposals/93481?phase=commitmenthere. However, most of the questions here feel rather more on the technological side of artificial intelligence. Those questions are on-topic on Data Science. That site was created as a site for the technological aspect of machine learning and AI, and that is the site that is in the Technology category (see http://area51.stackexchange.com/proposals/55053?phase=betahere), in spite of having "Science" in its name.
This was already emphasized by Robert Cartaino on https://area51.meta.stackexchange.com/questions/24014/will-machine-learning-be-considered-as-on-topicArea 51:

Data Science is an applied site for all the programmers/statisticians/mathematicians who are trying to make this stuff work. [...]
Notice that this proposal is in the 'Science' category; not 'Technology'.  [...]
It was convincing enough to give this site another try, but if this site were to simply start reiterating the implementation/tools questions that are already covered elsewhere, this site will not likely make it out of private beta.


I already tried to give a hint where we could find science questions here:
https://ai.meta.stackexchange.com/questions/1126/where-can-we-find-the-science-part-of-artificial-intelligenceWhere can we find the science part of Artificial Intelligence? That is one thing we could do: ask more science questions. The other thing we can do, is closing questions. Please do close questions that are highly technological or asking for applications.

I'd like to link some questions that are, in my opinion (but I could be wrong), scientifical :

https://ai.stackexchange.com/questions/92/how-is-it-possible-that-deep-neural-networks-are-so-easily-fooledHow is it possible that deep neural networks are so easily fooled?
https://ai.stackexchange.com/questions/74/what-is-the-difference-between-strong-ai-and-weak-aiWhat is the difference between strong-AI and weak-AI?
https://ai.stackexchange.com/questions/148/what-limits-if-any-does-the-halting-problem-put-on-artificial-intelligenceWhat limits, if any, does the halting problem put on Artificial Intelligence?
https://ai.stackexchange.com/questions/1397/are-there-any-ai-that-have-passed-the-mist-test-so-farAre there any AI that have passed the MIST test so far?
https://ai.stackexchange.com/questions/1451/has-the-lovelace-test-2-0-been-successfully-used-in-an-academic-settingHas the Lovelace Test 2.0 been successfully used in an academic setting?
https://ai.stackexchange.com/questions/123/does-the-chinese-room-argument-hold-against-aiDoes the Chinese Room argument hold against AI?
https://ai.stackexchange.com/questions/1479/do-scientists-know-what-is-happening-inside-artificial-neural-networksDo scientists know what is happening inside artificial neural networks?
https://ai.stackexchange.com/questions/1525/could-a-boltzmann-machine-store-more-patterns-than-a-hopfield-netCould a Boltzmann machine store more patterns than a Hopfield net?

There are more questions around that are scientifical and high-quality (fortunately), I just picked a few from the first page of the highest voted list.
b2A1I9n14a1r18y25_g7l12o15b2e5A friendly reminder that this site comes from the Science categoryb2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Maybe, just maybe Data Science and Artificial Intelligence should fuse. That way we would not need to worry about where a more theoretical/practical question belongs.


















Also a friendly reminder that our https://ai.stackexchange.com/tourtour page (also http://area51.stackexchange.com/proposals/93481/artificial-intelligenceproposal) states:


  A question and answer site for people interested in conceptual questions about life and challenges in a world where "cognitive" functions can be mimicked in purely digital environment. It's built and run by you.


So I don't see the reason why both kind of questions can be on-topic, conceptual and scientific or similar, otherwise we're limiting without any good reason.

Also please remember that it's run by us, so everybody can decide whether question should be on-topic by voting on it.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Yes, conceptual questions are also on-topic. This are questions like http://ai.stackexchange.com/questions/17/what-is-the-concept-of-the-technological-singularity and http://ai.stackexchange.com/questions/10/what-is-fuzzy-logic, asking to explain the concept of Technological Singularity and Fuzzy logic respectively. But we must be careful that it is a concept related to AI and not to much form the machine learning side.b2A1I9n14a1r18y25_g7l12o15b2e5Machine learning is a branch of AI, so it should be automatically included as well.b2A1I9n14a1r18y25_g7l12o15b2e5Please see [Will machine learning be considered as on-topic](http://discuss.area51.stackexchange.com/questions/24014/will-machine-learning-be-considered-as-on-topic) on Area 51.b2A1I9n14a1r18y25_g7l12o15b2e5'machine learning as far as implementation goes', so it's more about implementation being off-topic, not exactly 'machine learning'. Secondly the scope can be clarified/defined by community, as per comment on that post: 'Everything in the proposal is considered when evaluating whether the site would likely be viable.'.b2A1I9n14a1r18y25_g7l12o15b2e5`I don't see why both kind of questions can't be on-topic` Because the OPPOSITION against creating this site argued (correctly) that we already created sites to handle this subject explicitly. The argument FOR creating this site claimed that we have a missing socio-scientific angle that needed filling. **Private beta tests if that is a valid premise for creating a NEW site.** If the founding community does not live up to those expectations, it creates a strong argument for "I told you so" — that the initiative has failed. **Stick to the mission;** don't give credence to arguments for closure.


















Clearly, https://stats.stackexchange.com/Cross Validated is about statistics - it's even in the URL, stats.stackexchange.com. They're a very math-heavy and calculation-oriented site. MathJax is enabled there, and every question I scanned from their front page involves code or mathematical formulae. https://ai.stackexchange.com/questions/tagged/machine-learningmachine-learning is their third most popular tag at the moment, and https://stats.stackexchange.com/questions/tagged/machine-learningquestions in it are about the stats/math involved in machine learning.

Questions here are not expected to involve that level of detail. MathJax is not enabled here, and that https://ai.meta.stackexchange.com/q/35/75might be purposeful. Our questions should be about the https://area51.meta.stackexchange.com/a/24016/136466science - not so much the technology or math or implementation of - artificial intelligence. (For machine learning implementation, see https://datascience.stackexchange.com/Data Science.)
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5MathJax probably *should* be enabled here.  If you say we're about "the science of AI", you are pretty limited in talking about (real) science without using math.b2A1I9n14a1r18y25_g7l12o15b2e5@mindcrime I added a link to the discussion about MathJax formatting support.b2A1I9n14a1r18y25_g7l12o15b2e5I wonder how to make science without math? As soon as you want to quantify something you'll need it? So could you maybe elaborate a bit more on what you mean by "the science - not so much math - of artificial intelligence"? What is the science of AI?b2A1I9n14a1r18y25_g7l12o15b2e5@Trilarion That's a really good point, and the more I think about it, the more I feel that we need a better way to describe our scope. I encourage you to help us by participating in [this other meta discussion](http://meta.ai.stackexchange.com/q/1197/75)!


















I've seen this argument come up https://ai.meta.stackexchange.com/a/1142/95here and several times in other discussions about scope:


  I don't see why both kinds of questions can't be on-topic


It's because the OPPOSITION against creating this site argued (correctly) that we already created sites to handle this subject explicitly. The argument FOR creating this site claimed that we have a missing socio-scientific angle that needed filling. 

Private beta tests if that is a valid premise for creating a NEW site. 

If the founding community does not live up to those expectations, it creates a strong argument for "I told you so" — that the initiative has failed. 

Stick to the mission. 

Don't give credence to arguments for closure.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5It's possible that questions can be ontopic on several SE sites in which case the asker can usually choose to ask wherever he likes. A bit of overlap in the scope of stackexchanges is okay, but I agree that Artificial Intelligence should clearly find it's niche and also define the limits. It just seems quite difficult to clearly define the limit between concepts and implementations (so pseudocode is okay, but any actual used language not?).


















Sure I have an image myself:

https://i.stack.imgur.com/awUym.png

It is fairly easy and with high to recognition value. It has like everything to do with AI and is a discussion topic for https://duckduckgo.com/?q=hal+9000+costume&t=canonical&iax=1&ia=imagesevery party :)
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5This is the scientifically correct answer, all other answers are void.


















I was one of the close voters, and let me explain here why I voted to close. 

As I, and some other users, have said multiple times before, we should avoid questions that are only related to machine learning. Those questions are already on-topic on both Data Science and Cross Validated. 

The point of creating this site was filling a gap that was not already covered by Data Science and Cross Validated. Early stopping is on-topic on both sites (https://stats.stackexchange.com/search?q=early+stopping1, https://datascience.stackexchange.com/search?q=early+stopping2). Remember that if this site looks to much like Data Science and/or Cross Validated it will most likely not get out of private beta.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Question being on-topic on the other sites, doesn't make it automatically off-topic here. ['Different sites are different communities with different norms.'](http://meta.stackexchange.com/a/90514/191655). I still believe it's about AI, and closing it only, because it's on-topic somewhere, doesn't make any sense.


















After 10 days, the metrics on Area 51 seem to indicate that the site is doing well, except for the lack of users ("experts") and visits.


16.2 questions per day (10 questions per day is healthy, 5 questions need works)
85% answered (90% is healthy, 80% need works)
1.7 answers per questions (2.5 is healthy, 1 needs works)
108 visits/per day (1500 is healthy, 500 need works)
25 users with 200+ rep (250 users is healthy)


Yet, it doesn't seem as though the site is actually healthy, as the question https://ai.meta.stackexchange.com/questions/1122/have-we-brought-something-new-to-the-networkHave we brought something new to the network?, suggests. It seems that there is a high chance of closure, despite the stats supposedly being on our side.

However, interest in AI is not going away. It hasn't gone away the last time an AI StackExchange was proposed and shut down. We still need to deal with the humanities aspect of this field...and to help try to "demystify" the field of artificial intelligence. Until we get a good answer to this problem of dealing with artificial intelligence in a unified manner, all that's going to happen is a fourth AI proposal.

Now, technically, there are many sites that can handle AI questions. I mentioned about them in https://area51.meta.stackexchange.com/a/23515/152111this Area51 post, and how a programmer could build an AI simply by cobbling together answers from multiple StackExchange sites. I also stated that the de facto solution to the AI problem is a very problematic one:


  The AI programmer is stuck traveling from one site to another (though Google is helping out), asking questions on each individual site, to try and figure out how to accomplish his single goal. This AI programmer is a migratory beast, out to stitch together random answers on Stack Exchange into a coherent 'whole' that he can then use. ... Is it sensible for AI programmers to be dependent on 6 to 8 different sites, at any given time? Is it sensible for these 6 to 8 sites to pander to these AI programmers instead of answering other questions? Or is it better to instead consolidate AI-specific questions from these 6 to 8 different sites, onto a single site that is easy to browse and look up? Some overlap between the communities may be inevitable, but it's better than the current status quo.


This idea has been https://area51.meta.stackexchange.com/a/25180/152111resurrected by by kenorb recently very recently:


  If it fails, the backup is to have 20 different accounts and ask the AI questions across the different sites such as Stats.SE, CSTheory.SE, CogSci.SE, Philosophy.SE, Worldbuilding.SE, SO.SE, CS.SE, HSM.SE, Robotics.SE, GameDev.SE, with no real AI experts focused in one place.


I have built http://stackai.herokuapp.com"StackAI", a StackExchange aggregator of several AI-related StackExchange sites which I may plan on upgrading in the future to include other AI-related StackExchange sites (such as CogSci, Robotics, etc.). But I'm still dubious on whether this site would indeed be the best solution for our crisis. It's a good one-stop directory to help a migratory questioner know where they can ask their questions, but the process is still rather inefficient and we lack the consolidation that a standard AI site could provide for us...and, of course, I doubt that these other sites would even appreciate the influx of these migratory questioners.

Is there a better way to deal with the migratory AI questioner? Even if it is to just improve StackAI?

I get discouraged and cynical rather easily, so maybe I'm being overly pessimistic about this site. But I do care about helping out people, and will want to help them out, even if "ai.stackexchange.com" dies again.
b2A1I9n14a1r18y25_g7l12o15b2e5If this site closes, what should we do to help migratory AI questioners?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Despite what other think, I believe most of the questions would be actually off-topic on other sites (because they're not so technically oriented for these specific sites like stats or data science), so migration probably won't happen, maybe just few of them. So they're likely to be just exported and dumped into zip file and forgotten as the previous AI dumps.


















I think it's too early to worry about what to do if the site closes. We're different from previous AI sites in a couple important ways, and though we're not completely free of issues, we're making progress. For what it's worth, the target statistics on Area 51 are what you should expect from a site about to fully graduate (not one about to continue into public beta).

Without this site, the topic of artificial intelligence is indeed split across the network. Fortunately, each site's scope is fairly well-defined, so even if finding a good site is tricky, checking whether a question is OK for a given site is quite doable. https://meta.stackexchange.com/Meta Stack Exchange can help find a good home for questions - they even have https://meta.stackexchange.com/questions/tagged/site-recommendationa tag for such inquiries, and I think a question for routing people to the right AI site would be in order.

Again, don't get too worried. We'll cross that bridge if we come to it.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Additionally, there is now less pressure on a site to 'avoid closure' - as long as we are continuing to have questions and answers, and the community is stable or growing, public beta can now be effectively permanent.


















Each time when I log in to the site, it shows there are some unread review items (4, sometimes 5), but most of the time there are always none (all zeros) when clicking.


  4 total posts awaiting review


I believe the cache is too aggressive or something, as I didn't see this much on other sites. I've checked in incognito mode (without cookies) and it's the same thing.

https://i.stack.imgur.com/mzd2Om.png

Anybody else has the same issue?
b2A1I9n14a1r18y25_g7l12o15b2e5Caching too aggressive showing unread total posts awaiting review which are not thereb2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5http://meta.stackexchange.com/questions/233535/review-counts-in-top-bar-and-review-dont-match


















As mentioned in https://meta.stackexchange.com/a/233536/295684the MSE question linked in the comments, that indicator isn't calculated just for you. When you gain the "access moderator tools" privilege - 10K on graduated sites, 2K in public beta, 1K in private beta - you always see the total number of reviews pending for anyone. That is, even if the queues look empty to you (i.e. you reviewed each item already), that number is how many items are still awaiting consensus from the community.

Users with the edit privilege - 2K on graduated sites, 1K in public beta, 500 in private beta - but not the tools privilege will only see the number of items pending for them in the Suggested Edits queue.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Just a note: Privilege levels also change when going form private beta to public beta. I clarified for now that it is about a private beta, but you might want to add the public beta thresholds.b2A1I9n14a1r18y25_g7l12o15b2e5@wythagoras Thanks, I've added in the correct public beta figures from [this MSE FAQ](http://meta.stackexchange.com/a/160292/295684).b2A1I9n14a1r18y25_g7l12o15b2e5In short, it is "by design" that when you hit the moderator-tools reputation level, the review counter becomes useless.


















https://ai.stackexchange.com/users/42

https://ai.meta.stackexchange.com/users/42




Notes:

Currently most voted and dedicated user with the relevant knowledge and skills about AI. In addition, he's working in this research area, so he knows what he's talking about. His skills may help to improve quality of this site.

EDIT by NietzscheanAI (formerly known as user217281728): 
Most kind, thanks. I'm happy to accept this nomination and want to work to make this a informative and useful site. I live in the UK, so tend to be active on the site between 07.00 and 23.00 GMT. My varied career has included games software company owner, generative music developer, software architect, pure mathematician and (for the last 13 years) AI researcher.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Wow, 64 answers (and counting, hopefully). We have a topic expert right here.b2A1I9n14a1r18y25_g7l12o15b2e5I edited the nomination to include the nominee's network-wide flair.b2A1I9n14a1r18y25_g7l12o15b2e5@user217281728 Are you from London?b2A1I9n14a1r18y25_g7l12o15b2e5@kenorb No, I'm not.b2A1I9n14a1r18y25_g7l12o15b2e5@user217281728 Get a fancier username maybe?b2A1I9n14a1r18y25_g7l12o15b2e5@Rahul2001 - better?b2A1I9n14a1r18y25_g7l12o15b2e5@NietzscheanAI YES!b2A1I9n14a1r18y25_g7l12o15b2e5'e' constant was fancier I think:)b2A1I9n14a1r18y25_g7l12o15b2e5@NietzscheanAI just a note: I'm glad you're not a randomly anonymous who-knows-what-he-is-doing AI enthusiast from Russia or whatever :) I mean, because of the lack of information on your profile, sometimes I was playing with such thoughts, but of course it was not a serious issue, but rather some joke in my head.b2A1I9n14a1r18y25_g7l12o15b2e5Dear NietzscheanAI, considering the votes, I think we can welcome you in the mod club. As you finally get the diamond, please don't forget: as the site matures and grows older, its standards and customs tend to differ more and more from the common sense, and it results a growing ratio of disappointed newbies, leaving the site after their closed first questions. Please pay attention for that! Many SE sites has fallen already in this trap. Thanks!b2A1I9n14a1r18y25_g7l12o15b2e5@peterh - I'm not an enthusiastic closer of questions.


















https://ai.stackexchange.com/users/75

https://ai.meta.stackexchange.com/users/75

https://stackexchange.com/users/3364317/ben-n


Notes:

This nominee would be a good choice because of his active involvement in the community's development during the private beta and his experience on Stack Exchange!

I'll step right up and offer my services to the community as a moderator pro tempore. I confess that I'm just an enthusiast when it comes to artificial intelligence, but I have been highly active here on meta, gaining the community's first silver badge: https://ai.stackexchange.com/help/badges/68/conventionConvention. I thoroughly enjoy reviewing and I have been working the queues since the site's beginning. I've also spent a large (probably unhealthy, heh) amount of time reading Meta Stack Exchange and the SE blogs, so I'm familiar with the Stack Exchange model, the software, and the expectations for the various roles. I'm also active on https://meta.superuser.com/users/380318/ben-n?tab=topactivityMeta Super User, for what it's worth.

I live in Illinois (midwestern United States), so I'm usually awake from UTC 15:00 to 3:00. You can read about the things I've created in my profile. I have a blog https://fleexlab.blogspot.com/2016/08/ai-stack-exchange-site.htmlon which I mentioned the site a while back.

I've been doing what I can to make sure this site survives, and that has required casting a few close votes. Hopefully I haven't come off as too much of a maniacal ruthless reviewer :). When asked on meta, in comments, or in http://chat.stackexchange.com/rooms/43371/artificial-intelligencechat about why a question is closed, I always write up a helpful, respectful explanation. If I ever do something you think is less than ideal, please feel free to ask me about it! Like all humans (though perhaps not AIs!) I make the occasional mistake, and when I see that's happened, I make it right.

I have my own opinions and judgments, of course, but I would be happy to carry out as moderator pro tempore the consensus of the community, the mod team, and Stack Exchange. We're all in this together.

It's a pleasure building this community with everyone here. I look forward to continuing to the next stage of site growth with y'all!
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Full disclosure: it looks like one of the people from Super User's Root Access chat room joined the site and only upvoted this. I had linked the site's Area 51 proposal to drum up traffic for the site, not votes for myself. I apologize for the slight score inflation. On the plus side, we do have a handful of new users from SU looking around our main!b2A1I9n14a1r18y25_g7l12o15b2e5^ That comment alone speaks volumes. Diamond this man. (Also active on main meta, which is worth having in a mod.)b2A1I9n14a1r18y25_g7l12o15b2e5Would you mind cleaning up this thread to fix the broken flairs? (I don't have edit privs, and you're like the only one I know still hangs out on Meta...)


















https://ai.stackexchange.com/users/10

https://ai.meta.stackexchange.com/users/10

https://stackexchange.com/users/555192


Notes:

The second most voted and active user, data scientist with the right skillset across different AI branches. His answers are reliable and interesting. His skills can be a great asset to improve quality of this site.

EDIT by Matthew Graves: Thanks for the nomination! I'm pleased to accept it. I'm interested in helping this site help people better understand AI and the issues surrounding it, both through direct effort and community building. I've been clearing out review queues here as soon as I got access to them, and that's typically the first thing I check after my comment inbox. 

I'm currently in Austin, Texas, and so would typically be online from to about noon to 2am UTC. I've been doing machine-learning related work for, depending on how you count it, about 8 years now, mostly as a student but now also as a data scientist. My research effort has mostly been in numerical optimization, machine reliability, and time series analysis, rounded out by my personal interests in psychology, economics, and philosophy. I've been interested in intelligence for as long as I can remember, and that grew to encompass artificial intelligence as soon as I was introduced to it.

To a large degree I 'grew up on the internet'; forum-posting has been a major hobby for over half of my life at this point. I've consistently had a reputation for being polite, calm, and open-minded; qualities that I hope would serve me well as a moderator.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I edited the nomination to include the nominee's network-wide flair.


















I'll volunteer myself.

https://ai.stackexchange.com/users/33/

https://ai.meta.stackexchange.com/users/33/

https://stackexchange.com/users/48222/


Notes:

This nominee would be a good choice because - he is passionate about AI and its potential applications for improving the human condition.  This nominee is also a strong supporter of open exchange of scientific knowledge and technology, as expressed in the Open Source, Open Web, Open Data, Open Science and Open Hardware initiatives.   This nominee has been participating in multiple Stack Exchange communities for many years.   

You could consider this nominee to be the "ruthless NON closer" as he believes that closing questions is generally harmful to the community, as it is perceived as an aggressive and hostile act by whoever posted the question.  This nominee believes that "bad" questions can simply be down-voted and allowed to die from lack of activity in almost all cases.

This nominee believes we can strike a balance between being "beginner friendly" and still keeping things interesting enough to attract experts, but believes that it will take some time to establish our presence in the AI world and attract the high-level researchers and others of that ilk.  



Since I volunteered myself, it should go without saying that I accept this nomination.

Hi, I am Phillip. I live in Chapel Hill, NC, so I am generally active on this site from around 10:00am through 1:00am Eastern time. Some other things you may want to know about me are: I am founder / president at https://www.fogbeam.comFogbeam Labs, an open source software company.  I was a volunteer firefighter for many years and was Assistant Fire Chief of my department for the last couple of years I was there.  

I am the founder/organizer of the Research Triangle Park "Semantic Web / Artificial Intelligence / Machine Learning" Meetup here in the Raleigh/Durham area.  I'm also active on http://mindcrime.github.ioGithub and https://news.ycombinator.com/user?id=mindcrimeHacker News.  
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I edited the nomination to include your meta flair, and make the flair actually match the link it goes to.


















https://ai.stackexchange.com/users/5

https://ai.meta.stackexchange.com/users/5




Notes:

While I'm not the most knowledgeable about AI, and don't have the highest reputation level, I know a lot about moderating.

In the past three days, every single day, I've cleared all the review ques I have access to. I currently own two organizations, and I moderate, or lead, both of them. I have 2 pending proposals on Area51. I'm active on the Stack Exchange sites almost every single day. I have former experience from moderating as a former FPC from Scratch.

It would be an honor to be a moderator on this site.
Thank you for reading.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5" I'm not the most knowledgeable about AI". How much do you know?b2A1I9n14a1r18y25_g7l12o15b2e5@ABcDexter About what? AI is a rather large subject. You could be talking about neural networks, the history/origin of AI, etc.


















https://ai.stackexchange.com/users/8

https://ai.meta.stackexchange.com/users/8

https://stackexchange.com/users/22370


Notes:

This nominee would be a good choice because kenorb is a very active user, a person who knows a lot about AI, and, I feel, cares about helping this community grow. kenorb should be one of our moderators - even if his English isn't perfect, I still think he's perfect mod material. :)



First of all, I would like to thank you for nomination and I am pleased to take the responsibility of being a pro tempore mod. I believe that this site has a unique opportunity to make a huge impact to global technology market driven by artificial intelligence and our everyday life in the very near future by sharing advanced knowledge accessible for all.

I have been using SE for over 7 years, I am experienced across a variety of fields and I am familiar with moderation tools and I understand their purpose.

I am an experienced software engineer specialising in a variety of information technology stacks with over 18 years experience consulting across a range of sectors and multination companies. One of the recent one is planning to http://www.ft.com/cms/s/0/5ea4c668-1364-11e6-91da-096d89bd2173.html#axzz4HXDwufht'to deploy drone army' worldwide which can expand our scope of understanding of artificial intelligence (e.g. imagine flying drones in the restaurant and delivering your food to your table after pressing a single button). Check also my https://stackoverflow.com/cv/kenorbuser CV profile.

My first AI program was a chat bot written over 18 years ago in Pascal with custom written assembler libraries in order to make my school mates believing that they are chatting on IRC with real people, while being on the computers without any internet connection, so other can play games on spare computers with the real network. This worked, for the first 15-30 minutes, later on they could find out that something was wrong or get bored. Second project was involved AI bots protecting IRC channels. I did some AI in games. Since then I am interested in practical applications of AI. This is my long term hobby and interest. Further projects required more sophisticated requirements. Currently I am working on integration AI with the financial algorithms and systems.

I am good team player, so I am able to cooperate with other mods, I'm also available on daily basis (GMT/DST time). I hope we can improve this site by keeping it away from chaos, spam and trolls, to provide high quality site. 
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I edited the nomination to include the nominee's network-wide flair.b2A1I9n14a1r18y25_g7l12o15b2e5I personally think Kenorb is the best one for this. But, the community's response made me scratch my head :(b2A1I9n14a1r18y25_g7l12o15b2e5I could guess that some science people didn't like the general approach of this AI site treating it as a competition hoping it'll fail again in favor of Stats.SE, CS.SE or DataScience.SE, so negativity was expected, therefore I didn't expect to have a lot of fans. I think every success require some conflicts, sacrifices and hard work, so I'm really happy that this site went beta after 6 years of constant failures. I hope this will serve humanity for the next 100+ years to keep up with so much changing world and sharing the advanced knowledge to everyone.b2A1I9n14a1r18y25_g7l12o15b2e5@kenorb I doubt it's because "science people didn't like you". More likely, I'm afraid to say, that the community doesn't think you're mod material.b2A1I9n14a1r18y25_g7l12o15b2e5@ArtOfCode Thanks for your honest opinion:) Any idea about specifics?b2A1I9n14a1r18y25_g7l12o15b2e5@kenorb You had said: `I am >7 year old SE user experienced across variety of fields and I am familiar with moderation tools and understanding their purpose`b2A1I9n14a1r18y25_g7l12o15b2e5@Mithrandir True, my EN is still bad despite few Cambridge-FCE-like certificates (theory != practice), secondly usually I'm in hurry when writing and all the time distracted couple of times, so I had to re-read everything what I wrote couple of times, but even this doesn't help:) But not everybody is so pedantic to the English. So I don't think that's the reason, usually people just doesn't like me, since I tend to draw a lot of controversies whatever I do while pushing the things forward:)b2A1I9n14a1r18y25_g7l12o15b2e5What the hell is with all the downvotes?!b2A1I9n14a1r18y25_g7l12o15b2e5Why the downvotes o.Ob2A1I9n14a1r18y25_g7l12o15b2e5@ABcDexter I honestly don't know.b2A1I9n14a1r18y25_g7l12o15b2e5Yes, if someone doesn't like the nomination, say it openly. One must be honest, just like ArtofCode explained...b2A1I9n14a1r18y25_g7l12o15b2e5@Mithrandir Actually i read everything, but am not sure about anyone. If mod pro tempore is chosen from a set of experts, it would be great ^_^b2A1I9n14a1r18y25_g7l12o15b2e5I have downvoted this nomination because while kenorb seems to claim he has worked for a lot of years in the AI field, his questions and answers on this site appear to be based on very shaky ground and sometimes are borderline cranky. Moreover I have seen kenorb repeatedly use very dubious sources to justify his claims on other SE sites. His line of defence here is "Science people don't like me" which again sounds very cranky.b2A1I9n14a1r18y25_g7l12o15b2e5@Fatalize This is how I work, questioning everything and seeing everything from the different point of view. My approach is to analyse concepts based on my logical conclusions given the available data (that is not by repeating what the mainstream or other says) and I see nothing wrong with it. This is how the real science work, building and organising knowledge, not assuming that a single body-of-knowledge has the ultimate truth. If we would believe in mainstream all the time, we'll still live on the flat Earth. Although the A.I. science is very simple, it's testable and it needs to work.b2A1I9n14a1r18y25_g7l12o15b2e5@kenorb Just visited this site for the first time. Net score was 0, so I upvoted you.b2A1I9n14a1r18y25_g7l12o15b2e5@user1271772 Thanks, appreciate that, now I've got +14 vs -13:) Most of the candidates are no longer active here.b2A1I9n14a1r18y25_g7l12o15b2e5@kenorb I recently discovered that [nbro resigned after being suspended on CrossValidated.SE](https://ai.meta.stackexchange.com/q/1681/19524). If you do run again for election, I would upvote you, as I remember you from Area51 and the Paranormal Factor chat room.


















https://ai.stackexchange.com/users/145

https://ai.meta.stackexchange.com/users/145

https://stackexchange.com/users/5129611



Notes:

I would like to offer my services as a pro-tem moderator on this site. I have watched been a relatively active member since I joined on Day 0. I have 135 edits (counting tag-only edits), I was the first one to earn the https://ai.stackexchange.com/help/badges/12/strunk-whiteStrunk and White badge, I am the top reviewer for both https://ai.stackexchange.com/review/close/statsClose Votes and https://ai.stackexchange.com/review/reopen/statsReopen Votes on the main site, I was the first reviewer of https://ai.stackexchange.com/review/late-answers/statsLate Answers,  and I was the first reviewer on Meta. I have watched Meta, and pitched in when I could.I was also one of 25 users to earn the https://ai.stackexchange.com/help/badges/30/betaBeta badge, which means that I was an active user in the Private Beta. I now also have the https://ai.stackexchange.com/help/badges/68/conventionConvention badge, which means that I've been active here on Meta. I may not know so much about AI, really, but I do know enough to be able to tell if something answers the question or not, I think. :)

Also, I am one of the only users who has ventured onto http://chat.stackexchange.com/rooms/43371/the-singularitychat :P

I am also active on this Meta, the Puzzling Meta, and the main Meta*.

I am fairly well-versed in the content in the Help Center and site policy, as well.

* Okay, I mostly flag things as off-topic. But I have asked/answered some!

About Me

I'm a 14 year-old kid. The only moderation experience I have is being an admin on 3 Wikias. (Not popular ones - little outdated backwater ones. :P) I live in the UTC+2/3 time zone, although I'm often on late.
I don't go to school; I'm homeschooled.
I am not a programmer.
I have been using SE for a year and 11 months, roughly, so I have a pretty good idea about how the site works :P.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5This is how I know this guy: Edited by Mithrandir. I keep seeing it on multiple SE sites.b2A1I9n14a1r18y25_g7l12o15b2e5@CemKalyoncu :P I like editing.b2A1I9n14a1r18y25_g7l12o15b2e5I told ya, someone is [on editing spree](http://chat.stackexchange.com/transcript/37632?m=31055637#31055637) ;Db2A1I9n14a1r18y25_g7l12o15b2e5Yes, but he has it as CM & SE employee. These rules bind his hands: he can't do elected mod tasks, his role is essentially an over-mod exception handler. Being an elected mod, this rules wouldn't bind his hands.


















What would be the difference between brain-simulation and neuromorphic-computing tags?
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I have a word: synonym.b2A1I9n14a1r18y25_g7l12o15b2e5So let's stick with just neuromorphic-computing, right?b2A1I9n14a1r18y25_g7l12o15b2e5Yeah...........


















Yes, it's pointless to have two tags referring to the same thing. Since https://ai.stackexchange.com/questions/tagged/deepqadeepqa had three questions and https://ai.stackexchange.com/questions/tagged/watsonwatson had four (and all but one DeepQA question had the Watson tag already), I manually merged the tags together by removing https://ai.stackexchange.com/questions/tagged/deepqadeepqa.

One could make the argument that DeepQA is the research project while Watson is the product, but all of the questions tagged https://ai.stackexchange.com/questions/tagged/deepqadeepqa were about Watson.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5A synonym was appropriate here, so I added it.b2A1I9n14a1r18y25_g7l12o15b2e5@kenorb That's why I typically wait for community input before I jump in an make a change like that (cc Ben). No harm done. There are relative few questions in play here. Tag/re-tag them as you wish.b2A1I9n14a1r18y25_g7l12o15b2e5Precisely. Though I do see them as different I wouldn't be offended if they were merged, since anyone talking about DeepQA would probably be referencing Watson, and likely would include both the Watson and NLP tags to satisfactory effect. Other non-DeepQA NLP questions would just use the NLP tag. Since DeepQA is only so popular (as far as I know), the slight decrease in precision may be worth the simplicity. To me the deciding factor is how much people care specifically about the DeepQA part of Watson itself, and if that warrants its own tag.b2A1I9n14a1r18y25_g7l12o15b2e5@RobertCartaino Right, normally I wait for consensus before removing a tag. In this specific case, considering the tag's very few questions, the clearly duplicitous way in which it was *used*, and its lack of tag wiki, I figured I'd save everyone some time and blow it away myself :) Thanks for making a synonym, that way future users of [deepqa] will be automatically redirected.b2A1I9n14a1r18y25_g7l12o15b2e5@AvikMohan Yes, there could conceivably be a difference. As the tag had been used, though, they were the same.


















I would be careful to merge the two together. https://ai.stackexchange.com/questions/tagged/deepqadeepqa is very much just that - a deep learning approach to questions and answers. This covers NLP, hypothesis formation, candidate answer generation, and answer selection from the candidates. It is fully limited to that domain. 

These pages show what I'm getting at: 

https://www.research.ibm.com/deepqa/deepqa.shtmlhttps://www.research.ibm.com/deepqa/deepqa.shtml
http://researcher.watson.ibm.com/researcher/view_group_subpage.php?id=2159http://researcher.watson.ibm.com/researcher/view_group_subpage.php?id=2159
http://researcher.watson.ibm.com/researcher/view_group_subpage.php?id=2162http://researcher.watson.ibm.com/researcher/view_group_subpage.php?id=2162
http://researcher.watson.ibm.com/researcher/view_group_subpage.php?id=2160http://researcher.watson.ibm.com/researcher/view_group_subpage.php?id=2160

On the other hand, https://ai.stackexchange.com/questions/tagged/watsonwatson is this titanic over-arching project that dips into culinary arts, healthcare, and more recently education and other topics I'm sure I'm missing. It is the foremost product of IBM's cognitive computing research and has numerous applications and uses, and elements that construct it. It goes well beyond just the QA portion (which is an integral part of Watson, but not the entirety or even nearly a synonym of Watson).

For this reason, I personally think they are certainly different topics, but being new to stack exchange I'm not sure how you would like to handle this.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Thank you, I will add those soon (or feel free to do so yourself)


















AI is broader than Machine Learning and Statistical Learning. Yes, the probabilistic / statistical stuff dominates the conversation these days, but AI includes rule based systems, expert systems, symbolic processing, logic programming and other things that would not be on-topic at Cross Validated (or Data Science).

We've also been saying that we have more of a focus on the philosophy of AI and the humanities related aspects, as opposed to strictly the technology.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Being broader implies somehow that there is overlap. The question is probably how big the overlap is compared to the total scope. It also might be good to have standard migration paths to the overlapping sister sites, because askers will inevitably miss the finer points in distinguishing the scopes.


















Categorizing things in pictures as certain types of objects definitely sounds like https://ai.stackexchange.com/questions/tagged/image-recognitionimage-recognition to me. After all, the computer is supposed to recognize what the thing is and then put them into categories.

Two of the three existing questions in https://ai.stackexchange.com/questions/tagged/computer-visioncomputer-vision don't really seem to be related to computerized image comprehension at all. The last - the question you linked - would, in my opinion, be better served by https://ai.stackexchange.com/questions/tagged/image-recognitionimage-recognition. https://ai.stackexchange.com/questions/tagged/computer-visioncomputer-vision seems more appropriate for questions involving the AI moving around and continually seeing the world and the states of the things in it (like self-driving cars do), which involves more than just figuring out what objects are present.

Since https://ai.stackexchange.com/questions/tagged/visual-searchvisual-search doesn't exist yet, I think we should wait for a compelling distinction between it and https://ai.stackexchange.com/questions/tagged/image-recognitionimage-recognition before creating it.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5The visual-search was applied to the linked question, because it was relating to search using visual data.b2A1I9n14a1r18y25_g7l12o15b2e5Interesting. I don't see it on the question, and the tag says there are no questions tagged with it. (I blame caching.)b2A1I9n14a1r18y25_g7l12o15b2e5I mean it was [edited out](http://ai.stackexchange.com/posts/1687/revisions), so that's why I'm asking whether we should burn this tag.b2A1I9n14a1r18y25_g7l12o15b2e5@kenorb Ah. In the absence of a notable difference between it and [image-recognition], my inclination would be to leave it gone. (I wasn't the one who removed it, though.)b2A1I9n14a1r18y25_g7l12o15b2e5@BenN No, I was. :P And I did leave a comment, saying that I thought that [image-recognition] covered it all. (And since it was a *suggested* edit, kenorb could have rejected it...)b2A1I9n14a1r18y25_g7l12o15b2e5I accepted it, I agree that image-recognition covers that, so no worries, but I wanted to double check whether this tag could be useful for that kind of questions or other. In some studies they use 'visual-search' as a keyword. It indicates you're using image recognition for searching, not only classification.


















https://ai.stackexchange.com/questions/tagged/natural-languagenatural-language should stay. The others - synonymize.

https://ai.stackexchange.com/questions/tagged/natural-languagenatural-language is the most descriptive tag name, as a person who knows fairly close to nothing about AI. If you add the others as synonyms, then everyone will be able to find the right tag. :)
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Tags are not meant to facilitate newbies (AFAIK), but to organise the community.


















https://ai.stackexchange.com/questions/tagged/dnndnn just stands for deep neural network, which we already have a tag for: https://ai.stackexchange.com/questions/tagged/deep-networkdeep-network. Can we just synonymize these?
b2A1I9n14a1r18y25_g7l12o15b2e5Make [dnn] a synonym of [deep-network]b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5There is also [tag:deep-learning]b2A1I9n14a1r18y25_g7l12o15b2e5@kenorb Yeah, but [dnn] stands for [deep-network].b2A1I9n14a1r18y25_g7l12o15b2e5@RobertCartaino Since you took the time to remove the [tags] tag, can you take the time to do these? :P


















This is /questions/tagged/status-bydesignstatus-bydesign, although it is not because of the private beta.

From https://meta.stackexchange.com/questions/67397/list-of-all-badges-with-full-descriptions/188732#188732List of all badges with full descriptions:


  A tag must appear on a minimum of 100 questions to be considered for tag badges.


Since we don't have tags with 100 questions or more, we don't yet see tag badges.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Ah, I had forgotten about that requirement. Nice find!


















I am in the process of writing up the final review of this site. In it, we discuss the difficulties this site is having with scope — mostly around the popular fallacies of what AI actually is. Artificial intelligence is very different from how it’s portrayed in the movies. Whenever a problem becomes solvable by a computer, people start arguing that it does not require intelligence at all… and "as soon as it works, no one calls it AI anymore" — John McCarthy

As such, this community is having difficulty navigating that narrow gap of what I'd call "AI relevance".

The proposal that created this site was intentionally placed in the 'scientific' category. If you accept that we are not creating another programming site, I think we stumbled upon in interesting niche that describes the original premise of this site nicely:


  Artificial Intelligence Stack Exchange is a site with a social and scientific focus on "Advanced Computing in Society."


Think about it. With autonomous cars, smart surveillance, and "the next big thing" capturing the headlines, this isn't a terrible idea for a subject. Draping it in the popular AI label gives it a better focus… and it completely disambiguate that this is not a technical implementation or programming site. We already have that.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5What do you mean by technical implementation?b2A1I9n14a1r18y25_g7l12o15b2e5@FranckDernoncourt Programmers, engineers, and other practitioners asking how to actually implement AI processes. This is not a technical site.b2A1I9n14a1r18y25_g7l12o15b2e5Thanks. Does mathematical or statistical questions count as technical implementation? (from your comment I guess so, but just to be sure)b2A1I9n14a1r18y25_g7l12o15b2e5@FranckDernoncourt Typically they belong on Math or Stats (Cross Validated) or DataScience which were specifically created for these subjects. This site was created to handle the scientific and social/cultural interests that (prior to this site) did not have a place in our network.b2A1I9n14a1r18y25_g7l12o15b2e5There's no technical implementation site for Artificial Intelligence in the general sense.  Some specific topics are on-topic at ds.se or stats.se, but hardly the entire body of AI.  Taking this insanely hard-line stance against programming / implementation questions is going to be bad for this site. If that's the case, let's change the name to "AI philosophy" or "AI fluff".b2A1I9n14a1r18y25_g7l12o15b2e5I understand the social thing but not so much the scientific focus. Could you maybe elaborate a bit more on what would be scientific aspects of AI or Advanced Computing? Also a better definition of the borders of AI science towards mathematics, statistics or computer algorithms would be nice.b2A1I9n14a1r18y25_g7l12o15b2e5this way it will be closed againb2A1I9n14a1r18y25_g7l12o15b2e5I second @mindcrime's view: A lot of the problems on this site are rooted in misunderstandings about the scope of AI. AI is not just machine learning, and it's not just data science. Those make up a disproportionate share of the field in the last 5-10 years, but before that were just one small subfield among many. 

There is currently no technical site that answers questions about AI. We should be accepting such questions here if we're going to sit on the AI.se name.b2A1I9n14a1r18y25_g7l12o15b2e5Robert, I like the perspective you've brought to this Q. Have you seen the new Q on which new descriptions for the AI site are being proposed and voted upon? (https://ai.meta.stackexchange.com/questions/1430/what-should-the-ai-se-site-description-be/) Those involved could probably benefit from reading your opinion there.


















When I try to load AI.SE without logging in, I get a 


  Warning: this site is currently in **private beta** for at least 1 more day.


https://i.stack.imgur.com/XjLgi.png

That **private beta** should be private beta, right?
b2A1I9n14a1r18y25_g7l12o15b2e5Bug when showing "Warning: This site is in Private Beta"b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Yes it should. Evidently, the text was written with the assumption it would be parsed as Markdown, but whatever displays it doesn't do that parsing. (This sort of display issue tends to creep into tag wiki excerpts too.)b2A1I9n14a1r18y25_g7l12o15b2e5It would probably be a good idea to ask this on Meta.SE instead.b2A1I9n14a1r18y25_g7l12o15b2e5@wythagoras But as far as I can tell, it only applies to AI. [i2p.SE] loaded it with the bold properly.b2A1I9n14a1r18y25_g7l12o15b2e5Possible duplicate of [Welcome to public beta!](http://meta.ai.stackexchange.com/questions/1202/welcome-to-public-beta)b2A1I9n14a1r18y25_g7l12o15b2e5@kenorb What? This is a bug report o_ob2A1I9n14a1r18y25_g7l12o15b2e5Bug which is not relevant anymore, since we're already in public beta, so you cannot reproduce it anymore. So Public beta is the follow up post, unless you want to close it as off-topic or something.b2A1I9n14a1r18y25_g7l12o15b2e5@kenorb Close it as [status-completed]. :P


















The tour says:


  Artificial Intelligence Stack Exchange is a question and answer site for people interested in conceptual questions about life and challenges in a world where "cognitive" functions can be mimicked in purely digital environment.


However, it should say:


  Artificial Intelligence Stack Exchange is a question and answer site for people interested in conceptual questions about life and challenges in a world where "cognitive" functions can be mimicked in a purely digital environment.


Adding the word 'a' before purely digital environment.
b2A1I9n14a1r18y25_g7l12o15b2e5Add an article in the tourb2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5@kenorb It's not necessary. I already mentioned it after the quote, and since part of it is actually in bold, it's confusing.b2A1I9n14a1r18y25_g7l12o15b2e5I was actually reading from the top and scanning the differences between two quotes until I realized it was written below:) That's why I did it bolded.b2A1I9n14a1r18y25_g7l12o15b2e5Possible duplicate of [How can we quickly describe our site?](http://meta.ai.stackexchange.com/questions/1197/how-can-we-quickly-describe-our-site)b2A1I9n14a1r18y25_g7l12o15b2e5@kenorb Again, this is different...b2A1I9n14a1r18y25_g7l12o15b2e5The other is logical follow up, since this would be deprecated once we'll have proper description of our site. Doesn't make sense fix something minor, if we'll change the whole site description. Secondly it says it's completed, so we can close if favor of another to redirect the users to the next thing which is happening related to the tour page.


















As you may have noticed from the https://ai.stackexchange.com/help/badges/30/betaBeta badge being awarded, https://ai.stackexchange.com/help/privilegesprivilege thresholds being adjusted, and the http://area51.stackexchange.com/proposals/93481/artificial-intelligenceArea 51 proposal status being updated, we are now in public beta!

This is a really special moment because, though we weren't the first to try, we were the first group to succeed in getting an AI-related Stack Exchange site off the ground. I'd like to thank the Stack Exchange team for being willing to try this again and for providing the advice and adjustments needed to keep us on track. Also, thanks to https://ai.stackexchange.com/users?tab=Reputation&filter=allall our users who have been asking questions, posting answers, and building consensus on meta.

I would be interested to see what notes the community team has on our progress (as https://languagelearning.meta.stackexchange.com/a/199was shared on another fairly new site). Even if we were a little shaky at times, evidently we're doing well now!
b2A1I9n14a1r18y25_g7l12o15b2e5Welcome to public beta!b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Especially since [AI was the example of 'didn't make it out of private beta'](https://blog.stackoverflow.com/2010/12/no-artificial-intelligence-in-area-51/).b2A1I9n14a1r18y25_g7l12o15b2e5Hello and nice opening, this is really a big day to be considered a flash light of an unmissable and indispensable section for SE as AI, this is regarded a triumph very long awaited for !


















Can we please add Cognitive Sciences as a migration target? It only makes sense, since we're bound to have some questions that should probably be migrated there, such as https://ai.stackexchange.com/questions/1716/why-was-eliza-able-to-induce-delusional-thinkingthis.

Or at least add the 'Not about AI within the scope of the Help Center' things, so that we can VTC/flag as something other than 'Blatantly off-topic'.
b2A1I9n14a1r18y25_g7l12o15b2e5Add CogSCi as a migration targetb2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Migration targets usually aren't possible on beta sites, but you can flag it for the moderation to migrate it there manually.b2A1I9n14a1r18y25_g7l12o15b2e5That makes sense. We can do it after we graduate fully. (Further reading: [Adding stats as a migration target](http://meta.ai.stackexchange.com/a/1104/75).) Also, questions can't be *closed* as "blatantly off-topic"; that reason only appears when *flagging* for closure.b2A1I9n14a1r18y25_g7l12o15b2e5@BenN That's right, I meant adding the others as flagging options. :/


















In https://ai.meta.stackexchange.com/questions/1201/add-an-article-in-the-tourthis question, I asked for an 'A' to be added in the tour, in the site description. It was added. But in the dropdown list of sites, it's still gone!

https://i.stack.imgur.com/2x1cC.png

That should be "...in a purely digital...".
b2A1I9n14a1r18y25_g7l12o15b2e5The 'A' was added in the tour, but not in the site description!b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5On which page is it?b2A1I9n14a1r18y25_g7l12o15b2e5Btw. This will be replaced by [new description](http://meta.ai.stackexchange.com/q/1197/8) anyway.b2A1I9n14a1r18y25_g7l12o15b2e5It's not missing an a it's missing an **s**. *purely digital environment**s***.b2A1I9n14a1r18y25_g7l12o15b2e5I would suggest removing the 'digital' part since analog devices are also making a fray in AI, as proposed by a question https://ai.stackexchange.com/questions/7328/if-digital-values-are-mere-estimates-why-not-return-to-analog-for-ai


















It appears that there is at least one question like this on the site:

https://ai.stackexchange.com/questions/1461/are-siri-and-cortana-ai-programsAre Siri and Cortana AI programs?

So I guess it would be okay - as long as you are asking about one (or two) specific thing(s).

For asking about in general when something is AI, that has already been asked: https://ai.stackexchange.com/questions/1507/what-are-the-minimum-requirements-to-call-something-aiWhat are the minimum requirements to call something AI?

The tags... Now that's the problem. That might be worth its own Meta post.

And welcome to AI!
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5re: "as long as you are asking about one (or two) specific thing(s)." that's (sadly) the point, I was taking the opposite path about the _necessary_ features for a system to be called an AI, so maybe it is not specific enough (the car example was just to illustrate the idea and I don't feel opening a question for each thing would be of value) .b2A1I9n14a1r18y25_g7l12o15b2e5@Tensibai Duplicate: http://ai.stackexchange.com/questions/1507/what-are-the-minimum-requirements-to-call-something-aib2A1I9n14a1r18y25_g7l12o15b2e5Awww, missed it while searching before asking here :/


















There are already plenty of questions on programming AI/NN frameworks on Data science and SO: I don't think we need one more place, SE is fragmented enough.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I completely agree with this answer.


















In addition to what was said by Mithrandir, I would personally say it's best that such a question focus on only one thing. In other words, questions that ask about an aspect of each item in a big list of things would be less than ideal. In the case of Siri and Cortana (smart personal assistants, basically), they're very similar products, so it makes sense to have one question for them.

It would be even better if such questions included specific features of the objects/products that the question owner suspects may produce AI. That shows research effort, and in discovering the relevant features, the person who asks might stumble upon an interesting insight themselves. It also has the benefit of covering all products that have that feature (having wide applicability yet focused scope tends to mark great questions in my experience), so we might not even need to name Siri and Cortana in the question title.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I agree, the question could have been 'systems like siri or cortana' and by extent 'or alexa'. As I already said this question is reasonably scoped for a correct answer, mine was on the fence and at end was a dupe. Thanks for the insight for future readers BTW.b2A1I9n14a1r18y25_g7l12o15b2e5Correction: this though about scope never left my mind before, now it's done ;) Sorry for the double comment, my phone did give up on batteries



















  Data Science is an applied site


Yeah, for data science.  Data science is not artificial intelligence.  There is overlap around the statistical techniques for machine learning, but they just are not identical. 


  Please do close questions that are highly technological or asking for applications.


I'm sorry, but I think this is very misguided.  Ignoring all aspects of implementation and technology on a se like this, is like a football team fielding an offense, but no defense (or vice versa).  Or maybe I should say, it's like a Reese's Peanut Butter Cup without the chocolate.

The simple truth is, you can say "programming questions belong on xx.se (or so)" but there are programming questions which - in principle - would be best suited for this site.  If somebody is asking about an AI specific technique or something highly specialized like rule induction using OPS5, this community is probably a better resource than datascience.se, stats.se, or possibly even so. 
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I agree that I am exaggarating a bit in my post, it is just that it was very important for the site to not have too much overlap with other site to get out of private beta.b2A1I9n14a1r18y25_g7l12o15b2e5@wythagoras you should add to your post why explicitly it is important to not overlap, and how this overlap will/might prevent getting out of beta


















This is the second time I've seen something like this:

https://i.stack.imgur.com/fdzEk.png

https://i.stack.imgur.com/RTOW9.png

What's causing these odd line breaks? Why is it only showing up every now and then? Can you fix it?

EDIT: This happened again:

https://i.stack.imgur.com/pPOlI.png

Link for above: https://ai.stackexchange.com/review/suggested-edits/546https://ai.stackexchange.com/review/suggested-edits/546

I'm using Google Chrome on Ubuntu.

EDIT: https://meta.stackexchange.com/questions/284096/whats-happening-with-these-edit-review-historiesNow posted on Meta.SE.
b2A1I9n14a1r18y25_g7l12o15b2e5What's happening with these edit review histories?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5What browser and OS do you use? I'm not able to reproduce this on Edge or Chrome on Windows 10.b2A1I9n14a1r18y25_g7l12o15b2e5Can you tell which URL it was?b2A1I9n14a1r18y25_g7l12o15b2e5@kenorb [Here's one](http://ai.stackexchange.com/review/suggested-edits/497) where Doxosophoi approved Mithrandir's edit.b2A1I9n14a1r18y25_g7l12o15b2e5@kenorb I'm not sure which one of yours it was. :P


















In this question: https://ai.meta.stackexchange.com/questions/18/should-the-deep-network-tag-be-replaced-by-deep-learningShould the [deep-network] tag be replaced by [deep-learning]?, it seems that it was agreed upon that the https://ai.stackexchange.com/questions/tagged/deep-networkdeep-network should be replaced by https://ai.stackexchange.com/questions/tagged/deep-learningdeep-learning. 

However, currently, both tags are used. The https://ai.stackexchange.com/questions/tagged/deep-networkdeep-network is used by 18 questions, the https://ai.stackexchange.com/questions/tagged/deep-learningdeep-learning tag by 13 questions. Can we create a tag synonym?
b2A1I9n14a1r18y25_g7l12o15b2e5Should [deep-network] and [deep-learning] be made synonymous?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Which one should be the main?b2A1I9n14a1r18y25_g7l12o15b2e5@kenorb [deep-learning] was what was said in the question.



















  Artificial Intelligence Stack Exchange is a question and answer site for people interested in conceptual questions about non-biological agents. Join them; it only takes a minute

b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Join non-biological agents? Does non-biological cover [biocomputer technology](https://en.wikipedia.org/wiki/Biological_computing#Notable_advancements_in_biocomputer_technology)?b2A1I9n14a1r18y25_g7l12o15b2e5@kenorb, I'm not sure if you are aware that the proposal and selection of a new AI site description has been resurrected by Ben and others at https://ai.meta.stackexchange.com/questions/1430/what-should-the-ai-se-site-description-be/, and it would probably be good to see your opinion in the comments or an answer there.


















When I think of "implementation", things like math and code come to mind, while the larger components of AI construction don't fall under that category. Selecting features to build an AI for a certain purpose would therefore be on-topic, though they could easily be too broad. https://ai.stackexchange.com/q/1784/75Your first example approaches "how do I solve this important problem with AI?", which possibly requires a deep knowledge of that field.

Questions tangentially related to programming, but not actually about the coding of the AI itself, are also OK. https://ai.stackexchange.com/q/1783/75Your second example asks how to represent part of an AI's state for debugging visualization. It's a pretty neat question in my opinion, landing squarely in the science part of artificial intelligence.

I would be a little wary of allowing questions about the fine details (i.e. the mathematical/statistical mechanics) of yet-to-be-solved research problems, as those are likely to be much better served at one of the math-heavy sites. Conceptual questions about what kinds of things they work on are interesting and well-suited to our site.

Executive summary: if a question has mathematical formulae or computer code as critical elements, the best home for it is possibly a different site. This answer contains a lot of weasel words to emphasize that's it's not at all a rulebook that applies everywhere. Such an answer would be a tome.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I think you're over-generalizing when you say "if a question has mathematical formulae or computer code as critical elements, the best home for it is very possibly a different site.".  Computer code is not computer code, if you know what I mean.  That is, a question about "how do I add an element to a collection in Java" is quite different from a question about an *AI specific technique*, like, for example, something to do with Answer Set Programming using Prolog.  The latter is probably not going to get much of an answer on datascience.se or stats.se, or possibly even on so.com.b2A1I9n14a1r18y25_g7l12o15b2e5@mindcrime Right, this answer is general advice. As you say, judgment calls are frequently necessary.b2A1I9n14a1r18y25_g7l12o15b2e5*"yet-to-be-solved research problems [...] are likely to be much better served at one of the math sites"*. Maths per se does not hold the answer to the research problems facing AI - I claim that's conflating AI with the mechanisms of currently popular regression methods such as DL. Research problems in AI will be solved by devising better *architectures*, which is surely within the remit of this site.b2A1I9n14a1r18y25_g7l12o15b2e5@NietzscheanAI Ah, my misunderstanding, I thought "research problems" referred to the math and stats of those techniques. Answer clarified.b2A1I9n14a1r18y25_g7l12o15b2e5@BenN Thanks for the clarification.


















I would say that it's a judgment call on a case by case basis.  I don't think there's a simple rule you can implement that can capture all of the nuance involved here.  My feeling is, unless you say with pretty close to absolute certainty that a question which includes code would get a better answer somewhere else, it's better to err on the side of leaving it alone.

That a question might contain math is, to me, nearly completely irrelevant to whether a question belongs here or not.  Irrelevant in that it's orthogonal to the issue of whether something is "conceptual" or "implementation".  After all, math is the language of science.  
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5FWIW, I actually agree with you on 'no simple rule'. I *completely* agree with you on the maths issue.b2A1I9n14a1r18y25_g7l12o15b2e5"I would say that it's a judgment call on a case by case basis." Hmm, this could hint that there is no clear distinction between concepts and implementation or otherwhise we wouldn't need a case by case basis.


















As we can see the current http://area51.stackexchange.com/proposals/93481/artificial-intelligencestats of the site: 

https://i.stack.imgur.com/VvdrO.png

Alos, we've had similar proposal which all went in vain:


http://area51.stackexchange.com/proposals/6607/artificial-intelligenceClosed after 12 days in beta
http://area51.stackexchange.com/proposals/57719/artificial-intelligenceClosed after 18 days in beta


What should be done to maintain a healthy site?  
b2A1I9n14a1r18y25_g7l12o15b2e5What should be done to prevent the site being closed?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Possible duplicate of [How do we promote this site?](http://meta.ai.stackexchange.com/questions/1/how-do-we-promote-this-site)


















Don't worry! We've passed the private beta mark, while the sites you mentioned were closed during that stage. That indicates that Stack Exchange reviewed our progress and determined that we're doing well enough to continue into public beta, which is https://ai.meta.stackexchange.com/q/1202/75where we are now.

Regarding the Area 51 stats: those goals are what you should expect from a site that's about to graduate fully. In days of old, it was expected that graduation would happen at 90 days in or else the site would indeed be closed. Now, sites can stay in beta as long as necessary. For more information, see https://meta.stackexchange.com/q/257614/295684Graduation, site closure, and a clearer outlook on the health of SE sites.

All that said, we should be promoting this site and growing the community. Asking quality questions and providing great answers is an excellent way to improve the site. We're collecting ideas for site promotion here: https://ai.meta.stackexchange.com/q/1/75How do we promote this site?
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Thanks for removing all doubts :)


















Recently we've gone through very critical private stage where 3 attempts since the last 6 years failed to success. See: https://blog.stackoverflow.com/2010/12/no-artificial-intelligence-in-area-51/No AI in Area51.

Since we've successfully passed the final review process, we've now more time to improve and expand our site to match the healthy state, before graduating to full site (it can take months or even years to achieve that stage).

If you check http://stackexchange.com/sites#questionsperdayAll sites statistics and compare to other sites and take into the account that we've just entered the public beta, so it's not so bad as it looks (>30 sites with less questions asked per day). It just takes time for new people to join and starting using the site, not everybody knows about it yet.

As https://ai.meta.stackexchange.com/a/1199/8@Robert mentioned few weeks ago:


  we stumbled upon in interesting niche that describes the original premise of this site


Currently we are in stage of clarifying the scope as per: https://ai.meta.stackexchange.com/q/1197/8How can we quickly describe our site?

Instead of worrying about it, we should ask ourselves: https://ai.meta.stackexchange.com/q/1/8How do we promote this site?
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Thanks for your valuable answer :)


















Yes, but I think many philosophical questions would be better off on Philosophy SE. It depends on the type of question. Questions that AI experts have mostly thought about (like https://ai.stackexchange.com/q/1824/8"Why would an AI need to 'wipe out the human race'?") are better suited here, while questions that are tangentially related to AI but are really referring to "philosophical concepts" (https://philosophy.stackexchange.com/questions/37442/are-robot-rebellions-even-possiblerobotic free will and https://philosophy.stackexchange.com/questions/11450/can-computers-be-programmed-to-be-creative/15617#15617AI creativity) are better left to the philosophy experts.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5The problem is, philosophy as an armchair activity (i.e. without specific knowledge of the particular domain) is quite capable of being wrong by missing important subtleties. See this paper for some arguments of relevance to AI (http://www.scottaaronson.com/papers/philos.pdf).b2A1I9n14a1r18y25_g7l12o15b2e5There's also the flip-side...AI experts who have no specific knowledge of the particular domain of philosophy are also quite capable of being wrong by missing important subtleties. It's important that people avoid "armchair" analysis by having a good background in both philosophy and AI development (which might be done by having overlap between the two SE sites).


















I think that science without mathematics is usually impossible, science without technology is very difficult (otherwise how to talk about computers for example) but science without programming/implementations is possible.

The emphasis would then be on the concepts and/or abstractions.

So kind of:


pseudocode is okay, real code not
algorithms are okay, implementations not
Math is okay as long as the concepts remain abstract.


How to put that into a single line? 


  Artificial Intelligence Stack Exchange is a site for people
  interested in social, conceptual and scientific questions about Advanced
  Computing. Join them; it only takes a minute


I feel this tries most to keep away from any implementations. But I also feel the limit should only be implementations, not higher level programming, algorithms, maths or statistics.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5You're definitely right in that we focus on the *concepts*. One nitpick that I have, though, is that the proposed line still includes the word "scientific", which some interpret to include all the technical stuff. How can we clarify that?b2A1I9n14a1r18y25_g7l12o15b2e5@BenN I agree with you that scientific does not totally exclude the technical stuff. I also thought about it and did not come up with a better alternative. Alternative would be to leave it out??


















I would like to save content from them, but I can't find them on the A51. Maybe it is because I don't have a really high reputation there currently.

Could somebody (maybe a 10k+ A51 user) get a link to the old dumps?
b2A1I9n14a1r18y25_g7l12o15b2e5Where can I find the dumps of the older tries?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Just make sure you don't use ones that I've already salvaged ;)b2A1I9n14a1r18y25_g7l12o15b2e5Related: http://meta.ai.stackexchange.com/questions/1124/can-i-steal-a-question-from-a-closed-siteb2A1I9n14a1r18y25_g7l12o15b2e5@Mithrandir Thanks, I do this with my *NI*, and I use the search before that :-)


















One decent option that already exists is https://ai.stackexchange.com/questions/tagged/human-likehuman-like. It currently only has two questions: one comparing human brains with neural networks, and one about AIs lying to humans. This question is about whether AIs' personalities can be distinguished into categories like those used for humans'. Since personalities are a human-like thing to have*, it would seem to fit in that tag as it's used so far. I suggested an edit that replaced the incorrect tag with this one, and it was approved by the post owner.

In my understanding, that specific question only applies to general AIs (as opposed to something like an image recognizer). Therefore, https://ai.stackexchange.com/questions/tagged/agiagi could also be relevant.

*Yes, animals can have personalities too. Animals can also https://en.wikipedia.org/wiki/Deception_in_animalsdeceive.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5How about tagging it as 'behavioural'? This generalizes the human/animal distinction and also means that the system need not be a general intelligence.


















What should we have in https://ai.stackexchange.com/help/askingHelp Center > Asking section regarding https://ai.stackexchange.com/help/on-topicWhat topics can I ask about here?

For example https://stats.stackexchange.com/help/on-topicStats SE has this:


  CrossValidated is for statisticians, data miners, and anyone else
  doing data analysis or interested in it as a discipline. If you have a
  question about
  
  
  statistical analysis, applied or theoretical
  designing experiments
  collecting data
  data mining
  machine learning
  visualizing data
  probability theory
  mathematical statistics
  statistical and data-driven computing
  


And here is /help/on-topic at https://datascience.stackexchange.com/help/on-topicData Science:


  Examples of questions that are likely to be on-topic for Data Science
  Stack Exchange:
  
  
  Given process monitoring data arriving every 10ms, what statistical tool should I use to best characterize a change in the process - mean?
  a distribution?
  When is it suitable to apply L1 regularization for feature selection?
  I would like to produce a infographic on the 'Brexit' referendum. Given public opinion data across the UK, what are some meaningful
  techniques to visaualize it in a dashboard?
  When executing an ARIMA model in Spark, what are the pros and cons of using Python instead of R?
  Given Facebook Likes, is there an ML technique to predict age and gender?
  


If we would like to differentiate from the above sites, we should have our unique section about the topics which people can ask about here.

What description of https://ai.stackexchange.com/help/on-topic/help/on-topic page for AI site would you suggest?
b2A1I9n14a1r18y25_g7l12o15b2e5What topics can I ask about here?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I think its still unclear to me what goes on stats overflow vs ai overflow...how is that decided?b2A1I9n14a1r18y25_g7l12o15b2e5what does: "questions about the mathematics of machine learning should be asked at Cross Validated."? That ambiguous. If one asks for clarification of notation is that mathematics of ML? Or is only a proof of statistical learning theory the "mathematics of ML"?


















Drawing on these existing discussions:


https://ai.meta.stackexchange.com/q/1197/75How can we quickly describe our site?
https://ai.meta.stackexchange.com/q/1221/75Should philosophical questions related to AI be on-topic?
https://ai.meta.stackexchange.com/q/1141/75A friendly reminder that this site comes from the Science category
https://ai.meta.stackexchange.com/q/1123/75How this site is different from Cross Validated?


Also taking some inspiration from https://superuser.com/help/on-topicthe Super User "on topic" page, here's my first stab at it:


  If you have a question about...
  
  
  social issues in a world where artificial intelligence is common,
  conceptual aspects of AI, or
  human factors in AI development
  
  
  ...and it is not about...
  
  
  the https://ai.meta.stackexchange.com/q/1215/75implementation of machine learning, or
  asking for a development tool or career path recommendation
  
  
  ...then you're in the right place to ask your question!


This is only a draft, but it seems like a good starting point. Please suggest improvements if you see anything that needs adjustment! Specifically, I'm not sure how specific we need to be about what constitutes "implementation" in this blurb. If there are other commonly asked kinds of off-topic questions, those could be worth mentioning too.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Should we add point about [scientific questions](http://meta.ai.stackexchange.com/q/1141/8) about AI?b2A1I9n14a1r18y25_g7l12o15b2e5@kenorb Yes, I was trying to include those in the last two "acceptable" bullet points. I'm a little wary of the term "scientific" because some might interpret it as allowing much more than we have so far. ([A related question.](http://meta.ai.stackexchange.com/q/1078/75)) I would welcome better wordings!b2A1I9n14a1r18y25_g7l12o15b2e5@kenorb Since there didn't seem to be objections, I've added the current wording in this post to [the on-topic page](http://ai.stackexchange.com/help/on-topic). Suggestions for improvements are always welcome.b2A1I9n14a1r18y25_g7l12o15b2e5Added a section pointing people to Data Science or Cross Validated if their question is on ML implementation or mathematics.b2A1I9n14a1r18y25_g7l12o15b2e5Should we expand the second bullet of the "not" section to include questions like [this one](http://ai.stackexchange.com/questions/2077/what-is-good-way-of-start-learning-ai-step-by-step)? I think it's in the same general cluster but it also seems like answers that link to good tutorials are a good thing to have around. (That particular question is probably too broad anyway, but you could imagine a "what's the best way to learn about [specific issue X]?" question going well.)b2A1I9n14a1r18y25_g7l12o15b2e5@MatthewGraves I'm not super enthusiastic about questions/answers dedicated to off-site resources. Adding a [big list for beginners](http://meta.ai.stackexchange.com/q/74/75) is usually something that should be done with community consensus, since it would require continuing upkeep. I would be on board with adding "learning materials" to the list of things we discourage recommendations of.b2A1I9n14a1r18y25_g7l12o15b2e5I think it should be clarified what implementation of ML means. Does that mean just coding or does that include the descriptive language of it? e.g. maths (even if its NOT about proofs, but the mathematical language to express ML/DL modern AI).b2A1I9n14a1r18y25_g7l12o15b2e5I think it would be good to clarify what goes on stats vs AI overflow. Thats unclear.b2A1I9n14a1r18y25_g7l12o15b2e5what does: "questions about the mathematics of machine learning should be asked at Cross Validated."? That ambiguous. If one asks for clarification of notation is that mathematics of ML? Or is only a proof of statistical learning theory the "mathematics of ML"?


















Many questions on AI seems to be trying to predict what might be possible in the future. This lend itself to science-fiction speculation (opinions). I think I am mostly provoked by this question:
https://ai.stackexchange.com/questions/2048/what-jobs-cannot-be-automatized-by-ai-in-the-futureWhat jobs cannot be automatized by AI in the future?, which essentially wants us to make a  prediction about a future scenario (specifically, what AI can't do). Predicting the future is hard, especially if there's no cut-off point (predicting what jobs are killed by AI in the year 2020 is much easier than predicting what jobs are killed by AI in 2100)...and it's not quite clear if there will be much expert opinion on futuristic predictions, or even if experts even are able to make good predictions about the future.

Questions about the future would only solicit personal opinions. I would strongly suggest that these types of questions be closed as opinion-based.
b2A1I9n14a1r18y25_g7l12o15b2e5How should we handle questions about "predicting the future"?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5[I have an idea...](http://meta.stackexchange.com/questions/1696/add-a-magic-8-ball-feature-to-the-ask-a-question-page)


















Such question usually tend to draw a lot of low quality answers which are speculating without giving any backup to their claims. And at the end it's just one person opinion on that topic.

Therefore if the question isn't going to generate any constructive answers, which doesn't have any reliable references or there are no existing research studies in that area (because the topic isn't great or too localized), and question is just asking people to speculate based on their gut instinct, we should vote to close.

Although this particular question about https://ai.stackexchange.com/q/2048/8automatic human jobs isn't actually bad, since it's possible to assess such probability based on the available employment data and in http://www.oxfordmartin.ox.ac.uk/downloads/academic/The_Future_of_Employment.pdf2013 Oxford study they managed to estimate it using computer models. So I believe it's actually answerable.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Or we could be honest with ourselves, admit that this community is not primarily made up of academics, and simply let it be a useful resource to those who do use it.  Or we can beat our heads against the wall in a futile effort to mold it into something it's not, while chanting the SO mantra about opinion-based answers, blah, blah, blah.


















We should drop any reference to implementation specifically being on or off topic.  That's really orthogonal to the issue and it makes it too easy for people to justify arbitrarily closing good questions.  And as this eliminates so many of the more concrete questions, it makes the site appear as though it's only for science-fiction'ish questions.  
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I think that questions about how to pick the right architecture to solve a particular problem, or about why various architectures are good or bad fits for particular problems, would be interesting and useful to have around. But I also think that debugging tensorflow code or discussing data preprocessing is something that we should try to push off to another SE. Do you have a suggestion as to where to draw that line, and how to communicate it in the help center?b2A1I9n14a1r18y25_g7l12o15b2e5I agree that there should be a said line and i think that it should place questions about network architectures and methods within the AI site but should leave any deeper discussions outside. A good reference for this line is AI liturature: Most of it doesn't discuss code and rather theorizes, examines, and discusses how aspects of AI can be arranged, defined, estimated, while addressing the features that current AI systems lack. Using this as a guide, perhaps we can start having more answers that reference AI papers than comments which tell people to post in CrossVidated.b2A1I9n14a1r18y25_g7l12o15b2e5@MatthewGraves I think its simple. Anything that involves code is off topic. If its described in the mathematical language of what the ML algorithm is doing that is fine (especially if its brain inspired AI like deep learning). Just explicitly saying code is not allowed sounds good to me or that the questions should be how to code something or not code focused but AI concept focused.


















All the other Stack Exchange sites link to the same username, but for some reason the AI site changed my username to a25bedc5-3d09-41b8-82fb-ea6c353d75ae.

Why did that happen and how can I fix it?
b2A1I9n14a1r18y25_g7l12o15b2e5Why did my username change to a25bedc5-3d09-41b8-82fb-ea6c353d75ae?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Sounds like http://meta.stackexchange.com/q/135178/154443 - you should add the [tag:bug] tagb2A1I9n14a1r18y25_g7l12o15b2e5Does manually editing your profile to fix the name work?


















I'm noticing that we get quite a few questions asking for recommendations of programming languages or libraries. Unfortunately, I'm not sure that wordsmithing our site description or help center will make it sufficiently clear that such recommendations are off-topic (both because of site scope and the fact that recommendations go out of date fast). Not everyone reads the help center's https://ai.stackexchange.com/help/on-topicon-topic page; I don't even see a direct link to it from the asking form.

We can keep closing these questions - it feels like we've handled at least a dozen so far - but it would be a better experience for new users if there was something we could point them to. We've https://ai.meta.stackexchange.com/a/1074/75discussed having a collection of links to such resources before, and it was correctly noted that this site isn't focused on programming anyway. Nevertheless, with a site name like "Artificial Intelligence", it's understandable that people will ask how to start AI-related projects.

What, if anything, should we do about this?
b2A1I9n14a1r18y25_g7l12o15b2e5What should we do about programming resource recommendation questions?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5We can consider creating a wiki page either on the main site or in meta with some resources, pointing to some books or Coursera courses.b2A1I9n14a1r18y25_g7l12o15b2e5It's better to create a wiki page on the main site,so that even new users or visitors can easily be informed straight away.b2A1I9n14a1r18y25_g7l12o15b2e5@quintumnia That could be a good solution; I'd be on board with it. Would you like to write an answer here so people can vote on it?b2A1I9n14a1r18y25_g7l12o15b2e5@BenN ,basing on my analysis;why is that some questions have up-votes and no answers.Could this mean that voters understand the questions and can't even answer them!b2A1I9n14a1r18y25_g7l12o15b2e5If I could downvote this question or better this website, I would honestly. Not allowing this website discussing about AI programming tools (not problems) it's completely a waste! Stack Overflow is plenty of incompetent people and it seems that in this website is no different.b2A1I9n14a1r18y25_g7l12o15b2e5@nbro Indeed, Q&A on tools is an important thing to have, and it can be had at [datascience.se]; requests for tool suggestions can be posted at [softwarerecs.se]. If you have a specific concern about site policy (either of this site or another), I encourage you to post a constructive meta question so we can make things better.b2A1I9n14a1r18y25_g7l12o15b2e5@BenN Let me tell you just briefly here, because I think a constructive discussion on this website would not lead anywhere, since I know the most common type of person in this websites, who are closed-minded to certain aspects of certain things. Anyway, regarding this website, so far, looking at the qualities of the questions and answers, I don't think this will help improve the field of AI. They all seem opinion or philosophical-based. Everyone with a brain can philosophize. I think this website should be closed. I've read that this should be a "scientific" website. Pls, don't make me laugh.


















The following question:


https://ai.stackexchange.com/q/2235/8How q-learning solves the issue with value iteration in model-free settings


sounds like a modelling question. Should it be on-topic?
b2A1I9n14a1r18y25_g7l12o15b2e5Should questions about Q-learning solving in reinforcement learning be on-topic?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I'd be interested to understand the thinking behind voting this question down.b2A1I9n14a1r18y25_g7l12o15b2e5On meta it's probably means 'no' to the question.


















We seem to have a lot of questions about programming showing up now, which are off-topic (and not enough people VTCing!).

Examples: https://ai.stackexchange.com/q/2457/145(1) https://ai.stackexchange.com/q/2462/145(2) https://ai.stackexchange.com/q/2451/145(3)

Is it possible to place a banner at the top of the page, stating that these questions are off-topic, such as the one on http://judaism.stackexchange.comMi Yodeya? Or is that only available for graduated sites?
b2A1I9n14a1r18y25_g7l12o15b2e5Is it possible to place a banner stating that programming questions are off-topic here?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Mithical, do you have any screenshot of what it looked like on Mi Yodeya? It doesn't seem like such a banner exists now?b2A1I9n14a1r18y25_g7l12o15b2e5@user1271772 - I was *probably* referring to https://i.stack.imgur.com/OX6q6.png at the timeb2A1I9n14a1r18y25_g7l12o15b2e5@Mithrandir I see.


















Yes, I agree that this is a concerning trend. Though we https://ai.meta.stackexchange.com/q/1252/75have an on-topic page that categorizes such questions as off-topic, there is not a direct link to that help center article on the asking form. https://meta.stackexchange.com/q/213935/295684Relevant MSE.

Though we put together an on-topic page, the https://ai.stackexchange.com/tourtour page was neglected. People are encouraged to take the tour when they first sign up; for some, it might be the only topicality-related document they read. Just now, I changed the "ask" and "don't ask" bulleted lists away from the default generic stuff to something that summarizes our help center guidelines. Suggestions for improvements are welcome! Hopefully this change will help our problem; if it doesn't, we can consider more conspicuous help text.

In regard to the examples you brought up (thank you for bringing specifics!):


This question was voluntarily removed by its author after receiving some comments about topicality.
This seems interesting to me; I think one could argue that it's asking about ways of thinking as opposed to asking for some code.
This is indeed a question about programming. It is https://ai.stackexchange.com/review/close/1135in the Close Votes queue at the moment pending review. As you said, it would be very good to have more people reviewing. There are currently 16 non-moderator users with https://ai.stackexchange.com/help/privileges/close-questionsthe close/reopen vote privilege; I encourage all such users to https://ai.stackexchange.com/review/close/have a look at that queue.

b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Is seeing how many users have a privilege a moderator-only power?b2A1I9n14a1r18y25_g7l12o15b2e5@Mithrandir I just counted the number of users [on the reputation-ordered user page](http://ai.stackexchange.com/users?tab=Reputation&filter=all) with more than 500 reputation. I'm not aware of a feature that shows the users with a given privilege. If the number got too big to count by hand, a Data Explorer query could do the trick.b2A1I9n14a1r18y25_g7l12o15b2e5Thanks, I was just wondering what kind of tools you guys have :P


















Good. There has never been any actual consensus that all "technical" questions are off-topic.  And at the end of the day, the community decides what is on-topic, not a bunch of ivory-tower navel-gazers here on meta.  Personally I like where we're at with this.  There are some technical questions, yes, but quite often they're different technical questions than the ones you see on stats or datascience or whatever. That tells me we're providing real value to the world, and that makes me happy.

If anything, I say the only action we might need to ramp us, is migrating some questions to other *.se sites, if they are clearly more suited for a different site (say, stats.se or datascience.se). I'm not entirely sure how migration works though.. can anybody nominate a question to be migrated, or what? Does that come in at a certain karma level, or is that something that only the StackExchange employees can do, or what? 
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5"There are some technical questions, yes, but quite often they're different technical questions than the ones you see on stats or datascience -> I disagree, most of them very much on-topic on both stats and datascience (ignoring the case where questions too broad or unclear). I agree that it is preferable to migrate vs. close.b2A1I9n14a1r18y25_g7l12o15b2e5Just to illustrate what I'm getting at... here's a question that is very much "technical", but which I would argue is totally on-topic here, and would be only marginally on-topic at stats or datascience:  http://ai.stackexchange.com/questions/2623/role-of-bayesian-inference-in-reasoning-systems   Yes, it mentions Bayesian inference, but that doesn't make it a "data science" or "stats" question because the real meat of the question is about combining that with something that is more in the realm of GOFAI.b2A1I9n14a1r18y25_g7l12o15b2e5questions pertaining to GOFAI are much rarer. E.g., in the screenshot I have shown in the question, > 90% are not GOFAI and would be perfectly  on-topic on  stats and datascience (ignoring the case where questions too broad or unclear).b2A1I9n14a1r18y25_g7l12o15b2e5Sure, I wasn't saying anything one way or the other about the contents of the screenshot.  Some of those probably could stand to be migrated.  I'm just saying that - in general - we shouldn't hold to some hard-line position that "all technical questions are off-topic". I've been arguing that from the beginning and I'll keep arguing it until they ban me, or I die, etc.  :-)b2A1I9n14a1r18y25_g7l12o15b2e5got it, makes sense. FYI, from meta CV: [What is our stance on questions about non-statistical artificial intelligence?](http://meta.stats.stackexchange.com/q/4257/12359).b2A1I9n14a1r18y25_g7l12o15b2e5If a technical question related to AI has no home on CV or DS or SO, I absolutely agree we should welcome it. About migration: only fully graduated sites can have migration paths to other sites; beta sites only have a path to their meta. Moderators can migrate any question to anywhere, so currently all requests for migration have to be submitted via custom flags.


















I don't think it's not possible to force people to not ask the technical questions. Once it's asked, community decides whether it's on-topic or not. Closing only because it's a technical question isn't enough. More things needs to be taken into the account before deciding.

To be clear, this https://ai.meta.stackexchange.com/q/1141/8proposal comes from the Science category, so scientific questions are clearly on-topic (especially https://ai.meta.stackexchange.com/a/1144/8socio-scientific angle), but some overlap in scope is expected.

Please note that there are over 10 sites across Stack Exchange network where Artificial Intelligence related questions can be also on-topic (such as https://stats.stackexchange.com/questions/tagged/artificial-intelligenceCross Validated, https://datascience.stackexchange.com/questions/tagged/machine-learningData Science, https://cs.stackexchange.com/questions/tagged/artificial-intelligenceComputer Science, https://cstheory.stackexchange.com/questions/tagged/ai.artificial-intelCSTheory, https://cogsci.stackexchange.com/questions/tagged/artificial-intelligenceCognitive Sciences, https://philosophy.stackexchange.com/questions/tagged/artificial-intelligencePhilosophy, https://worldbuilding.stackexchange.com/questions/tagged/artificial-intelligenceWorldbuilding, https://stackoverflow.com/questions/tagged/artificial-intelligenceStack Overflow, https://hsm.stackexchange.com/questions/tagged/artificial-intelligenceHistory of Science, https://robotics.stackexchange.com/questions/tagged/artificial-intelligenceRobotics, https://gamedev.stackexchange.com/questions/tagged/aiGameDev and so on), so once the question is asked, it's a matter of speculation where it exactly should belong, unless it's very clear where it belongs. Otherwise claiming the ownership of some question related to AI on other non-AI site which has been asked specifically here or only because it's a technical one, it would be unwise. The point is, that this site is fully dedicated to AI, Cross Validated site has only few tags related to https://stats.stackexchange.com/questions/tagged/artificial-intelligenceAI and https://stats.stackexchange.com/questions/tagged/machine-learningmachine learning and it focuses only on statistical techniques where the questions asked there doesn't have to be related to AI.

Therefore if the question is asking about statistical techniques, then sure, it's more on-topic at https://stats.stackexchange.com/Cross Validated. Especially if you think it's off-topic here (e.g. nothing to do with AI), and on-topic there, vote to close, so after the closure it can be migrated by the moderators to another site. Similar with question specifically about https://datascience.stackexchange.com/data science or https://stackoverflow.com/questions/tagged/artificial-intelligenceprogramming.

In summary, the level of technicality is a matter of speculation. For me as far as it doesn't consist math, asking for formulas, technical implementation or modelling, programming code, it's not a technical question. We should rather ask ourselves, whether it's off-topic here (non-AI), and on-topic somewhere else.

Related discussion: https://ai.meta.stackexchange.com/a/1235/8What should be on-topic, modelling or implementation, or anything else?
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5"Cross Validated site has only few tags related to AI and machine learning" -> CV has plenty of ML tags. In the screenshot I have shown in the question, the vast majority of them are about statistical models, such as neural networks. Do you agree that they should be closed?b2A1I9n14a1r18y25_g7l12o15b2e5@FranckDernoncourt Some of them I voted to close, but it takes long time to close them completely, such as [2605](http://ai.stackexchange.com/q/2605), [2588](http://ai.stackexchange.com/q/2588), [2590](http://ai.stackexchange.com/q/2590), [2597](http://ai.stackexchange.com/q/2597), and so on, but for example not on [2599](http://ai.stackexchange.com/q/2599) (general enquiry) and the one which have already accepted UV answers, usually I tempt to ignore.b2A1I9n14a1r18y25_g7l12o15b2e5I see. One issue is that it looks like in most situations close votes expire before the question gets closed.



















  I'm getting tired of this site. It's supposed to be a factual site about software development and stuff. But 90% of the questions are sci-fi/fantasy questions like "If AI becomes sentient.......". The word "consciousness" does not refer to any scientifically definable concept. The answer is what ever you want it to be. What are the guide lines for this forum? are these questions even on topic? – Lorry Laurence mcLarry https://ai.stackexchange.com/questions/2646/how-to-stop-people-abusing-ai#comment3065_26468 hours ago


I share Lorry's distaste of these type of questions. Speculative questions are easy to ask, easy to answer, and easy to engage with, but they don't necessarily help humans to truly understand the field of AI (especially since many of these speculative questions are not really answerable within a reasonable timeframe). Speculative questions also might degrade into opinion-based questions, which is an obvious no-no. Many of these questions have the potential to be unanswerable.

It's not like these questions are bad. AI and science-fiction have been closely connected to each other, and people do want to speculate about the future. The scope of the site is to answer "conceptual questions about life and challenges in a world where 'cognitive' functions can be mimicked in purely digital environment", which seems to suggest that these types of speculative questions might be on-topic.

However, I don't think the site would survive if we were flooded by them.

Non-speculative humanities questions about AI are difficult to come up with and difficult to answer, but they seem to be more useful and applicable in the present-day. I think this is the type of content we want to have...

What can be done to encourage people to ask the latter type of questions?
b2A1I9n14a1r18y25_g7l12o15b2e5How Do We Encourage More "Non-Speculative" Questions?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5This is a very important concern, thank you for raising it. I hope to have a good answer ready soon. ([Potentially relevant SE blog post.](https://stackoverflow.blog/2010/09/good-subjective-bad-subjective/))


















I am also concerned about low-effort speculation questions (especially those that are very broad), and even more concerned when they manage to gather several upvotes. To help stop questions you deem low-quality from proliferating, you can exercise your voting rights: cast downvotes when appropriate, and optimally leave a comment to help the author improve. Conversely, upvote good questions, the kind you want to see more of. Note that close votes and downvotes are different things with different purposes: a question can be on-topic but poorly expressed or unresearched. If a question is in a useful/interesting topic but doesn't yet adhere to our expectations, edit it into shape. Try to preserve the original meaning as much as possible.

Our site is by design a little more subjective than, say, Data Science. That said, we don't allow pure speculation; a question that is primarily opinion-based should be closed as such. A somewhat squishy question that can invite facts instead of personal beliefs and wild speculation would be allowed. If an answer is only speculation with no reasoning or sources provided, please downvote.

"You get the site you build," said some MSE or blog post, if I remember the quote correctly. New users will take the most salient existing content as precedent, so we want our best content to be the highest-voted. If you're feeling particularly generous, you can add a bounty to reward excellent answers. Alas, there's not a way to give a big reward for an awesome question. You can, however, reward authors of good questions by putting effort into writing an answer to them. It's tougher to put together something based in fact than to write up a personal opinion, but it's what we collectively need.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I downvoted this answer because I think your suggestion (of just downvoting) is not sufficient to solve this problem. Rules should be introduced which somehow prevent the proliferation of this type of questions. It's completely untrue that this site doesn't allow primarily opinion-based questions. Most of the questions mentioned by the OP are indeed primarily opinion-based or lead to answers that are inevitably opinion-based. Speculations are just opinions.b2A1I9n14a1r18y25_g7l12o15b2e5I upvoted this answer because I think your suggestion is sufficient, and has proven to be sufficient through extensive testing on other SE sites.


















Since https://ai.meta.stackexchange.com/q/1283/75this site is more subjective than some, we occasionally get answers that are solely based on personal opinion or make claims with no justification/references. Even subjective questions should invite facts (instead of opinions), so such answers are less than ideal.

What should we do with these answers? Here are a few options (though feel free to propose alternatives not in this list):


Just leave them alone and let them be downvoted/ignored
Flag them for immediate deletion
Flag them for the application of a post notice (e.g. "citation needed"), with deletion being the next course of action if the answer is not filled out


If you'd like some ideas on how this is handled on other sites, I refer you to https://skeptics.meta.stackexchange.com/q/1054a Skeptics FAQ.
b2A1I9n14a1r18y25_g7l12o15b2e5How should non-fact-based answers be handled?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5So what's happening with this?  Are we waiting for more votes, or answers...?b2A1I9n14a1r18y25_g7l12o15b2e5@Mithrandir I was hoping there would be more votes on your answer, but since nobody else seems to have a proposal, I'm on board with that solution.


















Some implementation questions like https://ai.stackexchange.com/questions/2817/reproduce-firefly-algorithm-experiments-of-original-paperthis one and https://ai.stackexchange.com/questions/2743/how-to-fill-in-missing-transitions-when-sampling-an-mdp-transition-tablethis one are not about Machine Learning. They are getting closed anyway, as the actual topic would rather be on another SE site.
I wonder if the "not about... the implementation of machine learning" on the https://ai.stackexchange.com/help/on-topichelp center page is misleading a few people. That phrasing originates in a https://ai.meta.stackexchange.com/q/1252/169discussion about acceptable topics, and the term "implementation" still seems problematic.
How about "algorithmic or implementation details, software library or specific hardware-related" kind of phrasing? The idea is to exclude more implementation-related questions, but only the ones that pertain to step-by-step guidance through an implementation or library.
In short, a couple examples under the latter proposal:

NG: How to implement A* with TensorFlow?
OK: How to implement Case-Based Reasoning with Neural Networks?

Note the intended use of the "implementation" word in both questions. If there is something here, I still think there is a need for better examples (the OK is too broad yet).

Disclaimer: I am a proponent of having some implementation questions here.
b2A1I9n14a1r18y25_g7l12o15b2e5What is in scope under the "implementation of machine learning" exclusion?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Isn't "How to implement Case-Based Reasoning with Neural Networks?" an algorithmic  question?b2A1I9n14a1r18y25_g7l12o15b2e5It can go as far as an algorithm, yes. It could be as "simple" as explaining how CBR can be modeled with NN. I do not like my own example. I am trying to make a point that implementation is not necessarily about ML, and we should reflect that in the help center.b2A1I9n14a1r18y25_g7l12o15b2e5As a side note, questions about machine learning implementations are often not getting closed [Technical questions are not getting closed](http://meta.ai.stackexchange.com/q/1279/4)


















https://ai.stackexchange.com/revisions/3171/1This answer looked like this when it was first posted:


  Did you mean, technological singularity? https://en.wikipedia.org/wiki/Technological_singularityhttps://en.wikipedia.org/wiki/Technological_singularity


This looks suspiciously like a link-only answer. Let's look at what https://meta.stackexchange.com/questions/225370/your-answer-is-in-another-castle-when-is-an-answer-not-an-answerthe post about link only answers says:


  Yes, they're both very short, and yes, they contain links. But strip the markup, and you still get at least a little bit of useful information.


So if we strip the link, pretending that the last two words were linked - it's acceptable by that post. However, we have a https://ai.meta.stackexchange.com/questions/1285/how-should-non-fact-based-answers-be-handledpolicy that answers that don't provide support for themselves are to be removed.

So was this answer okay in its original state?
b2A1I9n14a1r18y25_g7l12o15b2e5Was this answer about dissolving in an AI acceptable in its original state?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5The "answer" really should have just been a comment (unless the person in question didn't have enough rep to post a comment, in which case, the answer was "fine" and it's up to the mods to do some minor fixing).b2A1I9n14a1r18y25_g7l12o15b2e5I agree with @TariqAli that the request for clarification should have been a comment, but the answer now seems to have an explanation, and does seem to propose a term "rebirth".  I think link only answers can have value, as the field is evolving so rapidly (i.e. linking questioners to newly defined concepts relevant to their inquiry.)  But we ideally don't want links without explanation and some "value add".


















I came to ask a basic fundamental question about AI: In a neural network when inputting nerve input to sense a 2D environment, how do you differentiate two types of objects so the neural network can treat them differently?

That's a solid, fundamental, extremely important AI question. It isnt based on writing code, it's about fundamental neural network structure. I was down-voted and told that's off topic. So I look at the on topic scope here:


social issues in a world where artificial intelligence is common,
conceptual aspects of AI, or
human factors in AI development


Let's address these one by one


  social issues in a world where artificial intelligence is common


That's already covered 100% by Worldbuilding Stack Exchange, people have no need to come here for those questions when they could get a response way faster and from a larger and more active community than here. 


  human factors in AI development


What does that even mean? Seriously, that line means nothing to anyone and should be revised / clarified. 


  conceptual aspects of AI


This makes sense, but it certainly shouldn't exclude fundamental aspects of AI. In its current state, this site's defined scope makes it useless for anyone who's an expert on AI: all of whom will be interested in creating AI, and will therefore be interested in asking and answering fundamental questions about topics such as structuring and designing AI, which can be asked and answered without involving any code. 

To reiterate, no AI experts are going to be drawn to this current scope, it's essentially only useful for the world building audience, which already has a https://worldbuilding.stackexchange.com/popular SE site. If this is going to be called AI SE, it needs to be a place attractive to actual AI experts in the field, not just science fiction enthusiasts speculating about challenges of a world with AI. Questions about fundamental AI design needs to be on-topic. Not programming questions. Just structural, fundamental design questions.
b2A1I9n14a1r18y25_g7l12o15b2e513 out of the 15 questions on the front page right now are -1 or lower score: This site needs a broader scope or it's doomedb2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Your question https://ai.stackexchange.com/questions/3329/how-can-object-types-be-differentiated-in-the-input-of-a-neural-network falls under the "conceptual aspects of AI".b2A1I9n14a1r18y25_g7l12o15b2e5@nbro great, well if "conceptual aspects of AI" covers fundamental AI design questions then I guess my primary argument is null, however, there does seem to be a problem here with that number of questions being at -1 score or lower... 13 of 15 on the front page yesterday, that doesn't bode well.b2A1I9n14a1r18y25_g7l12o15b2e5We don't need another duplicate of https://stats.stackexchange.com/b2A1I9n14a1r18y25_g7l12o15b2e5We don't need a duplicate, but there will be cross-fertilization. I've been active for a long time on [SO](https://stackoverflow.com) and still routinely flag to migrate questions that belong on serverfault, stats, datascience, codereview, .... There has to be tolerance for both people confused about the mission of the site as well as questions that can be described as lying at the boundaries.


















You are correct; conceptual aspects of AI are on-topic and https://ai.stackexchange.com/q/3329/75your question does indeed qualify. I hit Leave Open on it in the review queue, so it should survive. People have somewhat different ideas of what the scope is, and especially what the scope should be, so there will be some spurious scope-related admonishments.

The help center's on-topic page is also subject to revision, and I am always happy to adjust it if it needs clarification. Allow me to expound a bit on the current text:


Social issues: while Worldbuilding does indeed explore hypothetical worlds, this site requires that answers to these questions https://ai.meta.stackexchange.com/q/1285/75have basis in reality. Sci-fi writing is not acceptable here.
Human factors: this line was my attempt to describe questions about humans' role in creating or guiding AIs. It was originally inspired by one interesting question about displaying an AI's configuration/state for human inspection (which I can't find at the moment, sorry). I'll think about how best to express this.
Conceptual aspects: while non-mathematical concepts are definitely on topic, more concrete implementation issues are already better handled by https://stats.stackexchange.com/Cross Validated or http://datascience.stackexchange.com/Data Science; diffusing those questions across more Stack Exchange sites would add more confusion and duplication.


One thing that isn't captured currently is the academic/humanities arena, as set forth for us https://area51.meta.stackexchange.com/a/24016/136466back when the site was being considered for private beta. Those questions are definitely also on-topic.

I think our current scope is unique and interesting, though you are right: we could use more experts. Specific proposals for policy changes or wordsmithing are welcome!
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I think this subject matter is so new, industrially speaking, that it's like the early days of programming - you don't have a huge saturation of experts in the general population yet. Those who are experts are highly sought after and likely very busy. That's going to be a long running problem for the next few years while programmers start to take that leap to understanding AI. However, that being said, 13 out of 15 questions being down-voted to -1 or lower makes it clear that there's a problem: Either someone is serial down-voting, someone doesnt understand the scope or disagrees, orb2A1I9n14a1r18y25_g7l12o15b2e5(cont) or the scope is too narrow. If it's one of the former two possibilities, that's going to discourage and drive away potential members at a time when the community desperately needs to grow. If the scope is too narrow, that's a whole different beast to tackle. I'm new here, I can't yet say which one it is. Your guess will be a lot better than mine.b2A1I9n14a1r18y25_g7l12o15b2e5@Viziionary With a site this small, it's definitely possible for one or a handful of people to greatly affect the front page. If you like, you can help implement our scope by voting up good, on-topic questions.


















The site is described as "For people interested in conceptual questions about life and challenges in a world where "cognitive" functions can be mimicked in purely digital environment."

However, this does not seem to be what the questions are actually about. The blurb makes it seem that the site is about the effects of AI on the world, while the questions are actually about the theoretical foundation and implementation of AI technology. I believe the blurb should be changed to reflect the reality of the site's use. This can be done without making the philosophy questions off topic.
b2A1I9n14a1r18y25_g7l12o15b2e5The description of the site seems incorrectb2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5If questions on implementation of AI technology become on-topic, then we would have another duplicate of https://stats.stackexchange.com/b2A1I9n14a1r18y25_g7l12o15b2e5@FranckDernoncourt It's like saying, since the questions about Linux on Ubuntu or Server Fault are on-topic, then they should be duplicate of Linux/Unix SE site. Statistics are only small part of AI.b2A1I9n14a1r18y25_g7l12o15b2e5@A.W.Grossbard Can you give some few examples of the questions which you mean?b2A1I9n14a1r18y25_g7l12o15b2e5@kenorb how about only allowing non stastical AI questions here?b2A1I9n14a1r18y25_g7l12o15b2e5@FranckDernoncourt How would you force that? A.I. is self-explanatory.b2A1I9n14a1r18y25_g7l12o15b2e5@kenorb Defining the scope is up usb2A1I9n14a1r18y25_g7l12o15b2e5The reality is a lot of people come to AI instead of CV or Computational Science.  The best way, imo, to raise awareness of those Stacks is to field such questions, when basic, on AI, to introduce the concepts, and use the answers to point users (and direct traffic) to CV and CS. What new Stack users *think* AI is is a factor that needs to be accounted for.  UX for new Stack users is, in general, horrible, and trusted users need to do everything they can to facilitate new user participation.  Providing answers trumps strict adherence to the rules * guideline, imo.b2A1I9n14a1r18y25_g7l12o15b2e5@DukeZhou, It may be helpful to restate the view in the above comment, a good one, on the AI site description question initiated by Ben (https://ai.meta.stackexchange.com/questions/1430/what-should-the-ai-se-site-description-be). I, for one, would like to see a description text proposal written by you, particularly because you seem to have an overall perspective about SE's role in the www in general, like Frank, Douglas, Ken, and Robert.b2A1I9n14a1r18y25_g7l12o15b2e5Possible duplicate of [What should the AI.SE Site Description be?](https://ai.meta.stackexchange.com/questions/1430/what-should-the-ai-se-site-description-be)


















If the site description is confusing, you can always propose a new one:


https://ai.meta.stackexchange.com/q/1197/8How can we quickly describe our site?


so it can be voted.

This site comes from the https://ai.meta.stackexchange.com/q/1141/8'scientific' category, so both conceptual and scientific question are allowed, exempt the technical questions such as https://ai.meta.stackexchange.com/q/1078/8modelling and https://ai.meta.stackexchange.com/q/1081/8implementation (e.g. how to do X in the framework Y), where we've dedicated sites for such questions. It's still difficult to draw a line between https://ai.meta.stackexchange.com/q/1279/8technical vs non-technical , or https://ai.stackexchange.com/q/1297/8modelling vs implementation questions. However if you've any suggestions which can help, please share.

I think https://ai.meta.stackexchange.com/a/1236/8this post describes the site in better words:


  Artificial Intelligence Stack Exchange is a site for people interested in social, conceptual and scientific questions about Advanced Computing.

b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Kinda interesting.though most people think of artificial intelligence (AI) they think of HAL 9000 from "2001: A Space Odyssey," Data from "Star Trek," or more recently, the android Ava from "Ex Machina." But to a computer scientist that isn't what AI necessarily is, and the question "what is AI?" can be a complicated one.b2A1I9n14a1r18y25_g7l12o15b2e5One of the critiques of this Stack is that there are not enough experienced experts.  I strongly believe encouraging more science and math question would be a way of attracting such experts.  I'm even of the opinion that AI is an appropriate place for very basic questions that would also fall under the bailiwick of Cross Validated and Computational Science, and that AI can serve as a feeder to those Stacks.b2A1I9n14a1r18y25_g7l12o15b2e5@DukeZhou I absolutely agree. I came across the site, and expected to be able to ask questions about theory of the AIXI agent (for example), and was very disappointed to find that it was mostly focused on social issues. At the very least, it seems like the history of AI theory should be on-topic, and all of that is very technical. There's kind of a chicken-and-egg problem here--the site can't be properly defined until it attracts enough experts, and it won't attract experts until there are interesting questions.b2A1I9n14a1r18y25_g7l12o15b2e5@datageist That's exactly the feedback we need!  Thanks for commenting.  I took the liberty of opening up a separate meta question for this suggestion, which I strongly agree with: https://ai.meta.stackexchange.com/q/1299/1671


















I'm Pops, a Community Manager at Stack Exchange. Though it saddens me to say it, one of your moderators has decided it's time to step down. Fortunately for you, one of your fellow AI Stackers has answered the call to be your new pro tem mod:

https://ai.stackexchange.com/users/1671

Please join me in thanking NietzscheanAI for their service and in welcoming DukeZhou!
b2A1I9n14a1r18y25_g7l12o15b2e5Please welcome your new pro tem mod!b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5But we haven't elected..the community is unaware!!!!...Can someone tells us what's going on here?b2A1I9n14a1r18y25_g7l12o15b2e5@quint - right. This wasn't an election. DukeZhou was *appointed* directly by the Stack Exchange team, to be a moderator pro tempore. When the site graduates, we'll have an actual election.


















Goodbye, @Niet! I voted for you on the original pro tem nominations, and I was sorry to hear that you were unhappy with what was considered on topic and decided to step down - I hope you decide to still be generally active, even without the diamond.

To @DukeZhou: I've seen you around, here and over on Literature. You weren't active in the private beta, but that's excusable ;). I'm sure that you'll be able to take on your new duties and do them well. Thank you for volunteering for the position!
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5That last paragraph has made me think the other way.Planet earth is kinda interesting though.hands up-to you Duke.


















This is in relation to comments on: https://ai.stackexchange.com/q/2526/1671Differentiable activation function

I made the point that the question seems to fit into the "conceptual aspects of AI" covered by this stack, but T.C. countered that Machine Learning questions, in particular, are already quite fractured across several sites.  

How can we reconcile this so that the related Stacks support and add value to each other?    

I personally would welcome guidance from trusted contributors and mods on the related Stacks.



As an analogy,there is a relationship between the Humanities Stacks Mythology, Literature, Latin and Philosophy (in addition to others such as History.).  Different aspects of a single topic are best addressed in the forums where contributors have the relevant strengths.  My point is these are subjects where a fuller understanding requires many fields.   

I see this as one of the main strengths of Stack in an information explosion era with so many fields and subfields. Specifically that we can, and should, be walking "across the hall" to take advantage of the breadth of competencies Stack offers.  

Part of my inclination may derive from having been in an interdisciplinary studies program as an undergraduate.  In that program, we did not learn Science independently of History, Philosophy, Psychology, Art and Literature.  Rather, these subjects were taught in tandem.
b2A1I9n14a1r18y25_g7l12o15b2e5How can we address the fractured nature of practical AI questions across relevant Stacks?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I get the sense that this site may have moved too soon to close questions and define a strict scope early in the private beta. Something that SE should do a better job of communicating during the private beta is that while you can always close questions if they turn out to be a problem down the line, it's harder to recover from pushing certain topics away that later turn out to be very useful.b2A1I9n14a1r18y25_g7l12o15b2e5I also get the sense that if AI has problems, it's biggest problem is a lack of expertise. But of course, that lack of expertise could be caused by a scope that pushes away experts or draws people lacking experience.b2A1I9n14a1r18y25_g7l12o15b2e5@Hamlet Definitely an imperative of this stack should be to attract contributors with experience and expertise. This meta is partly in response to earlier critiques in the same vein.


















This suggestion came from a comment on https://ai.meta.stackexchange.com/q/1291another thread, but I thought it was worthy of it's own meta question, so people can vote on and discuss it.

Here is the full comment:


  "I came across the site, and expected to be able to ask questions about theory of the AIXI agent (for example), and was very disappointed to find that it was mostly focused on social issues. At the very least, it seems like the history of AI theory should be on-topic, and all of that is very technical. There's kind of a chicken-and-egg problem here--the site can't be properly defined until it attracts enough experts, and it won't attract experts until there are interesting questions."


I left the second part of the comment in to illustrate how this connects to what might be seen as our #1 imperative: to attract experienced experts as contributors.
b2A1I9n14a1r18y25_g7l12o15b2e5Should we expand Ai guidelines to include "History of AI Theory"?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5"There's kind of a chicken-and-egg problem here--the site can't be properly defined until it attracts enough experts, and it won't attract experts until there are interesting questions." whomever wrote that comment or statement does not supposed to be here nor banned from from our community in small wires of the INTERNET.We are experts/professionals here...and even might be an expert but daunting him/herself.Once again we are a small species in unified Artificial Intelligence Community.And we love, everyday it attracts new users.Humans appreciate what you have.b2A1I9n14a1r18y25_g7l12o15b2e5@quintumnia Although I also appreciate your viewpoint Q, we're doing ok from that perspective I think.  The humanities aspects of AI have been vigorously defended, at times by myself.  BUT there is a another side to the equation, and I'm working based on recurrent feedback about the weaknesses, as opposed to the strengths, of this Stack in its current form.  I do think we can reframe or expand the parameters with input from researchers, engineers and scholars, in hopes of attracting more.   The comment above was definitely not meant maliciously, but arose from desire to broaden AI engagement.


















I definitely understand the concerns about the overlap between CrossValidated, Data Science, and this site. What we need to do, to help the site get more traction, is to define that boundary in a useful way. At a high level, it wouldn't make sense to reject a site about statistics because a perfectly good mathematics site already existed. Statistics has different goals, conventions, notation, and concerns--even though it's almost all mathematics.

I'd argue that the failures of the previous sites were more a question of timing than content. Serious interest in AI is on the horizon again, very recently, precisely because of advances in ML. That doesn't mean, however, that AI proper is the same thing as ML, or needs to be focused on implementation issues. There's a large amount of theory that isn't necessarily data science, either.

We went through some of the same growing pains on Signal Processing. The approach we took there (and I'm not saying it's the right approach for AI), was to concentrate mostly on theory, and avoid implementation details. It's something that didn't exist, and it gave us a way to attract experts who weren't programmers.

Explicitly making the history of AI on-topic, however technical, might be a good starting point to help clarify what a site dedicated to AI can add to the SE network. I'm not saying that it's necessarily off-topic now, but given that MathJax isn't even enabled yet, there's currently a strong bias toward strictly non-technical questions.

I think the https://en.wikipedia.org/wiki/AIXIAIXI agent is a good example to begin discussing these issues. It's heavily mathematical, based on reinforcement learning, inspired by statistical reasoning (ala. https://en.wikipedia.org/wiki/Solomonoff%27s_theory_of_inductive_inferenceSolomonoff's Universal Prior), and uses non-computable concepts (i.e. https://en.wikipedia.org/wiki/Kolmogorov_complexityKolomogorov Complexity). So, there's a potential overlap with any number of fields, but really it's proper https://en.wikipedia.org/wiki/Artificial_general_intelligenceAGI. It's a much more practical definition of intelligence than, say, the Turing Test--precisely because it's defined mathematically. At the very least, it seems like definitions of intelligence should be on-topic, and we need math for those.

It might warrant a completely separate meta question, but I'll offer one thought on how to help clarify the scope of the site (in addition to including AI history). Let's start with https://en.wikipedia.org/wiki/Peter_NorvigPeter Norvig's definition of AI (from https://ai.meta.stackexchange.com/users/4/franck-dernoncourtFrank Dernoncort's http://www.francky.me/doc/20120530%20-%20AI%20and%20Business%20-%20CCSF%20Paris.pdfslides):


  We think of AI as understanding the world and deciding how to  make 
  good  decisions. Dealing with uncertainty  but  still  being  able  to
  make  good  decisions  is  what  separates  AI  from  the  rest  of 
  computer science.


Any discussion of decision making under uncertainty will almost necessarily involve probability and statistics. However, the challenges involved in automating those decisions effectively, in my opinion, are the domain of Artificial Intelligence, whether general or specialized. That definition also includes all of the potential social issues.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5This is very salient and useful.  AIXI personally highlights the beed to attract more experienced experts. *(I've been making a point about the problems with non-mathematical categorization of AI strength, but since I hadn't come across AIXI until you mentioned it, I've been talking about "strength" in relation to the concept of the solved game in Combinatorial Game Theory!;)*


















I was under the impression that history and theory were already on-topic. Social issues is one new topic we bring to the SE table, but academic questions (about AI as a discipline/science) are also ours to present. Key quote from a community manager https://area51.meta.stackexchange.com/a/24016/136466in the Area 51 Discussion Zone, emphasis original:


  Notice that this proposal is in the 'Science' category; not 'Technology'. Despite the creation of a Data Science site to cover this topic, the community made a sufficiently compelling case that there is a swath of questions in the academic humanities arena that are not covered by our current sites.


I realize now that when https://ai.meta.stackexchange.com/q/1252/75drafting the https://ai.stackexchange.com/help/on-topicon-topic page I forgot to include a bullet point to cover these questions. I apologize for the oversight and have corrected it. As always, suggestions for improvement to that page's contents are welcome!
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Ok, great. Thanks for the clarification Ben.b2A1I9n14a1r18y25_g7l12o15b2e5@BenN ,Thanks for the great insightful knowledge.Lets have some chips and wines.though virtually.


















Currently, we have the tag https://ai.stackexchange.com/questions/tagged/nlpnlp. Now that we have 35 characters in tags, can we change this to https://ai.stackexchange.com/questions/tagged/natural-language-processingnatural-language-processing?
b2A1I9n14a1r18y25_g7l12o15b2e5Rename [nlp] to [natural-language-processing]b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Hmm, I also notice a [`natural-language`](https://ai.stackexchange.com/questions/tagged/natural-language) tag with some overlap. Should anything be done involving that tag?b2A1I9n14a1r18y25_g7l12o15b2e5@Ben - that may be worth its own meta postb2A1I9n14a1r18y25_g7l12o15b2e5@BenN I saw 2 tags language processing and nlp..aren't the two synonyms?


















Done - a https://ai.stackexchange.com/tags/synonymstag synonym has been created and https://ai.stackexchange.com/questions/tagged/conv-neural-networkconv-neural-network has been merged into https://ai.stackexchange.com/questions/tagged/convolutional-neural-networksconvolutional-neural-networks, thereby updating all existing questions. This has the added benefit of making the tag name consistent with all the other pluralized ones.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5This might warrant an additional post, but isn't [tag:cnn] a synonym of [tag:convolutional-neural-networks]?b2A1I9n14a1r18y25_g7l12o15b2e5@wythagoras Yes, on the whole [cnn] is indeed just a shortened version of the latter, though there was one question that used the former to refer to "cellular neural network," which I just edited. I think the discussion of whether and how to synonymize and/or rename [cnn] would indeed merit a new meta question.



















  I made the point that the question seems to fit into the "conceptual aspects of AI" covered by this stack, but T.C. countered that Machine Learning questions, in particular, are already quite fractured across several sites.


I believe most ML questions are on CV. Then DS got created, which has a huge overlap with CV, and a more trendy name. So one way to avoid fracture is not creating new Stacks with huge overlaps (https://ai.meta.stackexchange.com/q/4/4Are all questions asked on stats and data science SE also on topic here?).


  How can we reconcile this so that the related Stacks support and add value to each other?


https://meta.stackexchange.com/q/199989/178179Build and strengthen the Stack Exchange community with "crossover questions" between sites


  Part of my inclination may derive from having been in an interdisciplinary studies program as an undergraduate. In that program, we did not learn Science independently of History, Philosophy, Psychology, Art and Literature. Rather, these subjects were taught in tandem.


In practice, the development of AI models doesn't care much about History, Philosophy, Art and Literature. Most AI experts focus on the models, which tend to be statistical, therefore on-topic on CV. 
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Thanks for this enlightening answer.  I am aware that the humanities don't bleed into AI unless we're talking AGI, but it seems to me combinatorics, game theory, and several fields of mathematics relate to AI development in general.  What I was really trying to get at is that the separate AI stacks should be more related to promote cross-stack participation.


















I Searched for the PGM tag to subscribe to but could not find it. 

IMHO, Probabilistic Graphical model is an essential branch of AI

Thanks 
b2A1I9n14a1r18y25_g7l12o15b2e5Proposed Tag: Probabilistic Graphical modelb2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Please make a more elaborate case for this tag.  (I'd have no problem adding it, especially if we get a question that involves PGM, but it's not a subject I have any background in, so I can't make the determination as to the utility of such as tag with so little information.)b2A1I9n14a1r18y25_g7l12o15b2e5@DukeZhou After this my meta post, https://ai.meta.stackexchange.com/q/1538/2444, you can see that we have a tag [tag:probabilistic], which, IMHO, should be deleted. A probabilistic graphical model is a quite important concept in AI. A PGM can be directed (Bayesian network) or undirected (MRFs). PGM are also associated with the concept of causation, which is a really important concept in AI.b2A1I9n14a1r18y25_g7l12o15b2e5@nbro let me know you thoughts on replacing the "probabilistic" tag.  (Skimming the  21 instances now.)  Also, am I reading your comment correctly in thinking we should also create a "probablistic graphical model" tag?b2A1I9n14a1r18y25_g7l12o15b2e5@DukeZhou I would need some time to review all the questions that are currently tagged as "probabilistic", but the tag probabilistic, IMHO, makes little sense anyway, so I think it should be deleted or replaced, but, as I said, I need to review all those questions first to give you my opinion regarding the idea of replacing it with PGM.b2A1I9n14a1r18y25_g7l12o15b2e5[Questions like this](https://ai.stackexchange.com/questions/5177/please-explain-this-log-probability-function-what-does-each-part-mean) don't seem to be PGN, but do make me wonder if there is some need for a general probability tag...b2A1I9n14a1r18y25_g7l12o15b2e5@DukeZhou I think that this why we have the tag [tag:math]. I think that the tag [tag:probability] (but _not_ probabilistic) would also be ok on this website, given that [tag:probability] is a widely known topic and it is highly related to AI.b2A1I9n14a1r18y25_g7l12o15b2e5@nbro strongly agree.  Quick fix may be to replace probabilistic with probability, then look for opportunities to utilize the PGN tag in specific cases.  (I'll look to do that shortly for probabilistic, in addition to merging the remaining "natural language" into the "natural language processing".


















We currently have both https://ai.stackexchange.com/questions/tagged/cnncnn and https://ai.stackexchange.com/questions/tagged/convolutional-neural-networksconvolutional-neural-networks. 

Should https://ai.stackexchange.com/questions/tagged/cnncnn be a synonym of https://ai.stackexchange.com/questions/tagged/convolutional-neural-networksconvolutional-neural-networks?
b2A1I9n14a1r18y25_g7l12o15b2e5Should [cnn] be a synonym of [convolutional-neural-networks]?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Well, they have the same meaning so I'm in support of this


















Yes.
They both mean the same thing, so we should have only one tag. They should be synonymized, because if you type cnn the tag https://ai.stackexchange.com/questions/tagged/convolutional-neural-networksconvolutional-neural-networks does not come up as a suggestion, and vice versa.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Done - a synonym has been created and [cnn] has been merged into [convolutional-neural-networks].b2A1I9n14a1r18y25_g7l12o15b2e5@Ben - answer with that, maybe?


















Gaming in the computational sense really refers to video games which are distinct from combinatorial games (board games, card games, etc.)  

My feeling is that the approach to these general categories has been distinct, and only recently have algorithms proven on combinatorial games been extended to video games (AlphaGo).


Should we add a "combinatorial-games" tag and replace the gaming tag on questions relating to Chess or Go, for example? 

b2A1I9n14a1r18y25_g7l12o15b2e5Do we need to disambiguate the "gaming" tag?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I don't know how games are made but as far as I heard shouldn't combinatorial games be those games in which all future outcomes are known? In chess the outcomes are very large to be computed and rest of most games (survival, strategy) follow the rule of different result for different decisions...so the remaining games like (fps, arcade shooting games) should really have no aspect of AI and so its unlikely people will ask questions about those under the gaming tag...b2A1I9n14a1r18y25_g7l12o15b2e5By rpg i meant fps gamesb2A1I9n14a1r18y25_g7l12o15b2e5@DuttaA Combinatorial Game Theory seems to be a fairly esoteric field, and the scope is always expanding based on what games can be fruitfully mathematically analyzed.  (I researched the field for a couple of years and was finally forced to reach out to some luminaries to get a handle on it.)  Intractability is not a requirement, but the focus in CGT is definitely solving games mathematically.  Tic-tac-toe is trivially solved and useful for that reason.b2A1I9n14a1r18y25_g7l12o15b2e5@DuttaA General game AI is a huge field (most AI for complex games suck today, but that is surely a temporary condition based on how NNs are performing against humans in games with significantly fewer parameters.  Of course, there's a greater "combinatorial explosion" to contend with in the high-level games...)  But, for instance, there is a current drive to develop a machine learning algorithm that can beat the top humans at Starcraft.  When they achieve it, it will be a very big deal: https://www.technologyreview.com/s/609242/humans-are-still-better-than-ai-at-starcraftfor-now/b2A1I9n14a1r18y25_g7l12o15b2e5Side note: In my experience, even the most complex 4x games out today pale in comparison to Chess and Go in terms of strategic depth and nuance.  In other words, high-level games with hundreds of rules are not as deep as the most durable intractable abstract games b/c it's about compactness-to-complexity ratio, not sheer complexity.  Compact combinatorial games are the most efficient chaotic systems I am aware of.


















I'm Pops, a Community Manager at Stack Exchange. Though it once again saddens me to say it, one of your moderators has decided it's time to step down. Another of your fellow community members here on AI SE has answered the call to be your new pro tem mod, though:

https://ai.stackexchange.com/users/4398

Please join me in thanking Matthew Graves for his service and in welcoming Jaden Travnik!

Those who are keeping a close eye on meta may remember https://ai.meta.stackexchange.com/questions/1293/please-welcome-your-new-pro-tem-modan announcement similar to this not that long ago. To address some of the issues raised implicitly and explicitly there:


Jaden, like your other mods, is a moderator https://stackoverflow.blog/2010/07/27/moderator-pro-tempore/pro tempore. All Stack Exchange sites in public beta have moderators appointed by the SE staff (people like me). You'll get to elect moderators on your own if and when your site graduates.
Graduation is, to oversimplify a bit, based primarily on question volume. We ran an analysis a couple years ago to make the process more data-driven and found a correlation between questions per day and site health. For more on that, and our philosophy, see https://meta.stackexchange.com/questions/257614/graduation-site-closure-and-a-clearer-outlook-on-the-health-of-se-sitesGraduation, site closure, and a clearer outlook on the health of SE sites on the network meta site.


(If you have questions about graduation, please post a separate meta question.)
b2A1I9n14a1r18y25_g7l12o15b2e5Please welcome another pro tem mod!b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5,pops you always disturb my mind even though am not perfectly human!b2A1I9n14a1r18y25_g7l12o15b2e5Congratulations @Jaden! And I'm glad that you found someone else, Pops - I'm sure Jaden will do a good job ;)b2A1I9n14a1r18y25_g7l12o15b2e5You did a great job Matthew, I personally enjoyed your contribution. Congratulations Jaden. I'm very excited regarding your new position. It will be great to have you as our mod


















I've been active on several different SE sites during the last years and I haven't seen any other community that's so fast with downvoting questions, especially without providing helpful comments.

I am all for strict rules and enforcing high quality content. But with a small site like AI that still https://area51.stackexchange.com/proposals/93481/artificial-intelligenceneeds to polish its numbers after over 400 days in beta we should be careful not to go over the top.

In case a question is definitely off-topic or not salvageable quality wise, it needs to be treated accordingly and it should be closed. But when I come here I am often greeted by several new questions with just a few views but the first downvotes already. No explanations are given and (the often new) visitors are left with a bad feeling and no idea what they did wrong. When I go over their questions it is sometimes difficult for me to understand why they have been downvoted. I don't feel like that's the right approach to grow the site and attract new members.

Am I on the right track or do you disagree? Is a strict (and maybe a little hostile) environment necessary to keep the quality high, at the cost of losing potential members who might create valuable content if we give them feedback and time to get accustomed to our community?
b2A1I9n14a1r18y25_g7l12o15b2e5Are we too fast downvoting questions, especially for newcomers?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5We probably do need to be better at leaving comments. But quick downvotes are good - if they deserve them. But yeah, leaving more comments would be good.b2A1I9n14a1r18y25_g7l12o15b2e5I have faced the same, when I joined stackoverflow.  It's really worst feeling to get downvotes without any comments. At least downvoter should write the comments so that author can correct his question.


















This could easily be solved by requiring a comment for downvotes on new stacks or on new user questions.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I support this idea and almost never downvote without comment with an exception for already commented but not corrected posts. However, on StackOverflow meta my similar suggestion was downvoted more than 100 times before deleted


















Folks:

Like it or not, people are going to continue to post variations of the "How do I get started in AI" question.  No matter how many get closed and marked off-topic, they're going to keep showing up. And closing them, while arguably "correct" in a pedantic sense, is not contributing to a good user experience for users of this site.  It's especially galling that we're going to leave bad taste in the mouth of newbies who are just trying to get started, only to (from a subjective, personal perspective) have a door slammed in their face.

I feel like we need to do something to address this.  An obvious choice would be to write a "getting started guide" and link to it somewhere in the sidebar on the right hand side of the page.  Another option might be to pick one of the existing "getting started" questions", pin it to the front-page somehow (might take special support from SE staff??) and make it the one, sole, "blessed" newbie thread.

Possibly there are other options, but I strongly feel that we need something in place to address this question.   
b2A1I9n14a1r18y25_g7l12o15b2e5Can we create something to permanently deal with the "Getting Started" question?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Thanks for raising this issue.  I strongly agree, not just on new user engagement, but b/c I think simple, fundamental questions have value. (it's also a way to engage experts, and provides opportunities for them to get rep by providing comprehensive answers on subjects where they have applied experience.)  Because overall engagement is still quite low, this is a tough stack to get rep on.


















Sites like SuperUser.SE and Physics.SE deal with this by having a set of “canonical” questions. These are usually specific questions/answers that are very specific but very well explained. 

I imagine that approach could very well apply here too, and the SE system already provides support for it. 

Update

I think this link provides a lot more information. https://meta.stackoverflow.com/q/291992/147507https://meta.stackoverflow.com/q/291992/147507

To sum it up: there's currently thing "special" about the canonical questions and answers, aside from being asked and answered very thoroughly, and sometimes with varying levels of detail, so that it handles most users questions.

Into how they are suggested to users: they go through the same process as every other question, by appearing on the sidebar or searches. (See notes https://meta.stackexchange.com/a/112438/335458here). If the question is properly redacted and the answers are detailed enough, it should pop up among suggested answers, and users should find it relevant to their search/question.

How to generate them? As simple as it sounds: once identified, start a new question, write the hell out of it, which will get it upvoted, and let it sit around. Maybe save the link if we're thinking in closing questions as duplicates to it.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Interesting.  How are the "canonical" questioned denoted?b2A1I9n14a1r18y25_g7l12o15b2e5@mindcrime Sorry I'm kind of in a hurry now. Here's how Physics.SE dealt with it. I'll come back and expand later on: https://physics.meta.stackexchange.com/questions/6060/do-we-want-and-need-a-set-of-canonical-questions-with-canonical-answersb2A1I9n14a1r18y25_g7l12o15b2e5@mindcrime There it is! Sorry it took me so long to get back to this.


















According to my scope of the subjects. Artificial intelligence in a very strict sense should only contain questions pertaining to how we can create truly intelligent (creative, aware, etc.) machines. Whereas data science is directly the manipulation of data in order to produce tools to make something better (image detection, intrusion detection, etc.). The separation is very blurry and I do not think that intelligence can exist without information/data, and its manipulations. However, most machine learning and deep learning demonstrated are simply conducting complex function approximations.

However, due to the popularization of machine learning and especially deep learning, the manipulation of data has created the impression of intelligent machine due to it being capable of competing with human performance in very targeted tasks (object recognition, segmentation, etc.). Evidently, the name artificial intelligence catches people's attention much more than data science or machine learning. Thus, it is common for news which is essentially generic data science/machine learning to be called artificial intelligence.

This is further demonstrated on the Artificial Intelligence site where the majority of the questions are pertaining more to data science and machine learning than truly discussing possibilities, methods or emerging work pertaining to machines capable of intelligence.

This niche can easily be encapsulated into a site that combines both Artificial Intelligence and Data Science.

Post on Data Science is found https://datascience.meta.stackexchange.com/questions/2352/should-this-site-be-combined-with-the-artificial-intelligence-stack-exchange/here.
b2A1I9n14a1r18y25_g7l12o15b2e5Should this site be combined with the Data Science stack exchange?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5See my answer below.  The Cross Validated community was apparently unhappy when Data Science launched, because of the profound overlap with an established Stack (CV.)  AI is distinct because we also deal with the philosophical and social impacts, the game theory aspects of AI, and combinatorial games, which are used in AI proving.


















Though we get a lot of (off-topic) questions about data manipulation and implementation issues in general, this site was created to serve questions that aren't so quantitative. For some more info on our scope, see the https://ai.stackexchange.com/help/on-topichelp center. Admittedly, we are currently doing an incomplete job of making the scope clear to new users and handling off-topic questions. Nevertheless, it is clear from https://area51.meta.stackexchange.com/a/24016/136466this Area 51 Discussion Zone post by a Stack Exchange community manager that this site is for AI as a science, not as a technology to be implemented:


  Notice that this proposal is in the 'Science' category; not 'Technology'.  Despite the creation of a Data Science site to cover this topic, the community made a sufficiently compelling case that there is a swath of questions in the academic humanities arena that are not covered by our current sites.


Social, conceptual, and philosophical aspects of AI are on-topic here, but not on Data Science, which is a more technical site. There is some overlap in architectural questions, but there is much precedent for sites' topics not being fully disjoint — Stack Overflow and Super User on PowerShell questions, for example. Combining our slightly subjective questions with Data Science's technicality would be mixing two different types of questions (and two different communities).

In short, this site and Data Science are looking at different aspects of artificial intelligence. Both sites are valuable, each with its own knowledgeable people, and it would be good to preserve the distinction.

Relevant MSE: https://meta.stackexchange.com/q/68214/295684Can Stack Exchange follow a more generic approach?
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Take a look at the new questions currently on the site. I think due to the media calling machine learning, artificial intelligence, and the unclear border between both of these topics, this site contains more off-topic questions than on-topic ones. We should just combine both sites and extend the scope to implementation and philosophical discussion.b2A1I9n14a1r18y25_g7l12o15b2e5Most individuals who have insight on the philosophical or ethical aspects of AI are studying the machine learning/data science. The ultimate goal of data science/machine learning is an autonomous AI. So as time progresses the data science site and the AI site will become more indistinguishable.


















Hellz No!  Where would people ask philosophical questions related to AI, or discuss theoretical topics?  What about the Mythology of AI?  (Off-topic at Stack:Mythology, but is the predominant influence re the public's perception of AI.)

Morality of AI applications is a critical issue, only increasing, as are social impacts of AI.  This Stack is the forum to discuss them.

This is also the Stack for Game Theory as it relates to AI, and combinatorial games, which are inextricably related to AI, in that they are still used for AI proving.

I'd propose, as the Cross Validated community has, that Data Science should probably be rolled into that Stack, and CV should probably adopt the name "Data Science" so people know where to go for those questions.  (i.e. "CV" is cool, but it's insider-ey, and noobs don't know that's the place to ask Data Science questions related to AI, and come to SE:AI.)

Do I don't think the problem is with the AI Stack at all.  The humanities size of the equation, which is the core of this stack, should not be handled on a Data Science forum.

I think the solution would be to revise our "Community Guidelines" to be very clear about which questions should go to CV/DS, reposting their guidelines as a sub-section to AI's guidelines, and try to get some involvement from the CV/DS forums on which questions to migrate, so we don't accidentally migrate questions they don't want. 
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5This site gets a very small number of questions pertaining to the humanities regarding AI. It can easily be engulfed into a single site. Moreover, as I explained, most people with interesting insight about the ethics, mythology, etc of AI have practical experience with the subject. Thus they are well equipped to answer both flavours of questions. Why not make it more convenient by having both in a single place?


















No.
If a question is on topic, then it should stay here. Migrating is for high-quality, but off topic questions. This is why migrating a question involves closing as "off-topic". In this case, they're not off topic - they just haven't gotten an answer.
Now, why don't they have an answer? Probably because there's nobody on the site who knows how to answer it... or the right person just hasn't seen it. If nobody on the site knows how to answer a question, then the best thing to do would be to attract users who do know how to answer the questions, namely, "experts".
How do these "experts" find the site, though? Usually through content already on the site - it'll come up in a Google search or something. So to attract the experts, you need content, and if you send all the content away, then AI.SE won't get new users and the site will stagnate.
There's nothing wrong with having some unanswered questions around, as long as not all questions are unanswered. And if that happens, the site's got a big problem.
See also https://meta.stackexchange.com/a/212271/294691Meta.SE guidance on migrations.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5A few of us in my lab are interested in reading your perspective on the AI SE outfacing description at https://ai.meta.stackexchange.com/questions/1430/what-should-the-ai-se-site-description-be.


















If we look at the curriculum of AI in any university, we will find as topics: agents, neural nets, supervised/unsupervised learning ... . In a few ones, an small part about AGI or mind.

It is not surprising that this site receives (and answers) a lot of questions about previous subjects. All the more because only a 0.0001% of people (not me) will thing in a site called "cross validated" to ask about neural nets.

However, the description of this site talks about "conceptual questions about life and challenges in a world where cognitive functions can be mimicked in purely digital environment." that not only excludes all previous, but even AGI seems off-topic.

This fact means that we should reject 99% of the questions and flag them as off-topic instead of answer them doing in this way an off-topic answer. 

In my opinion, there are a disagreement between name and site description. More opinions are welcome ...
b2A1I9n14a1r18y25_g7l12o15b2e5Are name and description of this site in disagreement?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I don't think you can have an AI site without questions on NN or ML. Although a separate site exists does not mean we cannot admit questions on ML. The same question arose on CV.se and datascience.se. And if we see stats.se, dataS.se and Cv.se are much more overlapping than AI.se.


















This might seem a bit opinionated, but since I joined AI.SE I have seen a lack of biological questions on this site. Neurobiology was one of the main influence of AI, but I don't see questions on the same. Questions on topics like brain, neurons, swarm-intelligence, etc. What can be done to explore the biological side of AI on this site?
b2A1I9n14a1r18y25_g7l12o15b2e5Biological aspect of Artificial Intelligenceb2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5That was brought up at P&N also: https://psychology.meta.stackexchange.com/q/128/19897b2A1I9n14a1r18y25_g7l12o15b2e5There's a few questions on our https://bioinformatics.stackexchange.com/questions/tagged/machine-learning site, see also: https://en.wikipedia.org/wiki/Machine_learning_in_bioinformatics


















Simple:

Ask more questions on the biological side of AI

That is pretty much it. 
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I get it...but we also need someone who will answer them...in short how can we diversify  our community more towards the linguistic and biological aspects..


















This has been proposed:


  For questions about current affairs about various types of contributions/theories proposed by different groups/communities identifying themselves as AI researchers/practitioners/enthusiasts.


This is not a subject I've given much thought to, but it's important in that it defines what we mean by "AI community" in context so please post any thoughts, suggestions, revisions or alternate proposals.
b2A1I9n14a1r18y25_g7l12o15b2e5What description do we want for the "ai-community" tag?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Self-learning is a tag that caught my eye...It has questions on self-learning ai and also beginners asking for learning resources...What should be done about that?b2A1I9n14a1r18y25_g7l12o15b2e5@DuttaA great point about "self-learning".  I just killed that tag (per the confusion) and replaced with "unassisted-learning", except for the handful of questions that were actually "getting-started".


















I guess this is my field. I'm researching the evolutionary development of human intelligence from non-intelligent roundworms. This is one part within the broader research on developing a general theory of intelligence and duplicating it non-biologically. This work seems to be unusual here since everyone else I've come across seems to assume that human reasoning is definable within Church-Turing.

I can't provide a lot of technical detail because it is unpublished and because it would take entire chapters to explain, but I can give general answers about what I know.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Keep visiting the site then..I had asked a few biological questions but the response to most of them was rather poor and computational based


















I have some information that is not publically available based on research that I've been doing for the past several years. I can't cite it since it isn't published. Yet it is considerably more advanced and in agreement with observed evidence than theories that usually get mentioned like Integrated Information Theory or Global Workspace (both of which can be disproved). It won't be published until it is completed and no earlier than 2021. So, I can either withhold what I know (which would be quite odd considering that proton decay was talked about for years before it was disproved), or I can answer without citations.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5This is a worthwhile concern. I think that as long as you explain why you hold the position you do (as opposed to just posting a one-line assertion), that should be considered sufficient support.


















I recently replied to a post on ai stackexchange, and I noticed that it is not possible to insert equations, unlike other websites like crypto stackexchange for example. I believe the library used on the latter to create mathematical equations is MathJax. Why is not there a similar tool on ai stackexchange? Wouldn't this be a very useful tool to use in posts?
b2A1I9n14a1r18y25_g7l12o15b2e5Math equations on AI stackexchangeb2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5TL;DR: I've poked the staff a couple times, they said they're considering it, and I think a site mod should send them an email.


















I have recently noticed that even the oldest questions have small errors in them. I think that this could be improved for future generations, both to improve readability and as a record. 

First of all, I want the mods/reviewers to know this is going on, and that I will be correcting the following:


Spelling
Grammar
Word choice 
Moving links to inline when they only appear once (Not a reason for editing by itself)


I, of course, don't want all of the rep, so I welcome other users to participate.

Also, I want input from a few mods ♦   on this.
b2A1I9n14a1r18y25_g7l12o15b2e5I am going to be editing the old questions forward. Any opinions?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5If I find a question that should have been deleted, should I post the link in the comments here so a mod can delete it?b2A1I9n14a1r18y25_g7l12o15b2e5Dropped off on post [#73](https://ai.stackexchange.com/questions/37/what-is-a-markov-chain-and-how-can-it-be-used-in-creating-artificial-intelligenc/73#73). Will resume as soon as my review queue has been cleared considerably.b2A1I9n14a1r18y25_g7l12o15b2e5I've been working my way through, and approving.  Thanks for taking the time to do some house cleaning!  The "action-recognition" tag need some work--not sure of the meaning...  (So far, everything else looks good.)b2A1I9n14a1r18y25_g7l12o15b2e5@DukeZhou thanks! My only worry is that others will not participate.b2A1I9n14a1r18y25_g7l12o15b2e5Picking up on post [#73](https://ai.stackexchange.com/questions/37/what-is-a-markov-chain-and-how-can-it-be-used-in-creating-artificial-intelligenc/73#73)b2A1I9n14a1r18y25_g7l12o15b2e5Dropped off on post [#4051](https://ai.stackexchange.com/questions/92/how-is-it-possible-that-deep-neural-networks-are-so-easily-fooled/4051#4051). Review queue bottle up. I hope you stay with me for these first few times, but I have been told you are permitted more edits in the queue the more you have approved.b2A1I9n14a1r18y25_g7l12o15b2e5Picking up on post [#4051](https://ai.stackexchange.com/questions/92/how-is-it-possible-that-deep-neural-networks-are-so-easily-fooled/4051#4051). Some of the queue was cleared.b2A1I9n14a1r18y25_g7l12o15b2e5Dropping off on post [#4011](https://ai.stackexchange.com/questions/94/what-is-the-significance-of-weights-in-a-feedforward-neural-network/4011#4011). Review Queue bottled up.b2A1I9n14a1r18y25_g7l12o15b2e5IMO, moving links which are in Markdown end-of-text format into being inline is counterproductive. The tools which exist for editing on SE are designed to put links in end-of-text format. Moving them inline may make it harder for the OP to edit their post, if they choose to do so. IMO, these should generally be left in the format in which they already exist in the post. This is similar to changing the indenting of code from one valid, common format to another valid, common format, just because you prefer it. OTOH, if the links are actually malformed/non-working, then they should be corrected.b2A1I9n14a1r18y25_g7l12o15b2e5@Makyen I had decided with another mod that I would leave them in the footer if there were more than 3 links. I apologize for the fact that I did not post this here, but that is what happened.


















That sounds good to me. 

A couple things to keep in mind: Especially when submitting suggested edits, please make sure to fix all problems with the post — this saves reviewer time and minimizes bumps. I'm not entirely certain what you mean by "moving links to inline when they only appear once," but if you're referring to the Markdown inline link style (as opposed to footnote style), please submit only edits that make improvements to the rendered post. Cleaning up the Markdown in the process of making helpful visual changes is good, though. Starting from the oldest posts and proceeding to the newest is a good idea because it keeps newer content nearer the top of the front page.

Thanks for helping improve AI.SE!
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I do my best. Also, if you could look at even a few of my edits, it would help a lot.b2A1I9n14a1r18y25_g7l12o15b2e5@Pheo Just be understanding that the mods, like yourself, are donating their time, and new questions and, where available time is limited, answers have to take priority.b2A1I9n14a1r18y25_g7l12o15b2e5@DukeZhou I appreciate the time you guys have taken, also.b2A1I9n14a1r18y25_g7l12o15b2e5@BenN Thanks for taking some of your time to work on my queue. I can't wait until I have full edit privs though, so I could not bother you guys as much with the queue:Pb2A1I9n14a1r18y25_g7l12o15b2e5@BenN I am going to postpone this project, until I have edit privs. I might do 2 or 3 a day, but thats it for now.


















When AI.SE was about to be created, there was a divide. A few wanted ML and implementation details to be part of the site; most wanted to exclude them. The final agreement was to exclude---so the current topic list excluding explicitly implementation details and so on.

The reasoning back then was that popular frameworks like Tensorflow, etc. were explicitly asking to question on SO. Questions about Data Science were perceived as much better fits for Cross Validated, etc. So no need to duplicate them here, and take the risk of killing AI.SE before it gets momentum. That was an interesting thinking, and I think the result is okay.

Now it seems that many AI.SE questions are about ANN, including popular subcategories like CNN, DNN, RNN, etc. The community here seems to expect xNN Q&A, so the description and topic list do seem like a mismatch---I concur (and that is how I found your question, searching for such a discussion). Another way to put it: How can we "make a mind™" without talking about techniques and tools we have at present?

IMHO it may be time to update description and topic list, to define a posteriori the scope of AI.SE.



Note:


The current description does include AGI, though. Terminology is quite vague, but an AGI could be a "set" of "cognitive functions [...] mimicked in purely digital environment." As for theory, models, notions, concepts, the current scope has been carefuly thought through, IMO.
Let's keep in mind that AI.SE is the 3rd attempt to create an AI-related SE site, and the most successfull so far (the previous attempts topped at 6 months before closing). This AI.SE is on something (and the current "market" makes it easier with the DL wave).




Disclaimer: I was part of the first group, so I am biased in my agreement. However the sheer volume of xNN questions might be a data-backed confirmation the site needs an update (I did not go beyond lazily listing and eye-balling unanswered questions).
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I think sometimes to be successful we have to be versatile and do the cumbersome jobs also...that is why this site is going on well...even area 51 tells that the questions per day is increasingb2A1I9n14a1r18y25_g7l12o15b2e5More than sometimes...b2A1I9n14a1r18y25_g7l12o15b2e5Deep Learning must be added (I think Machine Learning as well).


















So I don't know why but suddenly there is a spurt of "Close Vote" revies in my queue. It probably has something to do with the mass editing of posts by @Pheo. What exactly is the community policy for this matter? Because most of the question are pretty highly up-voted like:

https://ai.stackexchange.com/questions/3965/deducing-the-features-from-the-data-setDeducing features from the data-set

https://ai.stackexchange.com/questions/5981/computing-resources-needed-for-reinforcement-learning-machine-imageryComputing resources needed for Reinforcement Learning/Machine Imagery

I want to know what is the suitable action in few of these example questions. Should the mods do something?
b2A1I9n14a1r18y25_g7l12o15b2e5Spurt in Close Votesb2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I have made a total of 0 close votes. Just saying. And if you look at the questions, there are 0 flags towards closing. Odds are it does have something to do with me indirectly, though...b2A1I9n14a1r18y25_g7l12o15b2e5Could someone give me specs on this: "Chance that the system has detected that standards are changing"b2A1I9n14a1r18y25_g7l12o15b2e5@Pheo As far as I know, the system does not have any knowledge of site standards. Questions are never pushed into Close Votes without a human thinking it should be closed, but for what it's worth, there are some text heuristics that push things into Low Quality Posts.b2A1I9n14a1r18y25_g7l12o15b2e5Unless a post is egregious, and clearly off-topic, I try to follow Ben N's lead on closure, since he's been modding here the longest.  But it's rare a day passes when I don't have at least 1 close vote in my queue.  I think, because we're still Beta, and still defining ourselves, the close votes can be taken as dissenting opinions on the scope of this Stack.  It's good for us to get those opinions, but in general, we seem to prefer leniency.  (I personally prefer to try and salvage questions, as opposed to closing.)


















Edits don't cause things to head to the close vote queue. Edits on a closed question will sometimes push a question into the reopen queue, but never the close vote queue.

So for some reason, someone must have gone through and manually cast close votes/flags, pushing it into the queue.

Votes shouldn't affect the action you take on the post - if it was highly voted but then determined to be off topic, close it. If it's not close-worthy, leave it open. Each question should be judged on its own - if the standing policy on a specific type of question is that it should be closed, review it and pick the appropriate close reason. If you don't, pick Leave Open.

Unless someone is flooding the Close Votes queue with a mass of on topic questions, I don't think that any moderator action is necessary. There's nothing wrong with going through old questions that should be closed (although some would consider it a waste of time).
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Well should i vote for it or against it?b2A1I9n14a1r18y25_g7l12o15b2e5@DuttaA - I can't give you an answer for every question individually, you have to judge each one by yourself.b2A1I9n14a1r18y25_g7l12o15b2e5@DuttaA do what you feel is right in terms of voting for closure.  Again, because we're Beta, I think it's in our interest to attempt to salvage as many of them as we can, the most basic, beginner question in particular (i.e. the people who are still so new to Stack, or the field of AI, they don't yet know how to ask questions.  As an analogy, it's taken me quite a while to learn what types of questions are appropriate on SE:Math b/c I'm coming from outside the field.)


















I am not asking this question to criticize or nullify someone's effort. I have been noticing that since the last few days, when @Pheo started editing (which is a good thing) that new questions which are being asked by "new" users are getting minimum views. 

My question is should the "moderators" accept so many edits at a single time so that new questions get buried among the old questions? The old questions have a clear advantage in terms of reputation of the OP, views, upvotes, and general title. So what does the moderators think is a solution to the problem? 
b2A1I9n14a1r18y25_g7l12o15b2e5New questions getting buried in old questionsb2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I think a solution would be to pin a question, and have a list of new questions on it. Re-create the "active questions" slide. Just a friendly input from me. :)b2A1I9n14a1r18y25_g7l12o15b2e5Maybe we could take a look at some of SmokeDetectors code? Salvage something from there, and make a new question feed. Or, as I have recently seen, we could scrap some from the AI meta Questions Feed bot.b2A1I9n14a1r18y25_g7l12o15b2e5Hey, is there any way we can watch this: https://stackexchange.com/questions?tab=realtime, with something automated?b2A1I9n14a1r18y25_g7l12o15b2e5@Pheo Your suggestions here only address a small portion of the issue. For the significant majority of users, they are just going to use the tabs/pages which are available as stock destinations from SE. If anyone wants to see just new questions, they can do that, at least on a tag-by-tag basis. Nothing that's done to create a new, non-stock place for people to go will result in most people who already use the home page moving away from doing so. Thus, that type of solution won't solve the problem.b2A1I9n14a1r18y25_g7l12o15b2e5On SO, this type of bulk cleanup, particularly by users without full edit privileges, is not encouraged, for precisely this reason (i.e. it disrupts the use of the site for a significant number of people and harms the reception of new questions). When done, it's requested that the user either: edits all posts they are going to do in one large set, so the disruption to the homepage/tag activity pages is confined to one time and rolls off; or only does a few, every few days (or every day, if question volume is high enough), so those pages remain *primarily* questions not involved in these edits.b2A1I9n14a1r18y25_g7l12o15b2e5@Pheo In addition, it's requested that the user correct *all* problems, at least those that are obvious, which you have not done in some cases. In addition, some of your edits have been what I'd consider [pedantic formatting choices](//ai.stackexchange.com/posts/79/revisions). I'm not saying they're necessarily wrong, but I wouldn't edit/bump a post just to make that sort of change, as it doesn't actually help readability. I *certainly* wouldn't edit for just removing double spaces between a period and the first word in a sentence (a style choice by the OP, which while antiquated, is valid).b2A1I9n14a1r18y25_g7l12o15b2e5@Makyen what you are doing has a side effect of discouraging me. I understand that any method that moves users away from the main page is not a good habit. I also happen to understand the difference between users with edit privs, and those without. I also happen to want you to note that the number of posts to be edited is *__massive__*. I (I hope others are also) am working back from page 103 on the questions list. As for the edit privs, I hope to reach those soon. As for being pedantic, that is one of my greatest skills: feedback. And things that are valid are not necessarily valid still.b2A1I9n14a1r18y25_g7l12o15b2e5Apart from that I agree with you.


















I think I have found a solution to this. 

Until I attain edit privileges, I am only going to do a few posts a week - Making sure that everything on them is as it should be (Taking critical issues into consideration first). As much as this is going to slow the progress down, the quality will go up greatly. As a plus, I will have more practice and a lot more time for feedback per capita per post.

I hope the majority of you stand with me, but regardless, I am going to do this. Please note, I have not drawn into the shell of seclusion, but merely been scolded and found a corner for myself to sit in for a while.

TL;DR

I am going to be cutting back on the number of time per post and increasing the time spent on each post. In other words, keeping the impact down.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5As a wider community, all the SE sites encourage editing to improve quality and it has always been a challenge balancing the improvements with the front page bumping. Taking things a little bit slower, especially on a lower traffic site, is going to help. Remember, once you have edit privs, edits will still bump a post to the front page. They will just require less effort.b2A1I9n14a1r18y25_g7l12o15b2e5Thanks for moderating your initiative.  "Moderation in all things!" *(but, that can also apply to moderation itself;)*b2A1I9n14a1r18y25_g7l12o15b2e5@DukeZhou Sometimes you have to change when the ways get hard.


















For years, users have asked Stack Exchange to add an option not to bump a question/answer when it gets edited. Until this gets implemented, there will be some awkward balance between keeping imperfect content that could be edited and not burying new questions.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Thanks for weighing in.  I recognize DuttaA's concern, and there was an initial flood, but imo, it can also be useful to bring some of the old questions to light for subsequent evaluation.b2A1I9n14a1r18y25_g7l12o15b2e5@DukeZhou yes: bumping should be optional


















This is a known issue with all Stack Exchange sites currently: https://meta.stackexchange.com/questions/308966/traffic-views-visits-isnt-correctly-registered-on-site-analytics-or-area-51Traffic (views, visits) isn't correctly registered on Site Analytics or Area 51. SE employees are aware of it, but apparently it takes some time to fix the analytics.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Could it be possible that it is instead measuring *unique* visitors on only the home page?


















We've been informally allowing ML implementation questions, software & hardware evaluation questions, and the scope of the humanities side of the field has expanded also...

My sense is, the expansion of scope has been helpful and, in aggregate, welcomed. 


We're the general AI site, so I feel like pretty much anything we have a tag for, when it's related to AI, is within scope


For example:

terminology should definitely be on-topic and mentioned

hardware evaluation and software evaluation (libraries, frameworks, etc.) questions can be answered objectively and provide valuable information 

game theory and extensions I'd personally like to see mentioned 

logic seems to me to be fundamental, as does probability

The caveat is that we do want to work in conjunction with the communities with which we have overlap, and support those communities. 

We feel firmly that there needs to be a Stack:AI, but we're still in the process of figuring out how to make that permanent, and so we also depend on the support of these related communities. 

-----------------------

Because we also deal with the humanities, I'd want to have an explanation of what constitutes a good "soft question". 

These are cases where there is not an objective answer, but answers that are sufficiently supported, ideally with citations, are legitimate. 

These types of questions are a great opportunity to introduce OP's to fundamental concepts.
b2A1I9n14a1r18y25_g7l12o15b2e5Is it time to modify our site guidelines?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I would like to revive this question: https://ai.meta.stackexchange.com/questions/1320/should-this-site-be-combined-with-the-data-science-stack-exchange. I made some comments to your answers but they were entirely ignored.b2A1I9n14a1r18y25_g7l12o15b2e5On the front page of the site today, every single question falls outside the scope of this site. This is normal, most people have questions regarding the implementation of these methods and algorithms. Whereas ethical, moral questions are much fewer and require much more attention when answering. I do not see why these questions of ethics, morality cannot be a part of site which also serves to answer all questions pertaining to Data Science. I would suggest a name such as `Data Science & AI`.b2A1I9n14a1r18y25_g7l12o15b2e5@JahKnows I'd venture a guess: AI is an established and serious scientific field. Data Science borrows many of its techniques, and so many Data Science-ish questions are on topic here. However, Ethics, Morality, and Philosophy are not part of science, and only part of AI in a fringy sense, despite the popular media attention. I think including them undermines the credibility and usefulness of our site, because they tend to elicit low quality and subjective answers.b2A1I9n14a1r18y25_g7l12o15b2e5@JohnDoucette  It does seem that this stack has been evolving more towards the applied side of the field, and I think that's positive because it provides utility and is in line with the origin of Stack. Our new math formatting capabilities are clearly reinforcing our capability in this regard.  That said, there has been a significant expansion Humanities Stacks, and I do think social impacts of AI is an important topic. The philosophical questions I view more as "fun topics", though the question there may be does it undermine the perceived seriousness/utility of the Stack.b2A1I9n14a1r18y25_g7l12o15b2e5@DukeZhou That makes sense. I think that with some careful moderation the soft questions can have a lot of utility, but because the ones that are further out tend to attract a lot more attention, we ought to be pretty careful about them.


















This site is about Artificial Intelligence (AI) which generalizes Machine Learning and Deep Learning:

https://i.stack.imgur.com/1scCQ.png

Hence, I think, the site should embrace and be the home questions about any of those. Both practical and theoretical, science and engineering.
In order to do so and bring this great audience we should:


Change the name of the community into Artificial Intelligence and Machine Learning.
Write explicitly in the site description that it deals with those subjects and welcome questions about them.


Doing so, I believe, will fill the void in the SE communities which doesn't dedicate any community to gather people which are experts on those.

Remark
Image taken from the book https://rads.stackoverflow.com/amzn/click/1617294438Francois Chollet - Deep Learning with Python.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I'd also mention that incorporating Machine Learning into the Stack name might increase our traffic, but changing that is like turning a ship--requires a great deal of consensus. 

That said, I do think we need to revise the guidelines to at least reflect the current scope of the Stack.b2A1I9n14a1r18y25_g7l12o15b2e5Definitely agree of changing the site description, more importantly the scope definition. As for the title, I cannot understand the suggestion. The image shows inclusion, and you suggest putting them both in the title. (1) long title, less impact, (2) deep learning is really what people talk about (letting aside whether they understand), (3) I hope the community is really about AI at large---not only ML, (4) ML in the title confuses when considering Data Science, Cross-Validated, and probably some other exchanges.b2A1I9n14a1r18y25_g7l12o15b2e5@EricPlaton, The image shows the Hierarchy between the subjects. The title is about making the community attractive to more people. The title isn't long in my opinion. Yet the inclusion of Machine Learning will do miracles to the number of visitors.


















Well, I just got downvoted because I tried to make sense of a question that was somewhat unclear. And the person doing it left a comment saying that an answer to a bad question was still a wrong answer. This is exactly the kind of attitude that makes people leave this site.

There are a lot of questions from people who haven't got a clue about AI, and often express themselves not very clearly, as English is obviously not their first language. I am really taken aback by how unfriendly the community on here is, as most of these questions immediately get downvoted.

I don't know what the solution is, as even requiring a comment is not really solving this issue.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Isn't that a little over exaggeration..If you are talking of @pasaba por aqui then he clearly explained why he downvotd your question..He thought you were wrong..Infact there are lot of interpretations for ai and many of them are wrong...So promoting healthy criticism is nothing badb2A1I9n14a1r18y25_g7l12o15b2e5Great, thanks for this. I'll stop contributing to this site, then. Bye.


















This is a good idea. We'll need to wait, though, until our site graduates — a site generally https://meta.stackexchange.com/a/178463/295684doesn't become available as a migration source (except to its own meta) or target until the beta label is removed.

Moderators can migrate questions to any site, but I would guess that most off-topic questions are not suitable for migration because they don't yet meet the standards of the most relevant site. Such questions should instead be closed here with a helpful comment about the other site and a suggestion to review that site's guidance before posting.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5This is mostly correct, but not universally true - Writing.SE has an active migration path to English.SE. In general, though, you are correct in that beta sites do not usually get migration paths.b2A1I9n14a1r18y25_g7l12o15b2e5@Mithrandir Interesting! I've inserted a word to become strictly correct.b2A1I9n14a1r18y25_g7l12o15b2e5You guys both know more about this than I, but Ben N I fully support you, and thanks for taking the lead on this!


















Similar questions come back on Meta, but no convergence.

I am a proponent of technical questions since before the exchange creation. The hairy issue is to clearly define the boundary.

Any kind of technical question will lead to an overflow of simple programming questions on how to do something with Tensorflow or Pytorch. Such questions are (in my opinion) better answered on StackOverflow. These frameworks are still complex enough so as many questions are really about syntax and framework-specific understanding (e.g. I concieve it is hard to use TensorFlow if you have never used graphs or data flows).

Technical questions like "how many layers to do something?", "what architecture is best for mushroom recognition?", or "why SVM here and ANN there?" seem fine to me.

All in all, I expect the community manages to still attract questions about consciousness, AGI, ethics, etc. A tsunami of small technical questions is good for traffic, but causes a low signal/noise ratio.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Eric, thank you for weighing in.  These are valuable insights.b2A1I9n14a1r18y25_g7l12o15b2e5"Technical questions like "how many layers to do something?", "what architecture is best for mushroom recognition?", or "why SVM here and ANN there?" seem fine to me.". Wouldn't the Data Science site be way better suited for such a question? Choosing such parameters is a matter of the data at hand, not any aspect of intelligence. Artificial Intelligence is a misnomer. I believe that this problem can be mended by combining the Data Science and Artificial Intelligence sites. Both communities would benefit in this regard.b2A1I9n14a1r18y25_g7l12o15b2e5I agree with Eric.  There's always going to be the problem of newbies coming to AI to ask, and these more general questions can be used to bring Data Science to their attention.  Part of the reason I feel this way, speaking as a generalist, wading into the hard science stacks can be not only intimidating, but all too often fruitless for a newbs.  I think there's probably value in AI as a friendly intro site.b2A1I9n14a1r18y25_g7l12o15b2e5I think it's also valuable for the general AI enthusiast public to see some DS and CV and SO and CS and Math questions over here, so they can understand what constitutes the field of AI.b2A1I9n14a1r18y25_g7l12o15b2e5@JahKnows I see what you say as valid. There is a fine line how questions get asked, though, and this becomes case by case. If the question is really about the data, then I would vote for migrating to DS. If not, probably keep it and answer. A bit like a distinction between DS and "Data Engineering". I am half-saying that DE should be here, like in "how to make a brain".b2A1I9n14a1r18y25_g7l12o15b2e5@DukeZhou I start really liking the idea of AI.SE as a hub site, with AI-specific questions, and proper forwarding when more specialization is due. Fine line on some cases, but it looks feasible and valuable to me as for now.


















The Data Science site already covers such topics. It is in my opinion that the Artificial Intelligence site and the Data Science site should be merged where the scope would include


The humanities of artificial intelligence (ethics, morality, etc.)
The humanities of data collection and privacy (ethics, morality, etc.)
The discussion of state-of-the art research in the field of artificial intelligence, machine learning and data science.
Questions pertaining to the implementation of techniques and methods that can be used to achieve artificial intelligence (there are very few of these).
Questions pertaining to the implementation of machine learning techniques and methods (Bayesian models, trees, neural networks, deep learning, etc.).




A site which combines both Artificial Intelligence and Data Science would have many benefits:


A wider audience of potential answerers such that individuals may have a higher probability of find resolutions to their queries. For example a deep learning question asked on either of the sites only, will not reach as many answerers, this hurts the questioner's chances of getting the best possible answer.
The possibility of people with a strong implementation background whom are more likely to peruse Data Science, to also be involved in discussions regarding the ethics and morality of artificial intelligence. 
The possibility of those more interested in the humanities of artificial intelligence to see the kinds of problems that machine learning algorithms are capable of solving and forging stronger arguments about the ethical use and morality of artificial intelligence.




In my opinion, artificial intelligence does not yet exist, very fancy computational models which are essentially hyper-plane separators are not intelligent. However, due to the misnomer used in the medias for machine learning, artificial intelligence is used to describe these techniques. 

As a result, many questions on the Artificial Intelligence site do not match the intended guidelines of the site. Most questions on any particular day do not belong on this site and should be migrated to Data Science. I propose the sites be merged into a single site.

I really do like the questions asked on the Artificial Intelligence site and I would love to partake in them. However reading through Stack Overflow and Data Science usually occupies most of the time I want to spend on my couch. Furthermore, I often see questions in Artificial Intelligence that are almost mirrors of those that have already been answered in great lengths in Data Science. Specifically those relating to neural networks, backpropagtion or gradient descent.

I would ask kindly for the mods of this site to consider that in unity we are all stronger, in division we fall.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Thanks for contributing.  I can tell you there's no way DS would merge with us, and the main problem there is that what is covered by DS is just a fraction of the scope of AI.  (We don't actually get so many DSish questions compared to Overflow or Cross Validated.)  But the scope of AI also includes social and ethical issues, history and mythology of AI, terminology and concepts,  in addition to the technical stuff.b2A1I9n14a1r18y25_g7l12o15b2e5@DukeZhou, Actually when I proposed this idea on the Data Science meta people were very much open to it for the above reasons. I do not see why Data Science couldn't also include questions regarding ethics, history and mythology of AI.b2A1I9n14a1r18y25_g7l12o15b2e5@DukeZhou, "(We don't actually get so many DSish questions compared to Overflow or Cross Validated.)". Right now the front page is littered with questions that are outside the scope of this site. The only reason people choose to post here is due to the misnaming of machine learning in the media as artificial intelligence. Even though everyone in the field agrees that it is hardly artificial intelligence to fit parameters using an optimization function.b2A1I9n14a1r18y25_g7l12o15b2e5It's interesting because back in the 80's, they were calling what Id was doing with 3D games virtual reality.  Now we'd laugh at the idea, but it still constitutes a virtual reality.  Machine Learning is the hot field due to recent milestones, and is almost certainly the future of AI, but it didn't arise out of nowhere.  There are an array of semantic that have to be navigated to say "only Machine Learning is AI".b2A1I9n14a1r18y25_g7l12o15b2e5The other thing is, Data Science is very specific.  It's the statistical part of the equation that ties in machine learning.  There are certainly social issues that arise out of statistical modeling, and AI behavior {See: [Unchained: A story of love, loss, and blockchain](https://www.technologyreview.com/s/610831/unchained-a-story-of-love-loss-and-blockchain/)} but I don't see any reference to that in the DS guidelines.b2A1I9n14a1r18y25_g7l12o15b2e5@DukeZhou, I am not claiming machine learning to be AI. On the contrary, machine learning is hardly AI. A perceptron in the 60s was never considered to be intelligent, it was just a mathematical function that gave an output from a set of inputs. Simply stacking these functions does not generate some intelligence, it just adds layers of complexity to the function. The inventors of backpropagation openly admit that they regret the high performance of their algorithm because it will stunt the development of real AI.b2A1I9n14a1r18y25_g7l12o15b2e5@DukeZhou, again, I do not see why the Data Science site and the AI site cannot exist as one, where the ethical, mythological, etc... be added to the technical. This would make it so much better. We'd have a wider audience answering technical questions for all the noobs who think AI is the technical term to describe a neural network. And we'd get interesting insight of the potential risks associated with this technology from a philosophical stand point.b2A1I9n14a1r18y25_g7l12o15b2e5"Data Science is very specific. It's the statistical part of the equation that ties in machine learning.". I do not think this is a good description of data science in the least. Data science is the larger umbrella which contains, data generation, data storing, and the utilizing of data to solve problems (machine learning, statistical analysis, etc.). Consider what the job of a Data Scientist entails.b2A1I9n14a1r18y25_g7l12o15b2e5@DukeZhou, we can really do much better as a community if we work together then if we keep separated and continue discussing semantics. Objectively speaking, the AI site right now has very few questions that match the scope, most should be migrated to the Data Science site. The questions regarding the ethics, mythology, etc... are very interesting and I do not see how they cannot be integrated into a technical site.b2A1I9n14a1r18y25_g7l12o15b2e5I agree with you 100%.  I strongly believe SE:AI must be a feeder site to DS because we're always going to be the first place many come to ask.  While I'd like to see basic questions answered here, with an emphasis on the concepts, those answers should point to DS for more advanced followup.  Most importantly, **we do need to start migrating DS questions to DS!**  I just opened a meta for [a DS migration campaign](https://ai.meta.stackexchange.com/questions/1365/initiative-to-migrate-unanswered-data-science-questions-to-sedata-science)b2A1I9n14a1r18y25_g7l12o15b2e5Please migrate! I'll vote and flag on that vein.b2A1I9n14a1r18y25_g7l12o15b2e5I do not think DS and AI should merge, so each can keep their focus. Ethics on DS is terrific, given all the weapon of Math destruction that come online. However, mythology, history, philosphy, and topics like conciousness would be noise on DS (with rare exceptions). May AI be the home to these questions. That was the intent in creating it.


















I'd personally like to expand the guidelines to formally include:


a specific AI programming problem, or 
an AI software algorithm, or 
AI software tools commonly used by programmers; and is 
a practical, answerable problem that is unique to AI software development 


which is basically Overflow with "AI" added to each line.

WHY?

My main competency is in the humanities side of the AI equation, but I don't think it's possible we'd going to be able to sustain the level of activity to graduate from Beta on philosophical and conceptual questions alone.  And, I'm inclined to believe that AI is a field where the humanities and sciences intersect.  

When I first came on as mod, there was a flood of Python question related to AI development.  It seemed clear that these endeavors constitute a relatively new sub-field.  So while I'd point someone with a general Python question to Overflow of Computer Science, if that question relates to AI, I think it belongs here. That's just one example.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Thank you for the perspective. That goes in an interesting direction to me. I guess a future question would be if a question is about Python/Tensorflow, is it an "AI" question because the question is about TF ? Perhaps questions on how to use the API go to SO, and how to implement an AI algo can go to AI.SE.b2A1I9n14a1r18y25_g7l12o15b2e5@EricPlaton My feeling is that if the Python or Tensorflow question is related to an AI implementation, we want to address it here.  (There were a flood of python questions when I first started modding, no doubt due to AlphaGo, but my feeling is there is enough activity in AI specific software development to support specialization re: AI-specific implementation question and problems.)b2A1I9n14a1r18y25_g7l12o15b2e5Difficult and hairy. A question about how to do something in TF, because TF is the assembly language for ML would be better on SO. Agreed that a more abstract question with code would be terrific here.


















I preemptively modified the guidelines just now to make it clear that reference requests are on-topic.  (We have a tag for it, and reference requests have utility and traffic-drawing value.)  The idea is that experienced contributors can suggest reference materials with some vetting and, ideally, context and synopsis.

We also have software evaluation and hardware evaluation tags, and I'd like to add these officially as well because here there can be a great deal of objectivity.  (i.e. processor performance can be precisely quantified, and functions related to AI development explained.  Likewise, with software utilities, functions and capabilities can be accurately listed and broken down.)

AI Career Advice
I strongly feel this should be on-topic.  While it's typically the type of thing one undertakes on chat, most chat participation is low, and good luck finding someone who can give you advice in any given span.  But AI has never been more burgeoning as a field, with opportunities for the average programmer in addition to PhD's.  A lot of people want to get into the field, and advice from professionals and scholars would be salient, beneficial, and potentially boost activity/engagement with answerable questions.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Reference requests... Hairy topic, but I also see it working.b2A1I9n14a1r18y25_g7l12o15b2e5Career advice? If this is typical of chats, perhaps keeping them there is better (and traffic will increase as chats). I am currently on an opposing stance, but out of curiosity, is there any career advice on SO ? I've never realize, and I think that is better this way (there are so many ways to make a career).b2A1I9n14a1r18y25_g7l12o15b2e5@EricPlaton Re: career advice on other stacks, that might be worth investigating.  My feeling is expanding to allow this type of "soft question" could boost traffic and engagement if questions were allowed, and would have utility value if the advice came from experienced parties. (With everyone and their brother trying to capitalize on the renewed interest in the AI field, there are all kinds of pitfalls.  I know someone who spent ~15K on a "bootcamp" for AI, and was only able to find a job as a SQL admin.)b2A1I9n14a1r18y25_g7l12o15b2e5My problem with a traffic driven tactic is allowing now is like allowing forever. Hard to rollback. I’ll let more people weigh in, as I tend to exclude it.b2A1I9n14a1r18y25_g7l12o15b2e5@EricPlaton very true.


















I love that people are coming here to answer some of them, and I think we should encourage that for basic questions, and try to emphasize the conceptual aspects, and point to Data Science for more advanced followups, but


  We need to start migrating new DS questions to DS


None of us AI mods have mod privileges on DS, which is why I, at least, have been reluctant to migrate.  


At present, the "data-science" tag has only 11 instances on SE:AI



  We need Data Science users with high rep to start tagging the questions to be migrated.  If you're a trusted member of that community, I will migrate the questions for you.


We currently have only https://ai.stackexchange.com/questions/tagged/data-science11 data-science tags, with 3 unanswered:

https://ai.stackexchange.com/questions/6050/performance-evaluation-metrics-used-in-training-validation-and-testingPerformance Evaluation Metrics used in Training, Validation and Testing

the above one I actually like for AI because it's asking about the concepts.  I'd want to see the answer, ideally with links to Data Science questions.

https://ai.stackexchange.com/questions/5448/deep-nn-architecture-for-predicting-a-matrix-from-two-matricesDeep NN architecture for predicting a matrix from two matrices

https://ai.stackexchange.com/questions/4291/forecasting-and-predict-using-matlab-artificial-neural-networkForecasting and predict using matlab Artificial Neural Network

Should we try to get these answered, and point to DS?  
b2A1I9n14a1r18y25_g7l12o15b2e5Initiative to migrate unanswered Data Science questions to SE:Data Scienceb2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Extremely similar past discussion: [Should we do a mass migration of Data Sciency questions on AI that remain unanswered?](https://ai.meta.stackexchange.com/q/1326/75)b2A1I9n14a1r18y25_g7l12o15b2e5Thanks for linking to previous threads!  I modified this post to reflect the reality.  I'd definitely be willing to give a few migrations a try, because there have been some vocal AI users. I want to work with the related stacks, and am hoping that will encourage power users from those stacks also to participate here.


















If the example questions are not on-topic here, then I do not think any of them are unique, interesting and high enough quality to be worth migrating to Data Science stack exchange as they stand now.

As a long-term contributor to Data Science, my thoughts on the questions are:


https://ai.stackexchange.com/questions/6050/performance-evaluation-metrics-used-in-training-validation-and-testingPerformance Evaluation Metrics used in Training, Validation and Testing is too vague and broad. Comments attempting to clarify with OP have not really resolved it. IMO, this might get answered on Data Science, but equally could be left abandoned as it is here, or closed as "Too broad" or "Unclear".
https://ai.stackexchange.com/questions/4291/forecasting-and-predict-using-matlab-artificial-neural-networkForecasting and predict using matlab Artificial Neural Network looks like OP is trying to apply a regression model to a classification problem. However, there is nowhere near enough detail in the question to answer it well. Unless the OP was willing to get involved in clarifying how they are using the data set, this would likely get closed with "Unclear" on Data Science.
https://ai.stackexchange.com/questions/5448/deep-nn-architecture-for-predicting-a-matrix-from-two-matricesDeep NN architecture for predicting a matrix from two matrices could potentially be answered (I suggest a possible work around for OP in comments), and might be OK on Data Science if clarifying comments by OP were included. Data Science does get a lot of "I have a data set with this special trait, and I'm stuck about what to try" questions. Some are good, many are not clear, most just need the OP to go ahead and try stuff*. IMO, the question here is borderline - not quite enough information to make a good answer, but it can probably be answered. As such though, I'm not sure of the value of migrating it so long after it was asked. I think migrating a similar question in future would be well received.




* This is an ongoing issue on Data Science and I https://datascience.meta.stackexchange.com/questions/2267/what-to-do-about-are-my-model-ideas-for-this-problem-good-or-what-is-best-mosuggested we need to do something about it on Data Science meta a while ago. Maybe Data Science needs a help advice similar to Stack Overflow's excellent https://stackoverflow.com/help/mcvehttps://stackoverflow.com/help/mcve
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5The thing that confuses me is that some questions asked here have excellent answers on other stacks, recently i linked one of your answer from ds.se...so what abt those questions?b2A1I9n14a1r18y25_g7l12o15b2e5@DuttA: I think it is down to the detail in the questions. It is very hard to tell when to migrate, as you effectively need to be an expert on both sites to have a good chance of success.b2A1I9n14a1r18y25_g7l12o15b2e5Thanks for weighing in on these three specifically.  I've taken action to address, where possible.  Definitely let me know in future when you think questions are best migrated, or if you think they have value on SE:AI.  *(Possibly we could post some of the AI questions in the chats for the related stacks, to try and attract more expert users contributing over here:)*


















Starting a new list of math questions to expand on https://ai.meta.stackexchange.com/a/1319/1671nbro's list:

https://ai.stackexchange.com/questions/6633/back-propagation-in-nn-with-sigmoid-activation-function-division-by-0 (post deleted)

https://ai.stackexchange.com/questions/5057/k-armed-bandit-and-reinforcement-learning

https://ai.stackexchange.com/q/7032/1671

https://ai.stackexchange.com/questions/7147/gradient-of-boltzmann-policy-over-reward-function

https://ai.stackexchange.com/questions/7182/small-multinomial-naive-bayes-text-classification-probabilities

https://ai.stackexchange.com/questions/7207/mathematical-modelling-of-a-i-algorithms

https://ai.stackexchange.com/questions/6308/linucb-with-hybrid-linear-models

https://ai.stackexchange.com/questions/1925/are-ffnn-mlp-lipschitz-functions

https://ai.stackexchange.com/questions/6914/how-does-this-sigma-workharris-algorithmHow does this sigma work?(Harris algorithm)

https://ai.stackexchange.com/questions/6640/defining-formula-for-fuzzy-equationDefining formula for fuzzy equation

https://ai.stackexchange.com/questions/6030/how-to-calculate-gradient-of-filter-in-convolution-networkHow to calculate gradient of filter in convolution network

https://ai.stackexchange.com/a/5380/2444https://ai.stackexchange.com/a/5380/2444

https://ai.stackexchange.com/a/5179/2444https://ai.stackexchange.com/a/5179/2444

https://ai.stackexchange.com/questions/6995/simple-question-about-hs-algorithms-formuloptical-flowSimple question about HS algorithm's formul(Optical flow)

https://ai.stackexchange.com/a/7034/1671https://ai.stackexchange.com/a/7034/1671

https://ai.stackexchange.com/q/7003/1671Why do we have to solve MDP in each iteration of Maximum Entropy Inverse Reinforcement Learning?

https://ai.stackexchange.com/questions/6990/matrix-dimension-for-linear-regression-coefficientsMatrix Dimension for Linear regression coefficients

https://ai.stackexchange.com/a/7103/2444https://ai.stackexchange.com/a/7103/2444


b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5can add https://ai.stackexchange.com/q/6308/1641 to the list. The question would be a lot more clear if the Equation that it's about could be comfortably written in the question, rather than requiring people to download the linked paper and find the Equation. My answer to the question would also be much more readable with proper MathJax over... whatever I ended up doing.b2A1I9n14a1r18y25_g7l12o15b2e5@DennisSoemers Added.  *(Feel free to directly update this list.  Nbro's list original list, I think, is static at this point, so I created this one as a supplement.)*


















I've been active on SE from some time and only recently entered in ai.SE community. In very large communities like SO questions about resources are not welcomed and usually are closed after a short while. In smallest or not very large communities are usually welcomed since they could be helpful to beginners.

So, are this type of questions welcomed here?

For the sake of the question, I've already posted a https://ai.stackexchange.com/questions/7146/comprehensive-list-of-moocs-and-books-on-reinforcement-learningquestion but then the doubt comes up and I thought that it was better to ask instead of closing in advance my question. The post itself isn't opinion based or too broad but, as I said, not all communities welcome list type question.



Just to be clear, what I means for resources isn't links to external sites that could easily expire. I mean books, articles and so on. Of course links to external resources like tensorflow/keras/caffe/etc. manuals, tutorials or documentation are welcomed.
b2A1I9n14a1r18y25_g7l12o15b2e5Is a question about resouces considered off-topic?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5As you have an opinion that your question might suits the site (due to its small size), then I suggest you also write an answer. It is votes on the answers which will gauge community opinion. Votes on the question are not agreements with your stance, they are agreements that it is a worthwhile Meta question. In fact your first upvote is from me - I wish more Beta sites engaged with this question, it crops up repeatedly.


















The problems with generic external resource requests don't really change due to the size of the site.


Links can fail, or go out of date. An answer that is mostly links could degrade so that it is not usable, unless it was actively maintained. This is also why link-only answers are discouraged. 
A "correct" answer is hard to assess.
There is a strong element of opinion on what to include or exclude when compiling "comprehensive" lists. There is an implied "and the list should be reviewed for relevance and curated" which is hard to objectify, but if it wasn't present then clearly just Googling e.g. "Reinforcement Learning tutorials and MOOCs" would be enough for the OP.
No-one will actually read or use a comprehensive list of introductory material. It becomes like a restaurant menu where a reader has to attempt to pick out the 2 or 3 items from the answer that would be most useful to them.
I don't think that technical avoidance of actual hyperlinks, and use of ISBNs, course codes etc changes the nature of this at all. Some external references have a long shelf life. E.g. "Origin of Species" is still relevant today. But this does not apply to all books, just because they are books.



  Just to be clear, what I means for resources isn't links to external sites that could easily expire.


Perhaps if you made it clear what the nature of these non-link resources would look like in an answer, it could help move it out of being a request for generic resources, and become a more focused question. E.g. "What are the must have introductory books in subject area, and what prior knowledge do they assume?" is a lot more focused than "I'm looking for a comprehensive list of MOOCs, books, tutorial and good resources" which is essentially asking for anything and everything that might be useful, without bounds.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I think users can request materials in chat, especially from those who top answered in a tag.b2A1I9n14a1r18y25_g7l12o15b2e5@DuttaA: Yes of course, chat can accept a much wider range of topics. In addition, when someone has asked for links in good faith, I also will usually post a comment that both suggests edit/closing the question *and* gives a useful starting link. Because sharing a link that I know is very easy. I did that in this case on OP's question.b2A1I9n14a1r18y25_g7l12o15b2e5I agree with some of your points and don't agree with others. e.g. you don't need to have dozens of answer, you could also have one wiki answer in this case (also the question should be a wiki one IMHO).b2A1I9n14a1r18y25_g7l12o15b2e5@gvgramazio Yes a Wiki answer *might* work better for creating managed lists. One problem then is users, mostly well-meaning, adding low quality links and references - which is harder to spot/manage compared to other edits because they are just links and references.b2A1I9n14a1r18y25_g7l12o15b2e5Yes, you're right. But the post could be protected, in this way only expert or semi-expert users could add links and references.b2A1I9n14a1r18y25_g7l12o15b2e5@gvgramazio the problem is that expert or semi expert level users Generally don't answer such questions on this stack at least...From personal experience, when I was new here I answered resource recommendation questions in a nice comprehensive manner, after a certain time similar questions with a little variations started coming in and I stopped answering, I will assume it is the same case with experienced users they get tired of new users who ask similar questions without exploring the stack.


















After a week and after reading your comments and answers I still think that ai.SE could benefit from resource request questions. However, I think that my original question on main ai.SE is badly posed.

Some reasons why ai.SE could benefit from resource request questions are:


They attract visitors. This type of questions have usually a lot of views and could attract new visitors from web search engines.
They could prevent some users to post dumb questions. This could be only a personal thought but one of the main reasons why I choose to join this community is that, as a self-thought beginner, I don't know which sources I should consider trustworthy.
They could be helpful even for non-beginners. Even at the semi-professional level, one could find new resources interesting.
They could condense a lot of similar questions that ask for resources about some topic.


Of course, there are some disadvantages to this type of question. One of them is how to choose which answer should be accepted. I think that we could have one answer for each resource suggested and one accepted community answer that keeps track of the top resources linked. The community answer could be edit by anyone that has a certain reputation. 
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Thanks for following my suggestion and posting it. I don't personally think these points are enough, but it's a well-thought out answer, so not going to downvote just because I disagree :-)b2A1I9n14a1r18y25_g7l12o15b2e5@NeilSlater I have no problems if you down-vote it because you don't agree. I neither upvoted nor downvoted yours because I agree with some points and disagree with others. ;)


















When I think about this question in the context of research papers, for instance, I can't see a real issue.  

Ideally, when posting research papers links, the title of the paper will be used in addition to the link, so if the link goes bad, people can still search for the paper. 

Russel & Norvig's https://en.wikipedia.org/wiki/Artificial_Intelligence:_A_Modern_ApproachArtificial Intelligence: A Modern Approach is heavily cited on SE:AI, and the text was originally published in 1995.  The book is in its 3rd edition now, (which is not always noted when cited,) but even the 3rd edition dates from 2009, earlier than the recent Machine Learning milestones (~2016) yet the textbook is still relevant and heavily utilized.

List questions do have some issues (see https://ai.meta.stackexchange.com/a/1371/1671Neil Slater's answer) and seem to be off-topic in general across Stack exchange. 

However, I'd still think lists of research papers on a given topic, ideally peer-reviewed, would provide utility and carry archival value.  In the same way, lists of well-regarded textbooks could be useful. 



Second Consideration: Contemporary Hacker Culture and Youtube

In some sense we're the "General AI" site, covering the full scope of the field, as opposed to focusing on any given specific aspect (distinct from stacks like Data Science.)  

We seem to be the stack where beginners typically come to first.  I created a https://ai.stackexchange.com/questions/tagged/getting-startedgetting-started tag because there are so many of these questions. 

Many people today are learning the basics today via youtube videos. Where the videos are solid, they seem to provide benefit, but they tend to be more ephemeral, especially when they come from non-academic sources.  (Erik Demaine's lectures on https://www.youtube.com/watch?v=moPtwq_cVH8Time Complexity will likely be available for a very long time indeed, where a random youtuber using click-baitey titles subject matter to generate ad-revenues may not be.)

My feeling is, re: videos, is that anything commercial should be avoided, but anything coming from accredited academic institutions is reliable and suitable.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I agree with your arguments but I don't get your conclusions. Should question regarding a specific topic of artificial intelligence be considered off-topic or not in this site?b2A1I9n14a1r18y25_g7l12o15b2e5@gvgramazio Personally, if the resources are vetted (peer reviewed, standard texts, videos from academic institutions and other reliable sources) I tend to be in favor.


















I think the monte-carlo-search tag is currently ambiguous. The https://ai.stackexchange.com/tags/monte-carlo-search/infotag info page currently says:


  
    For questions about clarifications/applications/implementation of the Monte Carlo Search algorithm used especially in Artificial Intelligence/Combinatorial games. 
  
  
  In computer science, Monte Carlo tree search (MCTS) is a heuristic search algorithm for some kinds of decision processes, most notably those employed in game play.
  
  https://en.wikipedia.org/wiki/Monte_Carlo_tree_searchMonte Carlo Search - Wikipedia


which implies that the tag is just about MCTS. However, the tag name itself (excluding the word "tree") implies that it is either:


solely about plain "Monte Carlo Search" (which is, among game AI researchers, generally understood as a straightforward algorithm that evaluates children of the root by generating (semi-)random rollouts from the root node without any additional element of tree-building like in MCTS), or
more generally about search techniques that somehow involve Monte-Carlo methods in whatever way you can think of.


The https://ai.stackexchange.com/questions/tagged/monte-carlo-searchcurrent usage of the tag appears to be (almost) exclusively about MCTS.



I propose one of the following two should happen:


Rename the tag to monte-carlo-tree-search. This would remove ambiguity, and does not appear to conflict much (if at all) with usage of the tag so far.
Edit the tag info to be more generally about Monte-Carlo methods. Optionally, considering the popularity of the specific MCTS algorithm, I suppose a dedicated monte-carlo-tree-search tag could still be created as well.

b2A1I9n14a1r18y25_g7l12o15b2e5Ambiguous monte-carlo-search tagb2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Thanks for catching this.  Clarity is optimal.  I just checked the 15 tagged questions and they all involve MCTS specifically, so I think we can hold off on a general purpose "monte-carlo" tag for now.  Looking into the most efficient way to alter the current tag text.  Any thoughts on pros/cons for either "mcts" or "monte-carlo-tree-search" ?b2A1I9n14a1r18y25_g7l12o15b2e5@DukeZhou I'd go for the fully spelled out name, since the tag length limit increase made sufficient room.b2A1I9n14a1r18y25_g7l12o15b2e5@DukeZhou On StackOverflow the full named is also used for a tag about the algorithm, so that seems good to me too. See you already edited that. I've just proposed more detailed tag info (based on the tag info I previously also wrote for the same tag over on StackOverflow, slightly adapted because the scope is wider here, not just about implementation as it would be on StackOverflow)b2A1I9n14a1r18y25_g7l12o15b2e5Thanks for all of that detail in the tag info!  I've accepted the edits, with a slight massage to the usage guidance excerpt (my feeling is we should avoid explanation of the function in the guidance portion.)


















Because of a comment added to someone else's question about it being off topic, I looked up the definition of what is on topic for the AI beta.1

I was startled to find that the current Artificial Intelligence SE site description is this.


  Q&A for people interested in conceptual questions about life and challenges in a world where "cognitive" functions can be mimicked in purely digital environment


What I would have guessed it to be based on actual Q&A content is this.


  Q&A for people interested in conceptual, mathematical, design, and approach questions related to the creation, use, and cultural impact of artificial intelligence and cybernetics


Below are reasons why that second phrase is more descriptive of what is actually discussed and accepted as Q&A.  The evidence for the below reasons is clearly evident not only in the titles and bodies of the most popular questions and answers but also in tag usage, the top ten being these.


Neural networks
Machine learning
Deep learning
CNNs
Reinforcement
AI design
Image recognition
Algorithm
Classification
Training


Less than 1% of the content is about life and challenges in world where cognitive automation is emerging.  It is likely that many of our members couldn't distinguish a cognitive function from either first order predicate logic or learned routine.  The later two can be simulated in many respects with current digital systems, but it is unclear whether, in this century, cognition will be simulated.  I know that's not the popular conception, but those with the greater experience that have been watching AI and working in the field for decades know it to be the truth.

Here are my reasons why I think the current AI meta site definition is not consistent with either expectation, actual content, or the real interests of the membership.


A large proportion of the most active and interesting questions are about what can and has been done in the area of machine learning.
Robotics appears and should appear in the content for the AI beta.  To begin with, the field of AI was as much born out of the need for control systems faster than humans to defend against attacking aircraft and intercontinental ballistic missiles than as a way to do proofs using formal logic.  More importantly, the long awaited for emergence of autonomous vehicles, automated vacuum cleaners, and a host of other non-military intelligent control systems is no longer held back by the prices of control system components (CPU, motor drivers, memory, operating system) and the applicable machine learning strategies are now on GitHub and packaged in Python and Java libraries.
Many of the current AI beta Q&A are lacking in scientific rigor even though the AI beta is in the Science SE category.  The use of mathematics is a quality factor in a science site as much as inclusion of academic references or narrowness of the problems set forth in the questions.  I think it is correct to assemble AI under Science and not Technology because the technology side is covered under SE sites such as Arduino and Data Science, which are properly placed in the Technology category.
I don't see a membership-wide interest in, "Questions about life and challenges in a world where "cognitive" functions can be mimicked in purely digital environment."  People are aware that some job functions get replaced in the human job market by machines, and we've been, as a culture, adapting to it since the late 19th century.  Industrialization saw the emergence automated cotton picking, textile manufacture, type setting, and electronics assembly.  Most people, myself included, will actually be happy when office worker and programming is automated.  It's boring and no more psychologically healthy than coal mining was healthy for breathing.  Our members are not here not to ask questions about how to live or face the changes but to engage in right-now-present-day adaptation to what is so obviously the nearing of another big job market swing.
For reasons given above, "Cognition," is not the best choice of words to describe the relevant AI research and development under way today.  Notice that the word cognition or questions surrounding it are rare in tagging, titling, and discussion.  What is currently being synthesized is the lower mammalian functions that do not take place in the cerebral cortex and have no relationship with comprehension, discernment, or insight.  AI beta Q&A does not fit into the cognitive science definition of cognition or the dictionary definition of it.  For instance, character recognition, visual collision detection, identity recognition, and such are not cognitive functions.  Artificial analysis of large data sets, not for training but for feature extraction, is not cognitive either.


There's much more pointing to the inadequacy of the current description but I'll stop there.  Back to the central question.

Is the current out-facing description of the AI meta descriptive of what it is?

The co-question is this.

Is discussion about life in a changing world really what is relevant to most people who would search for Artificial Intelligence in the search field of SE?  And if not, shouldn't we adapt to the real interests of our membership?

There was an http://area51.stackexchange.com/proposals/57719/artificial-intelligenceolder AI beta that had a great description for what the current AI beta does, which failed as an SE beta probably only because it was before its time.


  Q&A site for theorists, system architects and analysts of intelligent machines and software




Footnotes

[1] I had to log off to find the AI beta description, which is a bug report I might make, but not directly related to this question.  It can be seen when one acts as a non-member and looks up "Artificial" in the SE site list using the search field.
b2A1I9n14a1r18y25_g7l12o15b2e5Is the current out-facing description of the AI meta descriptive of what it is?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5This stack itself is very problematic with a few core group of regular users...so there is no actual "interest of members"....somehow if you look at the stacks older questions you can see a lot of  participation from well reputed users...for some reason they stay away from this stack now...otherwise you would have got a lot of  answers to your theoretical postsb2A1I9n14a1r18y25_g7l12o15b2e5@DuttaA I suspect there actually is a significant amount of interest in a place like this for questions that are slightly on the technical side of AI, but dont have enough focus on programming for stackoverflow or enough focus on stats/math for crossvalidate.se or math.se. Questions like "how does this algorithm work in this particular case?", "does this algorithm suffer from problem X or Y?", etc.b2A1I9n14a1r18y25_g7l12o15b2e5I have personally answered many questions like that over on StackOverflow (even though they tend to officially be off-topic there), and seen many others get closed. I don't think the problem is a lack of interest, the problem is that most of such users find their way to StackOverflow first, and don't get redirected here. It doesn't help that AI.se is not one of the options to select to migrate to when flagging questions as off-topic on StackOverflow.b2A1I9n14a1r18y25_g7l12o15b2e5@DennisSoemers have you notified to the stack admins of this problem?b2A1I9n14a1r18y25_g7l12o15b2e5@DuttaA No I haven't. I'm not sure if I'm necessarily the person who should? I can try to compile a good list of examples questions on StackOverflow for which I feel they'd be a better fit on AI if that's helpful though.



















  Is the current out-facing description of the AI meta descriptive of what it is?


I think the answer to this is a fairly obvious "no" at this point in time.


  The co-question is this.
  
  Is discussion about life in a changing world really what is relevant to most people who would search for Artificial Intelligence in the search field of SE? And if not, shouldn't we adapt to the real interests of our membership?


This is in my opinion the much more important question. Again, I think the answer is "no". Those topics may be interesting and relevant for some, and it's fine to allow them, but I suspect that much more detailed questions about specific little things in AI are more relevant to more people that happen to find their way onto this site. In my opinion, the description should indeed be adapted to allow more "technical" questions... basically, allow the kinds of questions we see many of. Not necessarily technical in the sense of "why doesn't this snippet of code work", but technical in the sense of "how/why/in what cases should this part of an algorithm work?"



A few minor nitpickings from me:


  Many of the current AI beta Q&A are lacking in scientific rigor even though the AI beta is in the Science SE category. The use of mathematics is a quality factor in a science site as much as inclusion of academic references or narrowness of the problems set forth in the questions.


I don't agree that this is a problem. StackExchange as a whole (all sites across the entire network) tends to be primarily about "quick" questions and answers, about building a site that people can easily reach through google searches, quickly see a question relevant to their search terms, and quickly find an answer that addresses their needs. 

Most questions really don't need answers with a thorough literature review, like a scientific paper would. Some do, sometimes there'll a really great question that is best addressed with a great answer containing interesting references to literature, etc... kind of like how, on StackOverflow, you'll sometimes find great answers with lots of different possible solutions, a lot of work put into timing the different implementations, explaining observed performance differences, etc. 

That's certainly not necessary for the majority of questions though. Many more questions are asked by non-experts, or first-year or second-year students for example. They might use slightly incorrect terminology, not be aware of all kinds of other potential solutions, etc. But when they have a clear question about an algorithm they're learning about, they just need an answer to that, they don't need a thorough literature review.


  I think it is correct to assemble AI under Science and not Technology because the technology side is covered under SE sites such as Arduino and Data Science, which are properly placed in the Technology category.


I don't agree with the bolded part there. I've personally never heard of Arduino, but a quick google search does not tell me how that covers a major part of AI at all, it seems really specific and niche. AI is also much much more than just Data Science. AI includes things like search algorithms, planning, pathfinding, and probably much more stuff that is not Data Science. People need a place to ask questions about all that, and it's not covered by any other StackExchange site.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5@DouglasDaseeco That is a great question... to which I unfortunately don't know the answer


















I would like to add to the calls for LaTeX support with a specific topic. 

In my opinion, the AI Stack Exchange should be the home for questions about Reinforcement Learning.

RL questions actually appear in larger numbers on Data Science and Cross Validated Stack Exchange sites. That makes little sense to me, when AI, robotics and other better homes in a conceptual sense exist for this topic.

RL is a technical subject requiring solid understanding of underlying maths, especially for anyone wanting to engage in algorithm design. I would like to be able to write equations and maths-based pseudo code when writing questions or answers about RL. It is a shame that this site presents a barrier to doing that. Along with the larger audience for other Stack Exchange sites, this one is losing out IMO on a current hot topic that could provide much traffic. And in part that is due to barriers when writing content.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5You're the man Neil!


















I strongly recommend against using this tag info, for the following reasons:


Tag info should be easily understandable, provide clear information that tells a user whether or not to use that tag / whether or not it's relevant for their question. 
Tag info should be unambiguous, correct, and not be up for debate. The information in there should be "generally agreed upon" by people familiar with the relevant field(s) to be true.


I don't think either of these points are satisfied here.



For the first point, try reading through that text once, from top to bottom. Do you feel like you're now well aware of when the tag is or isn't applicable, what it's about? I certainly don't. I have the following concerns here:


Usage guidance doesn't really tell us for which questions it should or shouldn't be used. It starts out with a bunch of fancy words that don't tell me anything about its relation to AI. It ends by telling us that "topology" is supposedly "closely related" to something, but still don't know what it is.
Again, the main text / tag wiki doesn't provide clear information either. Again, lots of fancy words, but not much real information (definitely not clear information).
The tag wiki gives some examples of things that are "features of topology" or are "topological", but we still don't have a clear description of what it's supposed to be.




For the second point, I have the following concern:


It dives straight into "Correct Use" and "Misuse" headers, which is already hinting at the definition being up for debate, having multiple uses, being potentially ambiguous or not generally agreed upon. More importantly, as someone familiar with Neural Networks this might be plain incorrect according to my experiences. I say "might be" rather than "is" because the text is so incomprehensibly complicated that I can't tell for sure what it's actually saying.


In general, in AI, when people are talking about "topology" in the context of Neural Networks, it's used to describe the "architecture" of the Network; how many layers, what types of layers, how large is each layer, what activation functions do we put in between, where are the connections (typically a feature of layer type). That's basically it, and that can be explained very clearly in language that can be understood easily. Some sources:


https://www.quora.com/What-is-the-difference-between-neural-network-architecture-and-topologyA quora question
http://nn.cs.utexas.edu/downloads/papers/stanley.ec02.pdfA well-known paper on using evolutionary search to optimize a Neural Network's topology (indeed, it's evolving the "structure" of the neural network).


Many more similar sources can be found through a google search for "Neural Network topology".

That is specifically in the context of Neural Networks. This will likely be the most common natural usage of the tag on this site. However, as also mentioned in the proposed tag wiki, topology is also a completely different field of mathematics. And https://www.quora.com/What-has-topology-got-to-do-with-machine-learningthat field of mathematics may sometimes be relevant in a completely different manner in the field of AI. So, "topology" can be ambiguous, and probably should not be restricted only to the usage in the context of Neural Networks.



As a final concern, I am wondering what a header saying "Only Possible Logical Conclusion" is doing in a tag wiki. That's a header I'd expect in an opinion piece, or maybe as an overly-sensationalized header after a mathematical proof. This is not a header that belongs in a neutral, informative Tag Wiki.



Now, given the use of language, I know immediately precisely which person proposed that tag wiki edit. For context, I think it's important to note that I've previously had a long discussion with this user concerning terminology, https://chat.stackexchange.com/transcript/81180which can be read here.

Note that, in that discussion, it becomes very clear that this particular user is knowingly and actively trying to push the usage of new terminology that he personally believes to be "better" than commonly-used terminology across the entire field. That is fine, he can do that if he likes, even on this site by e.g. asking questions like "Wouldn't X be a better term instead of Y because reasons Z?" But this should not be done through tag wikis. Tag wikis should be consistent with language used commonly across the field, otherwise every single non-expert user visiting the site (and maybe even expert users) is going to be confused.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Dennis, thanks for commenting!  I agree with you here, but I'm still struggling with how to define our topology tag. *(Finally decided to ask a question on the general site so the experts can weigh in.)*



















  The evidence for the below reasons is clearly evident not only in the
  titles and bodies of the most popular questions and answers but also
  in tag usage, the top ten being these.
  
  
  Neural networks
  Machine learning
  Deep learning
  CNNs
  Reinforcement
  AI design
  Image recognition
  Algorithm
  Classification
  Training
  


All these topics are on-topic on http://stats.stackexchange.comhttp://stats.stackexchange.com and https://datascience.stackexchange.comhttps://datascience.stackexchange.com. I don't see any point in having https://ai.stackexchange.comhttps://ai.stackexchange.com covering them as well.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5@DouglasDaseeco I am okay with slight overlap. But as the list of top 10 tags you have listed show, the vast majority of questions (>80%) on  https://ai.stackexchange.com are very much on topic on http://stats.stackexchange.com/ and https://datascience.stackexchange.com/. I believe this is why the scope on meta was worded to try to avoid so much overlap.b2A1I9n14a1r18y25_g7l12o15b2e5@FranckDernoncourt I personally feel like there's value in... "findability". For people who do not already happen to know that there exists a site named "CrossValidated" or "stats.se", I suspect many people interested in these topics are going to have an easier time finding a site named "Artificial Intelligence". I don't know if that's an "officially acceptable" reason for a new site though, just something that I personally think has value.b2A1I9n14a1r18y25_g7l12o15b2e5Either way, on the more technical side of questions, there are also still topics in AI that don't fit into either stats or datascience. For example, search, planning... maybe genetic algorithms / evolutionary stuff, depending on who you ask? Not sure.b2A1I9n14a1r18y25_g7l12o15b2e5@DennisSoemers true, there are some questions on AI that aren't stats or DS but in practice, most questions here are about stats or DS. Evolutionary computation is definitely on topic on stats SE. I agree the name CV sucks.b2A1I9n14a1r18y25_g7l12o15b2e5@FranckDernoncourt, I'm not sure that you're aware that the proposal and selection of a new AI site description has been resurrected by Ben and others at https://ai.meta.stackexchange.com/questions/1430/what-should-the-ai-se-site-description-be/. It would probably be helpful to see your view in the comments there. For instance, it may be valuable to see your point about the overlap with Stats and DataScience sites, not well represented in that Q&A. Some involved have probably not read this Q. Also, if you have a proposed wording, I for one would like to read it.b2A1I9n14a1r18y25_g7l12o15b2e5@FauChristian thanks, I added an answer but the main issue is that since we already have CV and DS it doesn't make much sense to me to add one more AI-focused SE.b2A1I9n14a1r18y25_g7l12o15b2e5Your point is clear and astute. CV & DS do cover data center AI, reflecting Google's huge success with mining, ranking, & indexing. Yet, data intelligence is subset of smaller proportion than public media represents. The foundation of AI is not data-centrism but rather cybernetics, kick started by cold war funding of ICBM countermeasures under Reagan. Concurrent with data-centrism is the serious investment into real time embedded AI for transportation, factory defect reduction, and smart home robotics. Automated mathematics (Leibniz) is also well funded & lacks data in the conventional sense.b2A1I9n14a1r18y25_g7l12o15b2e5Even so, I think your concern needs to be heard clearly, thus my earlier comment.


















To give some background, recently I came across an answer which used some religious stories to explain a question. I reported it as spam as it contained link to a personal blog (it got consequently removed).

The answer in itself was faulty as it did not properly cite the sources of the religious stories. I would not have raised a flag if the person had cited the sources correctly.

My question should we allow answers based on religious sources in this stack? My opinion is since we ourselves have no real true understanding of  AI one should allow the religious sources to be counted as philosophy, since it is speculative. What are your thoughts on this matter?
b2A1I9n14a1r18y25_g7l12o15b2e5Religion based answers in AIb2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Can you give an example of what a "religion based answer" on an AI topic would look like? I'm having a difficult time imagining one. If it's something like "according to religious text X, humans are not allowed to create artificial forms of life, therefore AI research is bad"... then that doesn't seem useful to me. If a part from a religious text is used as an example / analogy and actually works well to explain some concept relevant to AI, I suppose that's fine, though it'd have to be explained sufficiently well for people unfamiliar with that text.b2A1I9n14a1r18y25_g7l12o15b2e5@DennisSoemers recently the answer was to a question about free will some things from bible and hinduism...like karma probably


















Our https://ai.meta.stackexchange.com/q/1285/75justification policy requires that speculative answers give some justification or reasoning for their assertions. I originally intended it for things like this hypothetical (and somewhat hyperbolic) exchange:


  Q: What is the risk from widespread deployment of self-driving cars?
  
  A: Self-driving cars will work fine for a while, gain sentience, turn malevolent, wait for a perfect opportunity, and kill us all. This sequence of events is 100% certain.


Wild speculation requires some sort of justification. It still might not be correct (votes can indicate accuracy/reasonableness), but there must be some explanation of how the answer author arrived at their conclusion. Citing sources is a great way, but not the only way, to provide that. It seems to me like drawing on philosophy/religion is a decent method to explain one's position.

Regarding the specific answer you discuss: I deleted it not for lack of explanation but because — despite its considerable length — it didn't actually address artificial intelligence.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I was talking in general of the broad case...In philosophy tag are we allowed to disallow answers which give explanation from religious texts? Since we ourselves use terms which are vague and loosely based on experiences from different sourcesb2A1I9n14a1r18y25_g7l12o15b2e5@BenN  ,long live Ben. Great work always.


















I just noticed that https://ai.meta.stackexchange.com/q/35/1641$\LaTeX$ support has been enabled on the site. In this meta discussion where that feature was requested, large lists of existing questions and answers that would benefit from $\LaTeX$ support have already been compiled.

What is the best way to go about editing all of those to use $\LaTeX$ for properly formatted math? I suppose that we will not want to edit them all right away, because that will drown out any new questions appearing on the frontpage. Are we going to be editing them slowly, one per day or something like that? Or all at once anyway?
b2A1I9n14a1r18y25_g7l12o15b2e5How to go about editing past questions and answers with new $\LaTeX$ support?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5@DouglasDaseeco I don't think stackexchange sites really have any functionality for those kinds of announcements, other than meta posts (which most users of the main site won't see). Its use will slowly grow as more and more people see it being used in other posts though. I personally try to remember to edit about one old post per day from the lists that were compiled in the original meta discussion (not more because we don't want to flood the front page with old questions).


















I personally feel like most Data Science questions would be just fine on AI too, Data Science and AI simply are very closely related. The only argument against having Data Science questions on AI.se that I'm aware of basically boils down to trying to avoid as much overlap as possible.

From my point of view, that kind of overlap really isn't too much of a problem. The topic in the question (entity recognition from text) is certainly a topic that could be described as being a part of "Artificial Intelligence", and it would be just as correct as saying it's a "Data Science" topic. So I personally really wouldn't mind if it's allowed on either site, I can see it fitting in either just fine. I understand that StackExchange as a complete network might find it more problematic if there's too much overlap, and if that's the case their opinion is probably more important than mine, I just don't experience it as problematic personally.

The only sentence in the question you linked to that is maybe a bit questionable in my opinion is the following:


  I have tried Spacy and NLTK for entity extraction but that doesn't suffice above requirements.


That sentence is describing specific tools/frameworks, and implies the question-asker might be looking for more names of similarly specific tools/frameworks. I do feel those kinds of questions would be a better fit for Data Science. 

But the same question, especially if you ignore that one sentence, can easily be interpreted as being of a more conceptual nature, asking more generally about techniques/algorithms that would be applicable. It looks to me like both of the current answers also interpret the question in that way. Such "conceptual" questions would be just fine here in my opinion.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Yep, the last paragraph is why I didn't migrate the question. Well said!b2A1I9n14a1r18y25_g7l12o15b2e5@BenN my thoughts were that the question would have been better served by a DS.SE...the user probably would have got better answers there


















I agree with this because https://en.wikipedia.org/wiki/Neuromorphic_engineeringit is consistent with the wiki article for the field.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5So when will it be changed? I'll try to add a definition to itb2A1I9n14a1r18y25_g7l12o15b2e5@DuttaA done.  (thanks for the reminder )


















If you take a look at our states on Area51, the two big areas that are still a problem for the beta are the rate of unanswered questions (which is close to 25%), and the average number of answers per question (which is about 1). These are related statistics.

Looking through our queue of unanswered questions, there are some that might be answerable, but that I cannot answer, and many that look unanswerable or very low quality. Many of the questions are very old.

Should we make a more concerted effort to close questions that are old and unanswerable? What criteria should we use to decide if a question meets that standard?
b2A1I9n14a1r18y25_g7l12o15b2e5Should we make a more concerted effort to answer or close the unanswered queue?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Note that "unanswered questions" in SE context is "questions with no upvoted or accepted answers", so if there are good enough answers without upvote, consider upvote them (if you think they worth it) to remove them from "unanswered" state.b2A1I9n14a1r18y25_g7l12o15b2e5@AndrewT. That makes sense, but we have some 350-400 questions with no answers at all.b2A1I9n14a1r18y25_g7l12o15b2e5@ManuelRodriguez That also makes sense, and I have done so. Many of the remaining questions look difficult or impossible to answer however, hence this question.


















I don't see a discussion of what constitutes a good "Soft Question", but @DukeZhou's suggestions make sense:


Questions should be rooted in existing AI research, or research by serious philosophers on AI related topics, not in popular non-fiction books. (i.e. favour Moshe Verdi or Nick Bostrom over Ray Kurzweil). 


Rationale: Popular non-fiction tends to exaggerate AI's capabilities, and tends to be written by people with little actual knowledge of the field, despite reaching a broad audience. Questions rooted in this material will tend to elicit wildly speculative answers, or to be unanswerable. 

Soft questions and their answers should include supporting citations to scholarly works, and should be rooted in empirically supported facts whenever possible. 


Rationale: A good example was a recent question on automation. It's easy to speculate, but there's actually lots of good data, both about what financial markets think will be automated, and what AI experts as a whole think can be automated. These estimates are likely to be far more reliable than an individual user's opinions, or even any philosopher's opinions.


b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5John, thanks for weighing in. I agree wholeheartedly.  *(I'd noticed that many hard science stacks have the "soft question" tag , and our guidelines should reflect the guidelines on those communities.)*b2A1I9n14a1r18y25_g7l12o15b2e5I also created a "mythology-of-ai" tag to identify the fringey questions, including the singularity, but it hasn't gotten much use.  My thought there is that the Carl Sagan/Cosmos initiative to popularize physics and astronomy probably had benefits for the field.  These types of questions surely help with traffic, but is it the right kind of traffic?  That said, there may be value in demystification of these topics, separating reality from speculation.    Another way to look at it may be "Was Asimov useful?"b2A1I9n14a1r18y25_g7l12o15b2e5@DukeZhou That makes a lot of sense to me. I like that tag a lot, and will be sure to suggest it in future when I see questions like it.


















If a question is unanswerable, it should be closed, be it old or new. This is more or less what closing is for. 

But don't do it for the sake of Area 51 statistics. Those statistics outlived their usefulness, as did Area 51 itself. The post https://meta.stackexchange.com/questions/257614/graduation-site-closure-and-a-clearer-outlook-on-the-health-of-se-sitesGraduation, site closure, and a clearer outlook on the health of SE sites explains that already in 2015, those stats did not really matter for site graduation or closure.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5That's interesting and makes sense, but what criteria do you think should be used to decide if a question is unanswerable? For example, if a question is new and I don't know how to answer it, I am sometimes pleasantly surprised to see someone else give a useful answer soon after. If it's 6 months old, if I don't know the answer, it starts to seem more reasonable to guess that the question is too poorly worded, or too exotic, to _ever_ receive a good answer.


















Speaking as a pro tem mod, we see a lot of single close votes, but tend to give the OP the benefit of the doubt, and err on the side of caution.

My feeling is the best method to increase closure of these "grey area" questions is to keep attracting knowledgeable contributors, and supporting those contributors by upvoting good questions and answers, so that more users have informal moderator privileges.  (i.e. I'm personally more comfortable with closures being consensus-based because, as JD notes, it can be a difficult determination, even for qualified individuals.)

That said, I'd like to prune away as much of the noise and dead-weight as possible to improve our stats.  I'm wondering if we might start a chat thread to address questions in limbo, so that if contributors make a strong case for closure, the moderators can more confidently take action.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Some users don't Know they can actually accept an answer...I also didn't know when I was new.b2A1I9n14a1r18y25_g7l12o15b2e5@DuttaA agreed.  (i try to gently remind new OPs to upvote if the answer is useful, and formally accept if it answers the question, when I notice comment discussion but no upvotes.)  we've definitely got to support each other to build this community.


















Earlier this year we announced a "site sponsorship" program aimed at bringing in industry and project-team leaders to help support these sites. A lot of your questions about this program can be answered through the posts and comments there:
https://meta.stackexchange.com/questions/307861/sponsorship-pilot-bringing-resources-back-to-stack-exchangeSite Sponsporships — Bringing Resources Back to Stack Exchange

Today I am excited to announce that IBM has generously agreed to sponsor the Artificial Intelligence site  by becoming a partner with the AI community — to encourage innovation within this space by helping developers solve the complex problems facing this field.
The primary focus of a sponsorship is to help bring more resources to this site. IBM is currently working with Stack Exchange to promote this site at their https://www.ibm.com/analytics/win-with-ai/Winning with AI conference on September 13, 2018 in New York City. IBM will also be advertising on Stack Overflow to drive further traffic and usage back to the AI site. IBM will also bring various dev teams throughout their organization (many with communities of their own) to participate on the AI site, and to help expand awareness of the industry itself.
How does a sponsorship affect this site?
Site sponsorships are administered much like the "tag sponsorships" you may have seen on other sites. Apart from the visual updates and site promotion, you should not see any significant changes in the scope or the operation of this site. Site sponsorship is essentially "strategic philanthropy" where industry partners like IBM can give back to developer communities by having a presence on the site, and to provide a place to help ask and answer questions.
Let's get a few immediate concerns out of the way
First — sponsors do not "own" these Q&A sites. Sponsors work alongside our communities who ultimately build these sites. Communities ask the questions; communities create the tags; communities conduct elections as they do now. Any ads a sponsor might submit still has to go through our crazy-strict ad editorial process… as it has always been. Companies do not have access to personal data, and all Q&A content remains irrevocably licensed under Creative Commons for sharing and attribution.
I am energized about the potential for working with companies like IBM as a way to expand our sites' growth and to help bring in new communities, and maybe even build out some new features for Q&A sites like this. Every site will ultimately benefit.
On a personal note, I continue to be impressed by just how attuned our marketing team and partners have been to the concerns of our Q&A sites. We will work hard to find organizations who are willing to cede so much control back to the community. It can be difficult to anticipate all the hiccups we might encounter along the way, but we remain steadfast in the guiding principle that these ideas should NOT interfere with the main experience of the Q&A, and IBM seems to fit that relationship and expectation to a T.
Enjoy!

b2A1I9n14a1r18y25_g7l12o15b2e5Something new coming to the Artificial Intelligence Stack Exchangeb2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5The motivations for why anybody might support a site vary from person to person. Some project teams may simply want the notoriety or increased exposure, while others might see an intrinsic value in helping assure this community succeeds,i would like to enjoy as the op says **but** We have been sweating for our knowledge base  and still we shall always do.....ibm to our knowledge base ,lets wake up from the dreamb2A1I9n14a1r18y25_g7l12o15b2e5How much did IBM pay Stack Exchange for the sponsorship?b2A1I9n14a1r18y25_g7l12o15b2e5@FranckDernoncourt The sponsorship is administered through the ads/sales team and they will not likely share that type of financial info.b2A1I9n14a1r18y25_g7l12o15b2e5Can we migrate best Q&As from previous AI betas to this site?b2A1I9n14a1r18y25_g7l12o15b2e5@RobertCartaino has the sponsorship ended, or is the missing logo just a bug? Cf. https://ai.meta.stackexchange.com/q/1632/4709b2A1I9n14a1r18y25_g7l12o15b2e5@Glorfindel The IBM sponsorship has concluded, but AWS has signed on to take over later this year! We are currently finalizing the materials needed and it should go live when everything is completed.b2A1I9n14a1r18y25_g7l12o15b2e5Thanks for the update, I'll update [the list of sponsored sites](https://meta.stackexchange.com/q/341662/295232).


















This is great news.  We may still be in Beta, but hopefully not for much longer!  I'm taking it as a good omen that a foundational company in the field of AI wants to be associated with our dynamic and growing Artificial Intelligence stack!
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5,lets get some coffee for this wonderful community,enjoy your cup,as i do.b2A1I9n14a1r18y25_g7l12o15b2e5AI.SE is it's own SITE! \o/b2A1I9n14a1r18y25_g7l12o15b2e5@FreezePhoenix I knew we were going to make it because there is just a certain inevitability to Stack:AI.  (If it didn't exist, someone would have to create it.  In fact, they did 3 times.  3rd time must be a charm!)b2A1I9n14a1r18y25_g7l12o15b2e5Wait... I kept my ability to review. wassup with that?b2A1I9n14a1r18y25_g7l12o15b2e5@FreezePhoenix Even though the new design has removed the "beta" label, we're still marked as a beta site - see [Area 51](https://area51.stackexchange.com/proposals/93481/artificial-intelligence) and [our privilege thresholds](https://ai.stackexchange.com/help/privileges). As we grow, those thresholds will eventually be adjusted.


















I do appreciate the IBM work!
However; How do this newly sponsored AI site differ from the other sites that have been parterned with SE,like AskUbuntu

Is creating a new site only in this case, as a proof of concept? And then if it works, in the future existing sites will be sponsored? Otherwise I don't think I understand how sponsorship equates to "bringing resources back"; creating more sites sounds like spreading resources out or else this is more of a "we want to advance knowledge in our field for altruistic reasons" thing for companies, or is this supposed to give them a profit eventually. 

According to my analysis,basing on the snapshot of the site in the question body,A sponsorship generally entails enabling ads relevant to the subject and affixing a small "sponsored by..." logo in the upper-right corner, and i do think  that's why ibm  is here!

Anyways,appreciated approximately.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I'm having a bit of difficulty understanding some of what you are asking, but if you read through the [original feature announcement linked above](https://meta.stackexchange.com/questions/307861/sponsorship-pilot-bringing-resources-back-to-stack-exchange) (including the answers and associated comments in that post), I believe most of your questions and concerns are addressed there more thoroughly. Let me know if I missed anything.b2A1I9n14a1r18y25_g7l12o15b2e5So the new UI will remain like this for quite long period of time or temporary? Some clarification!b2A1I9n14a1r18y25_g7l12o15b2e5The UI is not temporary. The design is part of the new site layout being rolled out across the network. Here is [the original announcement](https://meta.stackexchange.com/questions/307862/ch-ch-ch-changes-left-nav-responsive-design-themes) and a few of the sites where this has been rolled out: [Super User](https://superuser.com/), [Quantum Computing](https://quantumcomputing.stackexchange.com/), [Server Fault](https://serverfault.com/), [Ask Ubuntu](https://meta.askubuntu.com/), [Mathematics](https://math.stackexchange.com/).


















Slight concern: Does this mean that a new moderator will be appointed in AI.SE? Some of us here are beginners and may ask apparently stupid questions and answers. The new moderator might close or delete such questions and answers. 

The current moderators understand these concerns and have a very good moderating policy on such type of questions and answers.

Thought I would add some links:

https://ai.meta.stackexchange.com/questions/1313/are-we-too-fast-downvoting-questions-especially-for-newcomersAre we too fast downvoting questions, especially for newcomers?

https://ai.meta.stackexchange.com/questions/1289/13-out-of-the-15-questions-on-the-front-page-right-now-are-1-or-lower-score-th13 out of the 15 questions on the front page right now are -1 or lower score: This site needs a broader scope or it's doomed
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5There should be no concern; sponsorships have no effect on moderation.b2A1I9n14a1r18y25_g7l12o15b2e5Plus, when we do elect moderators, all users will have a vote.  *(In the recent math mod election, several of the candidates reinforced kindness to new and inexperienced users as a primary motivation, and those were the candidates who got my votes.) *


















While the new logo looks great at higher resolutions (e.g. in the title just under the navigation bar), it's really 'vague' (sorry, I don't know how to phrase it) in e.g. the Hot Network Questions list and the hamburger menu:

https://i.stack.imgur.com/urOJX.png https://i.stack.imgur.com/PwGvv.png

For starters, the black background should probably be removed; also, a lower number of lines probably suffices to convey the idea that it's a fingerprint.
b2A1I9n14a1r18y25_g7l12o15b2e5Low-resolution version of logo too vagueb2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5For one I have no idea of the relation between a fingerprint and AIb2A1I9n14a1r18y25_g7l12o15b2e5@DuttaA I was wondering the same thing!  (Not that I'm complaining. Certainly less menacing than the HAL 2000 eye;)


















https://ai.stackexchange.com/questions/3343/what-are-the-latest-methods-to-train-a-chat-botThis question was recently bumped to the front page. On some other SEs, the words "latest methods" would be a red flag and potentially cause it to be closed because any answer would have to be updated to continue to be true. The general philosophy on those other sites is that questions should be answerable in a fashion that is going to be useful not just to the questioner, but also to future visitors to the site. Indeed, one of the major uses of the SE network is as a long-standing repository of knowledge for future questioners.

Although new things can always be discovered that invalidate old answers that pre-date them, questions like the one I link to are going to attract answers that are always going to be going out of date. There is no way for an answerer to answer this question in a way that will be useful and true for a reader in six months or a year.

Is that an issue here, or are we fine with questions whose answers will inevitably become out of date?
b2A1I9n14a1r18y25_g7l12o15b2e5Are questions where answers are inevitably obsolete on topic?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Stella, thanks for raising this issue!  I've provisionally retitled that question to include the year, but this is a topic requiring serious discussion.  I definitely feel there is value in historical record and historical methods, but, by the same token, we don't want visitors unaware that a technique or approach may be outdated.b2A1I9n14a1r18y25_g7l12o15b2e5I’ve expanded my question a bit, but it’s worth noting that any policy about this should also take into account the fact that a question similar to “is there a method for doing X efficiently” is likely to one day be out-of-date if the answer is “no.” I do see a substantial difference between these two cases (and the later seems far more akin to the observation “well new facts could be discovered that invalidate answers”), but I think it’s nevertheless an important thing to note.b2A1I9n14a1r18y25_g7l12o15b2e5Regardless of how the answer comes down from the community on this issue, it’s very likely a good idea to encourage users to update answers they post as they become obsolete due to technological progression, and to encourage users to post later answers to questions when the old answers are not updated. A good example of this working well is StackOverflow where it is common to see older answers in Python 2.x, and later answers in 3.1 and even later ones in 3.5. I think this is a good way to preserve the historical value @DukeZhou raises in the context of answers effected by new discoveries.


















I like theory.

I recently https://ai.stackexchange.com/questions/7861/what-does-hard-for-ai-look-likemade a post and was highly surprised to find out that "theory" wasn't a tag option. I have never heard of the word "theorics" before in my life and only found it by looking at the list of tags. Edit: I didn’t even realize it was “theorics,” I thought it was “theoretics” which sounds more like a word to me.

Speaking as a native English speaker whose degrees are in math and philosophy I feel quite inclined to say that a word for “theory” that I’ve never heard in my life is unlikely to be widely known :P
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Theory would definitely be the optimal replacement.b2A1I9n14a1r18y25_g7l12o15b2e5Yes. In fact, somehow we have only a "theorics" tag (not "theoretics", really "theorics"), and no tag for "theory" at all!b2A1I9n14a1r18y25_g7l12o15b2e5@JohnDoucette &Stella I almost wonder if we need a "theoretical" tag in addition to "theory".  (Theory for the serious scientific, and theoretical for the popular questions on subjects such as "AI takeover". Semi-serious here;)b2A1I9n14a1r18y25_g7l12o15b2e5@DukeZhou I really like the "AI-mythology" tag for things like "AI takeover", and it's already around.


















I'd personally hesitate to declare questions off-topic just because the "correct" answers to them are highly likely to change over time. Indeed, this is going to be the case for "state-of-the-art" questions, especially considering how rapidly research in the field is moving and how rapidly the state of the art changes. I personally still feel like such questions aren't overly problematic because:


They are likely a class of questions that is the most interesting for some people. In a field that moves this rapidly, and where young people are newly entering the field also at increasing rates, there is a lot of interest in knowing "what is the state of the art right now?". If there is a lot of demand for such questions, it makes sense to have a place where they can be asked to me.
The web interface of the site already puts timestamps (dates) on questions and answers. Future visitors will be able to see (if they pay attention) if an answer they've run into is rather old.
In the future, if the state of the art has significantly changed, people are free to provide new answers or add comments to existing (outdated) answers. If the people who wrote the original outdated answers are still around, they can also edit them. See, for example, https://stackoverflow.com/q/6542274/6735980this old question on stackoverflow. It was originally asked 7 years ago, and was about the feasibility of training an Artificial Neural Network to play a complex video game like Diablo 2. At the time, this was highly unlikely to be feasible. However, we see some answers being written a few years later, and also see many edits in the question itself and in older answers, to reflect progress in the field.

b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5+1 for the ability to provide new answers. We should offer a "best effort" level of service, but that will still be very useful for 99% of users. The academics and industry researchers who care about true the state-of-the-art should looking in journals and conference proceedings anyway, not here.


















I just looked around a bit and it turns out that moderators can edit that tour text. Our scope has changed and widened markedly from two years ago - those discussions were held before we even had our own moderators - so I think it'd be good to get fresh eyes and new thoughts on the tour blurb. Once we reach a consensus, I (and I'm sure my fellow mods too) would be happy to replace the current outdated text. As for the site description that appears in https://stackexchange.com/sites#namethe sites list, we'll need to poke Stack Exchange staff to get that adjusted once we've decided on a replacement.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5The *tour* text can be edited, but the actual site description - used in other places, such as the site switcher dropdown - can only be edited by staff.b2A1I9n14a1r18y25_g7l12o15b2e5I don't want to unilaterally edit the tour text, and although I have moderator privileges, it not at all obvious to me how to do so (is it just those with the (moderator) tag, or those with moderator privileges?). Regardless, I think we should change it to the most popular post on the last vote now, and then we can think about holding another vote to make it more up to date still. We've clearly failed to update this several times in the past already, so waiting for new consensus seems likely to result in nothing changing again.b2A1I9n14a1r18y25_g7l12o15b2e5@Mithrandir Excellent point, thanks. Answer clarified.b2A1I9n14a1r18y25_g7l12o15b2e5@JohnDoucette Ah, the name of the [access moderator tools](https://ai.stackexchange.com/help/privileges/moderator-tools) privilege is a bit confusing here. I'm referring to [diamond moderators](https://ai.stackexchange.com/users?tab=moderators) in this answer.b2A1I9n14a1r18y25_g7l12o15b2e5@BenN That makes sense. What would constitute "consensus" though? I think there is consensus that the current text makes very little sense. Almost anything would be an improvement. Can you be clearer about _exactly_ what would have to happen to change it?b2A1I9n14a1r18y25_g7l12o15b2e5@JohnDoucette Please start a new meta question soliciting suggestions and I'll close the old one. A couple days after the voting settles down on the new answers, we'll alter the text. (Sorry for the late response, this slipped my mind for a bit.)b2A1I9n14a1r18y25_g7l12o15b2e5@JohnDoucette Since we're still a fairly small stack, I doubt we're going to get an avalanche of votes on this, so, in the end, we may have to resort to loose consensus and rely on rationality.  (I'm very happy with the suggestions that have been proposed on the new thread.)


















This is a question to ask the social engineers employed by those who own SE and SO, but I would like to vet it here before doing that.
Background
Consider that the SE/SO structure is, from one perspective, a game, whether or not it was intended to be. In the context of the best of the social networking models that have obtained some success on today's web, all of which were derived from or influenced by Morgenstern and von Neuman's Game Theory, gaming the system is what contributors to the content of the site do.
From a systems analysis perspective, whether their intention is any of the following or some proportional combination of them, playing for some objective can be proven as the prime motivator for all SE engagement.

Obtaining an answer for use in a project or to satisfy an interest
Educating one's self by writing and evaluating responses
Educating others out of purpose driven or altruistic motivation
Gaining reputation to be seen in a community as an expert
Writing because of satisfaction in writing
Interest in public affirmation of intelligence or expertise
Intrinsic value of high numeric reputation resulting from good PR
Addictive compulsion lacking a cognitive cause
Some other reason

The SE/SO system has adapted for the purposes of growth, and it works as is.  The original domain stackoverflow.com is rated 64th globally by Alexa, and the AI beta's main domain stackexchange.com is rated 127th.
In this context, the deltas aggregated in member reputation incentivizes behaviors that cause the increased growth of SE and SO through the system.
How This Social Model Applies to Down Voting
There are two distinct types of down votes.

Anonymous down vote
Down vote with associated reasoning for it

Both have purpose in that the identify a perceived error or inappropriateness of the Q or A.  Both currently have the same negative affect on the voter's reputation.
Is this optimal?
Critique from a Social Network Equilibrium Perspective
The advantage of the SE/SO system's game objective to humanity is that it helps the global development and dissemination of subject specific knowledge.  From a house (SE/SO business) perspective, it is to improve the domain's rating globally.
With regard to both of those game objectives, a down vote with an associated reason has greater value than an anonymous one in two respects.

Anonymity decouples the down vote from an ethical incentive.
The expression of reasons provides additional information to both writer and the entire public readership.

The current SE system merely indicates to the down voter that a reason in the comments is preferred.  It makes much more sense from an optimization point of view to use the reputation system to simultaneously.

Incentivize against down voting with ulterior motives.
Incentivize for information transparency.

The first is part of civilization in that those indicted can face their critic in academia and face their accuser in court.  The legal ethics behind this has much to do with the necessary checks and balances in civilized social structure.  The asymmetry of accountability in being able to dispute an answer and not being required to specify why leads to uncivilized behavior, which is why academia and ethically evolved legal systems do not permit it.
Potentially Beneficial Change
The overall metrics of satisfaction, positive impact on global understanding, and the value of the two domains (SO and SE) would likely be improved if transparency was not sacrificed for the sake of anonymity.
This is a potentially beneficial change.

Anonymous down votes would still be permitted but a higher integer value would be subtracted from the voter's reputation than 1.
Reason associated down votes would not subtract anything from the voter's reputation, since the action has as much a reason to incentivize as a reason to incentivize against.

A Possible Implementation
To implement such, in addition to the verbal encouragement of adding a comment when a down vote is cast, the comment field labeled, "Reason for down vote," could be added with a minimum required number of words, the provision of which differentiates the two cases so that reputation adjustment could reflect the more optimal incentive model regarding down voting.
Transparency With Anonymity
Down voting transparency and anonymity could easily be achieved concurrently by creating an Anonymous user for such purposes.  This solves the problem of retaliatory conduct, but it may not solve the problem of asymmetric accountability, where one can harm another without any risk of consequences, which is a policy not found in well developed systems outside the SE/SO space.
The question then becomes, why did academia and ethical judicial systems require transparency without anonymity except when a child or undercover public servant is involved?
b2A1I9n14a1r18y25_g7l12o15b2e5Is the incentive of the down vote undifferentiated by the existence of associated reasoning non-optimal for SE?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I am guessing you upvoted the answer I probably downvotd...I thought the comment by the OP on that answer was enough because I too had the same thought as the OP.


















Per Moderator @BenN's request in https://ai.meta.stackexchange.com/questions/1422/how-can-we-change-the-site-description-to-match-our-current-topic-guidelines-an/1423?noredirect=1#comment1708_1423this thread to change the site description, we need to open a new thread and vote on new suggestions.

Please propose site description texts exactly as past users did in https://ai.meta.stackexchange.com/questions/1197/how-can-we-quickly-describe-our-sitethis older thread, and vote on the suggestions of other users. After a reasonable consensus is reached, the moderators will update the site descriptions to match the top voted answer.

For people new to this process, most of the AI SE suggestions in the past follow the convention of the descriptions of most SE sites and start with something like, "Artificial Intelligence Stack Exchange is a question and answer site for ..."
b2A1I9n14a1r18y25_g7l12o15b2e5What should the AI.SE Site Description be?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Perhaps we can summon @BenN by mentioning him? It looks as though we did reach a good consensus.


















Artificial Intelligence Stack Exchange is a question and answer site for ...


  people interested in artificial intelligence theory, design,
  development, practice, research, and policy.


I like @DouglasDaseeco's answer, but I'm among the users who think that practice, and even code, have a place here. Presently users post questions containing code, and I and others answer them, so I think this description is more accurate.

While the founding moderators' intent was to exclude questions that overlapped with other sites (notably Data Science & Programmers.SE), the boundaries are quite porous in practice, and if we want to claim to be a useful place for AI related Q&A on the web, I think we need to accept practical questions as well.

Some examples of coding questions with no other place to go include:

https://ai.stackexchange.com/questions/7555/keeping-track-of-visited-states-in-breadth-first-search/7560#7560Keeping track of visited states in Breadth-first Search, which is about the proper data structures to use in a search algorithm. It doesn't belong in Data Science, since it is related to GOFAI and not machine learning. It doesn't really belong in Programmers.SE, because it isn't a generic question about programming, it's related to understanding the algorithm. It seems to clearly belong on this site, and yet it includes code and is about practice.

https://ai.stackexchange.com/questions/7940/snake-game-snake-converges-to-going-in-the-same-direction-every-time/7941#7941Snake game: snake converges to going in the same direction every time This question was about the implementation of a reinforcement learning algorithm. The question again has nothing to do with Data Science. It involves programming, but the users' problems were not related to understanding how to program, but to understanding the algorithm (and, as it turned out, the exact behaviour of a particular algorithm for training neural networks). This user is not likely to get useful answers on Programmers.SE. It seems to clearly belong on this site, and yet it also includes code and is about practice.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5maybe also add **research** to the list?b2A1I9n14a1r18y25_g7l12o15b2e5@DennisSoemers Good idea.b2A1I9n14a1r18y25_g7l12o15b2e5I would like practice questions to include code as relates to e.g. A*, RL and other high-level AI constructs, but would like exclude code (and questions) that gets bogged down in minutiae of how to implement neural networks, other supervised/unsupervised learners, or Python syntax etc. Likewise, "why does my NN only get a loss of X on this data" type question. This is already a key area of confusion between Cross Validated, Data Science and Stack Overflow. Bundling AI in with those three will further dilute things. The difficulty is phrasing things, because AI is a superset including ML.b2A1I9n14a1r18y25_g7l12o15b2e5Strongly agree that we have to include practice.  I also think Neil's points are important, as we do need find the right boundaries with the stacks where there is overlap.  PS I wonder if "history" might also have a place.  (There is a history of science & mathematics stack, but I feel that the history of AI is most usefully covered here.)b2A1I9n14a1r18y25_g7l12o15b2e5@NeilSlater & JohnDoucette What are your thoughts on providing a little guidance on questions that would be more suitable for Data Science, Overflow, etc.b2A1I9n14a1r18y25_g7l12o15b2e5@DukeZhou: I am torn on that. Although there is clearly a difference between the sites that seem relevant, even experts on multiples of those sites find it hard to express what the actual differences are. It is next to impossible to word a short enough clear statement that a new question asker could follow, even assuming they take the time. The current trend to conflate "Deep X" using NNs with AI is going to cause a lot of misplaced questions. I think the guidance is going to be best focussed on the experts at each site so we can gently push questions around . . .b2A1I9n14a1r18y25_g7l12o15b2e5. . . but the first barrier to that is getting a bunch of experts to agree on any course of action when there is no clear consensus. My default position right now is to answer questions wherever they land, and only comment on suitability of another site when a question would very clearly be welcomed on an alternative according to history of similar questions that I have seen. That's definitely how I have been treating technical questions in Reinforcement Learning.b2A1I9n14a1r18y25_g7l12o15b2e5@DukeZhou I agree with Neil. I think that exactly which technical questions are "on-topic" will be very hard to define, but that moderators can "know it when they see it". A question that is primarily about _how_ to program something is probably (though not always) off topic. A question about _what_ to program (i.e. what the steps in an algorithm actually mean) is probably on topic. But there are lots that fall in between those questions.b2A1I9n14a1r18y25_g7l12o15b2e5@NeilSlater "Answer where you see it" seems to best serve the mission of Stack.  *(Pedantic adherence to guideline minutiae, especially as there is legitimate fuzziness, has definitely not been helpful.)*  Thanks for sharing your thinking on this and your approach.b2A1I9n14a1r18y25_g7l12o15b2e5[Snake game: snake converges to going in the same direction every time](https://ai.stackexchange.com/q/7940/4) is on-topic on both CV and DS.b2A1I9n14a1r18y25_g7l12o15b2e5It _may_ be on topic in CV or DS (I suspect it would be closed on either of those, despite the site policies). A bigger question is: why would any person _expect_ it to be on topic there? The user certainly isn't doing anything I'd recognize as data science. They are doing a kind of machine learning, but it's not anything a regular statistician would expect to see. If I were going to ask about it, I'd expect to get an answer on the "AI" stack, and if I was searching for an answer, that's where I'd expect to find one too.


















I think the number of votes is also a factor.  Right now, on SE:AI, we have relatively low voting participation.  This makes us a tough stack to build rep on, but it also makes the solo downvotes stick out.  

Compare to a stack where there questions and answers receive a large number of votes quickly. When voting activity is high, the random downvotes have less of an impact.

So, in some sense, the solution is to keep working to attract users, and boost the voting levels.



I have seen what I believe to be pro forma, serial downvoting in the past on SE:AI.  My remedy for that has been to look at all new questions every day (been slacking lately, admittedly,) and make a point of upvoting questions I think have been unfairly downvoted.

With answers, it's a little tougher b/c one doesn't want to up or downvote without a high degree of confidence.  
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5@FelicityC definitely don't be shy about downvoting questions & answers (especially) that are inaccurate or misleading.  On reflection, this post is more about defacto downvoting of questions and more related to the evolving scope of this Stack, which entails some fuzziness.  Poor answers, on the other hand, should not be given the benefit of the doubt!


















It looks to me like they are both used for similar questions, and based on the current Tag Info for the two tags they don't really appear to be different either. So, based on current tag usage, I'd argue that they should be combined into a single tag (which, in my opinion, should be natural-language-processing because that's the full term that everyone in the field uses in my experience).

I suppose that, in theory, natural-language could refer to something else than NLP... like, it could be for questions about language itself, rather than questions about processing (generating and/or understanding) language. I have a very difficult time imagining any such questions would actually be on-topic for AI though.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5re: natural-language, I was also wondering if it was initially intended as a linguistics tag.  In that context, I think it could have a place, linguistics being one of the corollary disciplines that contributes to natural-language-processing.  The problem there is people using the tags arbitrarily, despite any disambiguation we might provide in the tag info...b2A1I9n14a1r18y25_g7l12o15b2e5@DukeZhou Well the current Tag Info certainly doesn't disambiguate in such a way, since the Tag Info for `natural-language` is still all about AI (it's basically a highly informal summary of NLP). If someone were to ask a linguistics-only question for the purpose of understanding language better and the end goal of that understanding is still something NLP-related... NLP would work too. If it's really so far removed from AI that NLP becomes the wrong tag... I feel like the question would fit better in one of the dedicated language-related SE sites anyway.b2A1I9n14a1r18y25_g7l12o15b2e5Definitely the natural-language tag would have to be modified if we do keep it.  (My feeling is it is analogous to having tags for "probability", "logic", etc.)b2A1I9n14a1r18y25_g7l12o15b2e5Just as an update, I'm leaning toward merging the current tags (per you point that most of the usages of both tags is currently similar.)  My thinking is that if we should need a straight linguistics tag, it can be subsequently created.b2A1I9n14a1r18y25_g7l12o15b2e5@DukeZhou Maybe such a new tag should then simply be named `linguistics`, to make the difference with NLP clear?b2A1I9n14a1r18y25_g7l12o15b2e5It's a good thought but it might open up another semantic issue in that linguistics is not restricted to natural language only.  I could see potential use for an umbrella linguistics tag...


















There is a key difference between the two terms.  Whether this finer level of granularity is useful in the tags, I have no opinion.

Natural language is concerned with the general idea of conveying ideas via vocalization and the comprehension of the idea by a listener.

Natural language processing sounds more well defined, but it is actually poorly defined and the definitions in the literature are scattered between these two extremes:


Parsing text into linguistic structures.
Linguistic processing components in chat-bots designed to replace human experts.


What is included in NLP?


Talking?
Generating text?
Generating linguistic associations?
Parsing text?
Hearing?
Listening?
Dialog?
Topic detection?
Cognition?
Story invocation? — See Schank.
Translation?


Depends on who is teaching and when.  I don't even see any consistency between the same person's view of NLP over time.

If addressing the terms literally, natural language is simply the field of linguistics minus the addition of formal languages.  NLP would then become the action that occurs when some system deals with natural language at either its input, its output, or both.

I saw those two tags earlier today.  I don't have a recommendation as to whether to combine them or leave them alone.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I'm not convinced this is limited to auditory language, since the language analyzed can be in text form.b2A1I9n14a1r18y25_g7l12o15b2e5Still discounts the fact that NLP algorithms would be used for interpreting both text and audio.  You clearly make the point that parsing audio is important, but not that it is a requirement, jsut that it adds an extra element of correctly translating spoken language into text where the language is spoken.b2A1I9n14a1r18y25_g7l12o15b2e5I think that would be fine to create the new tag, if necessary.  (I think the current problem is that they weren't properly disambiguated, which led to the question overlap.) Thanks for you input on this!b2A1I9n14a1r18y25_g7l12o15b2e5I think we'd want to merge to NLP because it's the AI specific field, and then look to relaunch, and probably retag some old questions, with the new tag.b2A1I9n14a1r18y25_g7l12o15b2e5Thanks for doing it.  The edits should all be approved.


















The two leaders are ...


  people interested in artificial intelligence theory, design, development, practice, research, and policy.


... and ...


  people interested in embedded, mathematical, cognitive, and discovery centered artificial intelligence research and development.


... so I propose the union.


  people interested in AI theory, mathematics, research, discovery, design, development, practice, embedded uses, cognition, policy, and impact.




This one is inclusive and dodges the terms statistics and data science which are the explicit domains of established SE siblings.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I like this idea. It's a bit wordy, but that's the not the worst thing to compromise on.b2A1I9n14a1r18y25_g7l12o15b2e5This answer seems fine to me, it doesn't seem to exclude anything that should be on-topic, and seems to cover everything that should be on-topic imo. If people think it's too wordy, I think some of the words don't add much and could be removed though: 1) mathematics (I'd say theory and research already imply that AI-related math is on-topic), 2) embedded uses (is it necessary to specify this? I feel like questions about embedded uses of AI will already also always be covered by one of the other terms, like development or practice).b2A1I9n14a1r18y25_g7l12o15b2e5I don't feel strongly about removing them though... just feel like they could be removed if it's necessary to reduce the word-count for whatever reason.b2A1I9n14a1r18y25_g7l12o15b2e5I appreciate the broad expansion in scope of "cognition" unqualified, but I agree it's on-topic, and no one seems to object.  I agree that if we include mathematics, it's with the understanding that we're trying to raise awareness of that aspect of the field, for beginners especially.  My thought is including mathematics would encourage mathematical questions, which we definitely want.b2A1I9n14a1r18y25_g7l12o15b2e5@DouglasDaseeco I agree it's in scope and useful.  Most importantly, we seem to have some consensus and buy-in on the merged descriptions in this answer, which helps in moving forward confidently with the change.b2A1I9n14a1r18y25_g7l12o15b2e5@DukeZhou in case we need to mention you in a thread that you were on already. Please see comment thread under the main question.b2A1I9n14a1r18y25_g7l12o15b2e5I think the first vote can be dismissed. It is probable that the electorate of the previous vote is different from the electorate of this vote because different users are active now. Our process should reflect the will of those who are currently active on, and thus running, the site.


















Has anyone tried to approximate the percentage of questions posted here that are also on-topic on Cross Validated and Data Science?
b2A1I9n14a1r18y25_g7l12o15b2e5What percentage of questions posted here are also on-topic on Cross Validated and Data Science?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Except reinforcement learning and algorithm or conceptual questions pretty much all...based on my experience I would say 90-95%...but recently questions about RL is increasing.b2A1I9n14a1r18y25_g7l12o15b2e5@DuttaA Reinforcement leaning is also on topic on   Cross Validated and Data Science. I agree with the 90-95% estimate.


















After https://ai.meta.stackexchange.com/search?q=description+-tag+-recommendation+-reinforcementtwo years of effort and patience in developing a sensible consensus about the AI SE sub-site's description, taking care to be respectful of other established SE sub-sites and insuring a faithful representation of the content contributions and voting choices of members, we seem to remain once again in limbo.

Is it possible to change the description, or are we stuck with the current pathetically narrow and unrepresentative one?

Perhaps, rather than let this recent vote become stale and start all over again next year, it would be functionally wise and ethically correct if those who have power just told us frankly what the deal is.

Is it fixed or variable?  If variable, has SE been notified of https://ai.meta.stackexchange.com/questions/1430/what-should-the-ai-se-site-description-bethe selected one?


  Artificial Intelligence Stack Exchange is a question and answer site for people interested in AI theory, mathematics, research, discovery, design, development, practice, embedded uses, cognition, policy, and impact.


If fixed, let's not, going forward, enter into some democratic process and waste everyone's time proposing and voting on descriptions that can never be.
b2A1I9n14a1r18y25_g7l12o15b2e5Is the Artificial Intelligence beta stuck with its current out-facing description?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Sorry, I've been pretty busy and wasn't able to keep an eye on the new discussion. I'll try to make something happen later today.b2A1I9n14a1r18y25_g7l12o15b2e5(1st!) +1 for caring so much but just keep in mind the description while important symbolically doesnt actually affect much dynamics of the site...


















I don't see why AI should be different to SO in this respect. Updates to questions should be limited to clarifying, improving layout, spelling and grammar. They should not add new insights from or progress of the questioner, once answers to the original have been written.

In general, this process needs to be more friendly to question answerers that askers. It is more expedient to get the OP of the question to take the extra effort to frame their problem as multiple separate questions, instead of having volunteers answering questions track changes and try to follow a conversation (and in the meantime often dilute the purpose of the original question).

If someone tries to alter their question or ask lots of extensions in comments, then in my experience, a gentle/friendly push back and suggestion to ask a separate question is often all that is required. It is more helpful to show what the question OP should do as opposed to telling them that they are doing something wrong. 

If the OP of the question ignores such a suggestion, then the best next step is to walk away. There is no point arguing with them if they think they know better how the site should work. Just let their extensions to the question go unanswered. If that is disappointing to you (because you found the question a really good fit to the site, and were excited to answer it), then perhaps help the OP further by opening the new question yourself and pointing them at it - although I personally would not go that far, there are always other good questions.

Regarding this scenario:


  it may not be popular with a Q author and A author that are essentially collaborating on a small project together and are fully engaged in an extended helping process


It's not really what the site is for. I would either:


Downvote or close the question, if it was clearly too long/confusing and broad to meet site guidelines.
Ignore the question if it kept changing, as it would be a waste of time to get involved, and it is only one question. This is not common behaviour.


Given how little rep both the asker and answerer would get for their efforts, as the content becomes too dense for anyone else to work with, it is in some ways self-limiting. I note that as it stands today, the OP questioner got 10 rep in your linked question https://ai.stackexchange.com/questions/8128/difficulty-in-understanding-identifiability-in-dueling-network-paperdifficulty in understanding identifiability in Dueling Network paper and the four answers got a total of -2 rep between them. The resulting content is all but incomprehensible to me.

In this case I notice you are one of the affected answerers. I don't think there is much you can do at this stage but chalk it up to experience. There is no way to force collaborating site users to behave according to above - the only tools SE has for moderation at that level are too heavy-handed to apply when the discussion is still technical, on-topic and polite. If you spot the behaviour early enough you can comment that you prefer it another way (and IMO the "correct" Stack Exchange way would be separate questions as you suggest), but if the whole thing has momentum with updates to both questions and answers, just leave the others involved in their discussion. 



Some clarifications might still make significant changes, if to answer a question accurately (as opposed to answers with general advice that might apply), the OP needs to add details about their specific situation, including code, data etc. Sometimes this unfortunately can invalidate answers that attack the question in a general sense. This is a tricky area to judge correctly. I think the line is most clearly drawn when the OP unilaterally adds new data, or is obviously changing their question in response to an answer which has already helped them.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I strongly agree with this.  I remember one instance early on in my modding career where an OP asked an unclear question, and it received valid two answers that interpreted the question differently.  I tried to address that by editing the original question which only opened up a can of worms and created more problems.  What I concluded was that *if it's not the OP providing the clarifications, it's problematic.*


















OK, this is partially done now, sorry for the delay. https://ai.meta.stackexchange.com/a/1443/75This proposal (lightly edited for length) has now been used to update the blurb at the top of our https://ai.stackexchange.com/tourtour page! To get various other instances of the text updated, we'll need to contact Stack Exchange. They're pretty busy at the moment, but hopefully something will happen here within a couple weeks.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Fair enough, full version reinstated. I definitely should have checked before trimming things down, sorry :)


















I agree that such questions are low-quality. I think the current options take care of these cases pretty well:


  They usually show no effort in asking the question


Downvoting is appropriate for such questions. In fact, the first part of the downvote arrow's tooltip is "this question does not show any research effort." Note that it's possible for a question to be entirely on-topic and well-phrased (therefore not being a good candidate for closure) but still be of poor quality.


  They [...] are hard to answer because it is not totally clear which variant of the algorithm / which facts about the algorithm the OP knows.


These are a perfect application for the "unclear what you're asking" close reason, which asks the author to clarify. Note that it's possible for a question to be on-topic but still unclear or overly broad.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I agree that there are options to deal with it. I just wanted to be more helpful to the OPs by showing them a clear and easy way how to improve their question. Asking good questions seems to be hard for some people. When a question is closed with "unclear what you're asking" it's way harder for them to improve then when it's closed by "algorithmic questions require description of the algorithm"


















The question becomes whether that information and the context it provides might be relevant in understanding the source of confusion or how the question might be answered (i.e. write for your audience).
Certainly, someone saying:

"I am an {x} year student who is/is not familar with {x}; can you explain this to me in a way that others like me will understand?"* ← USEFUL CONTEXT

Of course, that doesn't necessarily forgive a question exhibiting insufficient understanding of the problem to bring it to a site like this ("too soon, where are you  stuck specifically? what have you tried?").
But where "needless introductions" can be stripped away is where it becomes chatty filler not really relevant to the post:

"Hi, guys. I love this site and y'all are great and I've been here for 3 years and now I have a question and I hope you all can help me yada yada ...
<actual question>
Thank you so much. I really appreciate your help. Important, important. Hopefully I can get an answer soon.
signed <username> <smiley emoji>
<list of credentials>
<list of favorite tomes>
<meme cartoon>

Of course, you don't have to become overly head-strong and vigilant in stripping away every incidental nicety. The overall goal is to make the content demonstrably more clear for those who come after. Use your judgement with those goals in mind and most of those leave-it/remove-it questions should become a bit more self-evident.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Thanks for the insight.


















It was unanimously agreed that the current AI Stack Exchange description in the below depicted drop down and search for MORE STACK EXCHANGE COMMUNITIES is a misrepresentation for two reasons.


Not nearly descriptive of current Q&A content
Not aligned with the current interests of active members


https://i.stack.imgur.com/Bgp1M.png

Worse that that, the text being somewhat technophobic in the mentioning of life and challenges related to AI, the description is not attractive to those qualified to write answers to the many legitimate questions about AI research, design, and use not yet answered well. In short, leaving the above drop down text is counterproductive and damaging to the growth of the beta.

The technophobic nature of the current public description is not philosophically aligned with IBM's Watson lab, which is problematic for IBM, our current sponsor. Technophibia may be brand erosive for IBM.

A previous vote was taken in 2016, but the result of the vote was not acted upon and was this year dismissed as stale, so a new vote was taken two months ago. https://ai.meta.stackexchange.com/questions/1430/what-should-the-ai-se-site-description-beThis year's vote was https://ai.meta.stackexchange.com/questions/1422/how-can-we-change-the-site-description-to-match-our-current-topic-guidelines-an/1423?noredirect=1#comment1708_1423initiated by a moderator, conducted democratically, and is both valid and fresh. The description in https://ai.stackexchange.com/tourthe Tour has been https://ai.meta.stackexchange.com/questions/1461/is-the-artificial-intelligence-beta-stuck-with-its-current-out-facing-descriptio/1463#1463updated by Ben, but the CMS value for the MORE COMMUNITIES drop down shown above https://ai.meta.stackexchange.com/questions/1430/what-should-the-ai-se-site-description-be/1437#comment1860_1437can only be altered by SE employees, and it remains stuck with a misrepresentative and technophobic description instead of the result of the democratic process.

The unusual delay in updating a simple CMS text value probably qualifies this shortcoming as a bug or feature request. Please make the modification so that we can attract qualified contributors capable of answering the many unanswered questions that have been accumulating.
b2A1I9n14a1r18y25_g7l12o15b2e5When will the CMS value corresponding to the description in the communities drop down be changed?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5It's whenever we can get Stack Exchange staff to actually do it. You can try emailing team@stackoverflow.com; I've been trying on and off behind the scenes to get them to implement the changes, but so far no luck.b2A1I9n14a1r18y25_g7l12o15b2e5@Mithrandir, Don't bother. It's a waste of time.


















Likely it's going to be a while.  I emailed the "powers that be", noting that we're starting to get traction and that we have a prestigious sponsor, but no reply as yet.  I'll ping them again after the New Year and update my answer as I get more information.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5@DouglasDaseeco I think the community did a good job redefining the core mission, and suspect it will hold for years to come.b2A1I9n14a1r18y25_g7l12o15b2e5The core mission is far from defined, and if it were, I wouldn't like the definition. The description will never change to the result of any democratic process, so it was a waste of time.


















First, badly formatted posts should be fixed; that is what the wiki-style editing is for. 

But that specific question should be closed as primarily opinion-based because it is soliciting arguments and debate centered around a vague premise built on a hypothetical future which does not currently exist. Please don't let this site become https://worldbuilding.stackexchange.com/help/on-topicWorldbuilding. It is not a good fit for this site. 

But to answer your question more generally, if the premise of a question is wrong or misleading — whether by misunderstanding or pop culture hype — you should answer in a way that dispels the mistaken belief. Head off the incorrect information or assumption with a cohesive answer explaining the issue correctly. 

Folks around the Internet are searching for this (mis)information wherever they can find it. It would nice if they landed here to straighten out the issue authoritatively.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5What do you think about things which you cannot deny or approve...Like 'parallel government'..Can't deny nor can assure it's existence....Like God based topics (can't prove or disprove). What should be done then?


















There's actually a great deal of debate about this subject in general in the wider AI community (ethics re: implementation of AI).  

That said, the question is poorly worded, and overly focuses on the proffered scenario, as opposed to the underlying general issue.

I've retagged (ethics, social, legal) and have provisionally closed the question, pending clarification.  
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5The problem here is not the question itself but the solution...I can easily vote to close the question or downvote it, but it will give the new user a bad experience.b2A1I9n14a1r18y25_g7l12o15b2e5@DuttaA  In this case, although it partly a factor of bad, un-re-retranslated translation, I was unable to extract a line of thinking related to AI specifically.  I left it closed after OP edit b/c it's filled with ALL CAPS click-baity, polarizing keywords, which suggests ulterior motives.  (Distinct from noob OPs with earnest question who might not know how to ask them properly yet, being new to the field or self taught. It's these folks we want to encourage, not the really passionate ones who can't form a cogent, on-topic, answerable question.)


















I asked https://ai.stackexchange.com/questions/10539/should-facebook-safety-check-work-if-an-account-is-stuck-at-a-name-change-checkpai.stackexchange.com/questions/10539/should-facebook-safety-check-work-if-an-account-is-stuck-at-a-name-change-checkp after https://webapps.stackexchange.com/questions/103217/will-facebook-safety-check-work-if-my-account-is-stuck-at-a-checkpoint-pagewebapps.stackexchange.com/questions/103217/will-facebook-safety-check-work-if-my-account-is-stuck-at-a-checkpoint-page and each time the reason is that question does not seem to fit, so the asker is personally verbally antagonized because of repeating the specific grammar/https://en.wikipedia.org/wiki/Search_engine_optimizationSEO of Mark's (@zuck's) exact dictated verbatim use of code/language?

To quote and repeat their apparently questionable (judging by the quick solved-same-day-every-time-nobody-else-could-help-better-if-they-read-too moderator responses of Stack's encouragement) wording again, "Zuckerberg didn’t seem to have any specifics, but he went out of his way to tell me he thought artificial intelligence was going to play a big role in identifying moments of crisis on the network." from https://www.wired.com/2016/11/facebook-disaster-responsehttps://www.wired.com/2016/11/facebook-disaster-response an AI/computer site.

I asked about the fact of if a user still gets safety notifications.
b2A1I9n14a1r18y25_g7l12o15b2e5Is FB.com's "Safety Check/"Crisis Response" for AI.stack or WebApp.stack if @zuck called it Artificial Intelligence?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Please ignore for a moment whether the question is AI-related or not, but what is your expectation for the answer? The question seems soliciting opinion because there's no correct answer (or otherwise, every answer is correct), and that's generally off-topic as primarily opinion-based. Which is the correct answer, "yes", or "no", or "it doesn't matter"? Note that SE is a strict Q&A site, not a discussion forum. Unless you can make the question objectively answerable, then the question seems off-topic.b2A1I9n14a1r18y25_g7l12o15b2e5@AndrewT. How is there not a correct answer to if a user who is at a facebook.com/checkpoint/ page is warned about a natural disaster through Safety Check AI?b2A1I9n14a1r18y25_g7l12o15b2e5@prosody - that question is unlikely to have an answer here. And your previous posts don't seem to be asking what you asked just now. And if it is Facebook specific, why not try asking Facebook?b2A1I9n14a1r18y25_g7l12o15b2e5@prosody-GabVereableContext Because it's then a moral issue (whether it's a right/wrong thing to do) or policy issue (should Facebook allow it or not?), not an AI issue. Replace the "Safety Check AI" with a hypothetical "Safety Check smartphone app" and the basis of the question is still the same.b2A1I9n14a1r18y25_g7l12o15b2e5@AndrewT. I asked about the *fact* of if a user still gets safety notifications.b2A1I9n14a1r18y25_g7l12o15b2e5Prosody - it looks like your posts say "should", and while I still cannot align the wording in them with what you are speaking about here, should is a moral issue as Andrew says.b2A1I9n14a1r18y25_g7l12o15b2e5@RoryAlsop My moderators on Quora.com changed a significant number of my questions to the prefix "Should"/"Would" and I did not fight, that might be trauma then? What word is objective?b2A1I9n14a1r18y25_g7l12o15b2e5I think you made the current question too complicated written. Your previous comment is the question that I can easily understand and objectively answerable: "Do FB users on name change checkpoint still receive safety check notification?". Now, I don't know if company's policy related question is on-topic or not on [webapps.se], but if it's on-topic, then that's the question you should ask. (Note that I can't see your deleted question on [webapps.se], so I don't know the question you had posted on there)b2A1I9n14a1r18y25_g7l12o15b2e5@AndrewT. Okay I can go with that, it's my original question just said another way.  However, https://webapps.stackexchange.com/revisions/103217/13 reworded similarly (do you have enough reputation to read? (Edit: I wrote that before you edited again, if keylog tracked)) and led to still harsh words, I am worried you do not have enough reputation to help counter the crowd.b2A1I9n14a1r18y25_g7l12o15b2e5Well, then [meta.webapps.se] is the place to discuss about your question...b2A1I9n14a1r18y25_g7l12o15b2e5@AndrewT. How many times do I recreate a question uncertain if that is the amount that is too far and find another crowd (a moderator from before is already here saying I do not speak English again, after US Public Schools) of angry moderators? ...is there any effort to assist existing questions or is the goal to make multiplle questions and have me worried about counting?b2A1I9n14a1r18y25_g7l12o15b2e5I mentioned *Meta* WebApps.SE, not the main WebApps.SE. It's the place to discuss and request for feedback how to improve your now-deleted question on there. Assuming [website's policy is on-topic](https://webapps.meta.stackexchange.com/questions/97/are-questions-regarding-website-policies-on-topic), then the core of the question should be on-topic, unless shown otherwise by their community.b2A1I9n14a1r18y25_g7l12o15b2e5@AndrewT. My experience with Quora.com is that if I keep making another question at some point that itself becomes a moderation reason. I have existing questions for commenters to congregate if a discussion is necessary first, otherwise I am scared to make an additional question while being publicly flogged.b2A1I9n14a1r18y25_g7l12o15b2e5Since I can't see deleted post on there, did you receive any actionable feedback/comments to improve your post? If yes, then follow their suggestion. If not, then you can ask for feedback on *how to make your question on-topic (if possible)* on their meta. While SE is **not** Quora, you're right that if you repost the same question, then it's wrong. But SE **allows** any users to request for constructive feedback on their meta site. Otherwise, I'm afraid I can't help you anymore on this issue...b2A1I9n14a1r18y25_g7l12o15b2e5@prosody - quora is very different to Stack Exchange. Please don't use experience there as indication as to what is needed here. And what do you mean by "that might be trauma then"


















Neither of those questions, nor this one make any sense to me. I have read and re-read trying to understand what you mean, and I honestly have no idea.

I would vote either of those ones as unclear what you are asking, or possible offtopic, and have to also vote this one as unclear.

There seems to be a language challenge here. The body of your questions doesn't align with the titles. The titles seem like off topic questions, but the body of the questions is all over the place.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I was exactly wondering the same thing. Is it me or does the question look somewhat Incoherent?


















https://ai.stackexchange.com/revisions/10539/7At the time I read the question for the first time, this is what I interpreted:


Title: "Should" suggests that the question was eliciting opinions of the readers, whether "yes", "no", "doesn't matter", etc., which is opinion-based (off-topic) because there's no one correct answer, or every answers are correct.
1st paragraph: According to your personal experience, "Safety Check" doesn't seem to work when you're stuck on "Name Change Checkpoint" page.
2nd paragraph: According to Zuckerberg, "Safety Check" is using AI.
3rd paragraph: More explanation about "Safety Check", particularly about it not being able to be moderated by public users (i.e. fully automatic)?
4th paragraph:  Explanation about checkpoint page and Name Change Checkpoint page
2 list items: Meta commentary that there are no related questions about "Safety Check" on AI.SE
5th paragraph: Meta commentary, and a slight hint of another question ("what is important for a question about safety"), and a comment about "911 case" (globally recognized), "211 case" (I never heard about that until I googled it), and "911 API" (also not sure, but based on googling, perhaps an emergency reporting system)


So, after finished reading this, the question left me with the impression that it is opinion-based (title) and too-broad (5th paragraph).



Regarding the title of the meta discussion,


  Is FB.com's “Safety Check/”Crisis Response" for AI.stack or WebApp.stack if @zuck called it Artificial Intelligence?


As I'm not a regular of this community, I don't have enough knowledge to determine if it's on-topic or not.

Perhaps the inside work/mechanic of the feature might be on-topic, e.g. "How does Facebook's 'Safety Check' recognize a crisis and alert the relevant user?" looks like AI-related. (Note again, whether it's really acceptable question or not, I can't answer that as I'm not a regular)

However, for your specific question on AI.SE, reading from the title and the non-existence of the explicit question on the body made me assuming that you're asking if Facebook should work or not on a particular case. Most possibly due to language barrier/misunderstanding (note: I'm not a native English speaker), I read the question as a moral question ("is it right/wrong if FB is not doing this?") or a company's policy question ("does FB do this?"), which is certainly off-topic on this site, because the core question is not related to AI at all.

This is an example case of https://meta.stackexchange.com/q/14470/241919"boat programming", i.e. just because Zuckerberg stated that FB's "Safety Check" is done by AI, doesn't mean this question is automatically on-topic on AI.SE.



After the back-and-forth comments on this meta question and https://ai.meta.stackexchange.com/revisions/1495/2the revision to it, looks like the real question is


  I asked about the fact of if a user [currently stuck on checkpoint] still gets safety notifications.


This is a clear question about the current policy of Facebook. While this is off-topic on AI.SE, this looks like on-topic on WebApps.SE based on their meta discussion: https://webapps.meta.stackexchange.com/q/97Are questions regarding website policies on-topic?

Apparently, you have https://webapps.stackexchange.com/questions/103217/will-facebook-safety-check-work-if-my-account-is-stuck-at-a-checkpoint-pageposted the question on WebApps.SE before posting here, but it's been deleted, and according to you, you got angry comments. I believe the core question is on-topic on WebApps.SE, but perhaps the wording gave the readers wrong impression. While I can't see deleted posts on there (so I won't judge anything), the correct place to discuss and request for feedback on how to improve your question is on their meta site, https://webapps.meta.stackexchange.com/Web Applications Meta.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Okay, if formally citing me adding the singular word "fact" https://ai.meta.stackexchange.com/revisions/1495/2 is supposed to be encouragement, that attempt might work. I almost never vote for answers just questions so you are now +1 special. I do not know how I feel about being popular first (my 1st question taking me apart with a long answer had to be here?:) for meta (super meta?) moderation questions.b2A1I9n14a1r18y25_g7l12o15b2e5Can I vote for just the line number with Git Blame https://git-scm.com/docs/git-blame? Partial vote? ~3.7%? of your citation?b2A1I9n14a1r18y25_g7l12o15b2e5Is .meta. actually .moderation. and secretly public (did I miss that with Quora.com:)? Is that why you are all always crowded telling me to go to "ask another question", you all mean ask Meta==Moderation, and that is now a colloquial passing synonym here, even though being called meta usually meant verbal abuse that you/me are being taunted in *any other* context in real life with how being called "meta" means a slur? Usually "ask another question" (partly what I called "angry") means "go away" does not necessarily mean "try". Now I am learning Meta means Moderation basically?b2A1I9n14a1r18y25_g7l12o15b2e5I will link/credit you for your wording of "I asked about the fact of if a user [currently stuck on checkpoint] still gets safety notifications." once I re-ask.b2A1I9n14a1r18y25_g7l12o15b2e5@prosody-GabVereableContext Every SE site has its own meta site, and it might help to understand [what "meta" is and how it works](https://ai.stackexchange.com/help/whats-meta).b2A1I9n14a1r18y25_g7l12o15b2e5Apparently ".Meta" is too abstract for me (I know that's funny almost, me being meta and abstract too), I think ".Moderation" would have worked. The mod chats were called mod chats FWIW. Thank you for helping me with my first meta questions here and now https://webapps.meta.stackexchange.com/questions/4619/specification-of-facebook-safety-check-crisis-response-being-about-the-feature (https://webapps.meta.stackexchange.com/revisions/4619/2), feel free to edit me if you think of better wording.


















I remember that one, and the first thing I did was edit the question to make the wording more suitable.

So "Why are AI models so racist and how can we actually reverse this?" became "How is it that AI can become biased, and what are the proposals to mitigate this?"

Now, if this had been a question about chatbot Tay, racism would have been the relevant term, because there it's not statistical bias, but an algorithm learning and replicating racist human behavior in an NLP context.

In terms of answers, we need to clarify the issue or method or application, in service of disambiguation, demystification and demythification.  



Bear in mind we are likely to only see questions on issues of algorithmic bias increase—it is a major issue, involving data and statistics.  (Neo-luddism seems to be rearing it's head in that the effects reported on are initially unforeseen.)  

If we're not lucky as a society, we are likely to also get increasing questions about procedurally generated racism.  Malicious bot activity in relation to politics I suspect will only ever increase. 
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5These type of questions can have a tendency to generate highly opinion based answers. For e.g I consider harmless stereotypes to be non racist, whereas some other users might not agree. Similarly, many people might argue about the origin of racism (when in reality we have very less understanding of how AI works).b2A1I9n14a1r18y25_g7l12o15b2e5@DuttaA yeah but what is your assessment of Tay using racial slurs?  (Also I might posit that "harmless stereotypes" are not so harmless, based on how they've been used historically.)   But the issues of algorithmic bias is real and will not be going away anytime soon. As Neil noted in his answer, you can only work to remove it once you've become aware of it, and this type of applied bias can have real social impact.b2A1I9n14a1r18y25_g7l12o15b2e5@DuttaA That said, the way to respond to legitimate questions is dispassionately, as Neil did in his useful answer to that particular question.b2A1I9n14a1r18y25_g7l12o15b2e5tay was literally trained by the worst community on the internet, it is expected that'll happen. A kid learns from it's surroundings.  The main point is It kind of annoys me that misinformed journalists are spreading so much malicious info about AI. Elon Musk say's something about AI and the journos will jump in on it and predict AI as some kind of sci-fi demon like skynet. This is having a knock off effect on the public, they think AI means as smart as humans when in reality it's just a bunch of numbers with no real intelligence.b2A1I9n14a1r18y25_g7l12o15b2e5You'll see people who ask such questions themselves are guilty of stereotyping an AI as a person and treat it prejudicially when in reality it's just a stupid algo. It taints the overall picture of the AI community to the general public. That's my 2 cents.b2A1I9n14a1r18y25_g7l12o15b2e5@DuttaA It's really a statistical issue in terms of algorithmic bias, and therefore should not be a charged subject.  (Re: algorithmic racism, it does seem to be an issue of who it is learning from.  My sense is that Zo, Tay's successor, is being "parented" by humans who are restricting what she can learn from, similar to human parenting, which involves passing on beliefs and social mores.)  Part of the function of this stack is to address social impacts.b2A1I9n14a1r18y25_g7l12o15b2e5yes but the OP's don't treat it as such, they come in with all guns blazing. Yes an AI should be parented by humans, but the problem is AI is still an algorithm and will be still be influenced if subject to significant negativeness. Basically Ai is blown whichever direction the wind blows. And as far as I know there is no way to combat it without degrading the AI.b2A1I9n14a1r18y25_g7l12o15b2e5@DuttA Our job is to delete the questions that are off-topic, and reform the questions that are on-topic but inaccurately worded.  In the example question, the OP is legitimately trying to understand the mechanism for Google's algorithm.  Even the misconceptions of the OP are valuable because a good answer clarifies and corrects them.b2A1I9n14a1r18y25_g7l12o15b2e5Let us [continue this discussion in chat](https://chat.stackexchange.com/rooms/90403/discussion-between-dukezhou-and-duttaa).


















Came across a https://ai.stackexchange.com/a/11136/1671messy link-only answer today, and had to edit to include the titles for the papers with embedded links. 

Web addresses reduce readability, and links can expire, limiting future utility.  (Ideally, we would also cite the authors, but my experience is title-only works fine for search.)   


Should we do a section in the "https://ai.stackexchange.com/help/on-topicWhat can I ask about here?" and/or else where to specify how links to research should be handled?

b2A1I9n14a1r18y25_g7l12o15b2e5Do we need a special note on linking to research?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Nah...A person not bothered to title the links sure won't be bothered to read any kind of instruction.b2A1I9n14a1r18y25_g7l12o15b2e5@DuttaA Sadly I have to agree.


















I agree strongly and think this is necessary, especially now that we're getting a good number of questions, and need to raise out stats on having multiple answers.

2 suggested additions:


Clear guidance on when to ask on Data Science and Overflow.
"Social impacts" as a separate sub-category


re: social impacts, I think it's distinct from philosophy, because it deals with tangible effects.  It would also cover "mythology of AI" (singularity, robot takeover, etc.) and "AI journalism", which I think is an increasingly important topic--policing misleading reporting.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5My this question was on topic though https://ai.stackexchange.com/questions/7555/keeping-track-of-visited-states-in-breadth-first-search


















I mostly agree with the guidelines for on-topic topics proposed in the OP. The only possibly gray area for me is in this:


  Furthermore, I would say that every implementation-related question should always be considered off-topic here, given that there's already Stack Overflow (and Data Science SE) for this.


Now in most cases I do agree implementation-only questions are better suited for StackOverflow (especially Tensorflow ones, since Stackoverflow is the official place for Tensorflow questions). However, a recent implementation question that I feel like may be better suited here was this one:

https://ai.stackexchange.com/q/11433/1641Expressing Arbitrary Reward Functions as Potential-Based Advice (PBA)

It technically is just an implementation / bugfixing question, which I'd usually feel like should be off-topic... but it is about a rather specific, non-trivial, relatively recent AI publication. I was personally already familiar with the paper (maybe because I spent a couple of years working in the same lab that these publications came from earlier, with some of the same people), but I think very few people on StackOverflow would be familiar with the paper or feel like reading it just to make sure they'd be able to answer the question correctly.

Would such implementation questions about very specific, relatively uncommon approaches still be considered on-topic here? I'm not talking about common stuff, like implementing "Neural Networks" or "an image classifier", plenty of people on SO know about that too.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Bug-fixing answers usually provide little utility to anyone but the question asker, in my opinion. They add little value to our archive of answers when compared to conceptual questions. So it depends on our priorities. Do we want to help individuals, or do we want to focus efforts on questions with a large impact?


















My feeling is this should be addressed by voting since Quora is no more commercial than Stack (limited ads,) thus such links don't constitute spam.

I do see Stack & Quora in competition, although I hope Stack will ultimately prevail in terms of search rankings.  (US Alexa ranking for Stack is 115 worldwide and 65 in the US, vs. 78/47, so we're not quite there yet.)

But, in some sense, both sites have the same mission, if Stack seems to to a better job because of our voting system.  
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Quora has also a voting system, but it is "shallower". I would actually attribute the greater success of Quora with respect to SE to their more flexible and welcoming system. Furthermore, it is my impression that SE users are also known not to be very friendly. The introduction of warnings like "_X  is a new contributor to this site. Take care in asking for clarification, commenting, and answering. Check out our Code of Conduct."_ is likely due to this known rude behaviour of SE users with respect to new users (that just need help and find themselves more desperate after having visited SE).b2A1I9n14a1r18y25_g7l12o15b2e5I don't see Quora as competition, and I don't see them having the same mission. Quora has even moved further away from Q&A by removing the question details (a few years ago). And the number characters for the title/question is quite limited. It is now much closer to what Joel Spolsky called "provoked blogging". Quora is closer than ever to Yahoo Answers ([but with much better grammar](http://knowyourmeme.com/memes/how-is-babby-formed) - especially as editing is a possibility).b2A1I9n14a1r18y25_g7l12o15b2e5@PeterMortensen I agree, and now find Quora even less useful and reliable than it was previously.  (Essentially, people blogging and making claims with no real vetting or challenge--great way to confuse issues and introduce misleading information!)  Stack can be an unfriendly place at time (although we are getting better,) but having to face challenges to questions and answers is a very good thing!b2A1I9n14a1r18y25_g7l12o15b2e5@DukeZhou It might be true that Quora contains more misleading answers and, in general information. However, it contains a lot of questions. Sometimes, if I am lost or I want quickly an answer to my question, I look for an answer on Quora first, because it's likely someone has already asked it there. It is then a little the responsibility of the reader to also ensure the quality of the given answers there.


















Just found something immensely interesting on ai.SE.

https://ai.stackexchange.com/questions/9582/can-someone-suggest-me-a-platform-to-develop-a-mental-health-mobile-app-for-andrFirst Question

https://ai.stackexchange.com/questions/9542/can-someone-suggest-me-a-platform-to-develop-a-mental-health-mobile-app-for-andrSecond Question:)

Both the questions are identical. They are not just duplicate questions rephrasing eachother, they are literally the same. 

I don't know how neither of them was not marked as duplicate by fellow users. Moreover, the questions have received separate answers and upvotes too. Does this raise any concerns to/from the community?
b2A1I9n14a1r18y25_g7l12o15b2e5Duplicate questions answeredb2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5The community is short in community members for active moderation.


















Looking at it, it looks like the OP didn't realise how user accounts work, or how the site works, so created a new account and a new post in order to be able to interact with the post.

I have flagged for the posts and the user accounts to be merged.

It's not a major issue - on a small site with few active members things like this happen, just vote to close as dupe or flag if necessary.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Yeah, I even I thought that was the case.b2A1I9n14a1r18y25_g7l12o15b2e5The questions have been merged, thank you both!


















I raised the flag, since it was the second time OP posted link to quora answer written by the OP. IMO referring to one's blog is ok, but referring frequently is not ok. Also it is not much hard to copy paste from the blog and at the end attribute it to the blog (both the answers did not involve any technical or Math details), so it does not make sense not to do it.

Also since the user was new I did not want to comment wrongly on what's accepted and what's not in this stack, so I just thought moderators will do a better job.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I respect your opinion, and am grateful for the flag, which brought it to my attention!b2A1I9n14a1r18y25_g7l12o15b2e5@DukeZhou I am not offended or anything..I just think there is rules in SE to link own work even if it is attributed. The answers the person gave or the content of the link IMO really did not demand linking, but when the OP did it twice I thoughts moderators should better look into this.b2A1I9n14a1r18y25_g7l12o15b2e5Your concern was prescient.  I closed an answer today that was clearly a low effort attempt to drive traffic to a loosely related Quora answer.  Definitely feel free to flag these--not all may warrant closure, but I appreciate the assist in identifying potential abuse!


















A new tag ant-colony has been introduced. I see 2 problems here:


The name should have been ant-colony-optimization
The tag swarm-intelligence should already cover ant colony optmization techniques, so it does not make much sense for a new tag.


What are your thoughts?
b2A1I9n14a1r18y25_g7l12o15b2e5New Tag Ant Colonyb2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I do favor "ant-colony-optimization" for being more explicit.


















I introduced this tag because ACO is a well developed sub-field of swarm intelligence, so it deserves (IHMO) its own tag, like e.g. reinforcement learning deserves its own tag (compared to machine learning) on a website dedicated to AI.

I used https://ai.stackexchange.com/questions/tagged/ant-colonyant-colony because it is shorter and there's no ambiguity in the field of AI. Furthermore, a lot of people do not refer to these algorithms as "ACO", but e.g. as "ant colony system" or just "ant colony algorithms". I would argue that https://ai.stackexchange.com/questions/tagged/ant-colonyant-colony is a more general tag and expression.

Furthermore, several questions on ACO have already been asked on the website.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5It's overkill since unlike RL there aren't much questions about swarm intelligence..And also following this trend will result in bee, fish, whale, termite, etc etc optimization. In fact elseiver or some other journal I cannot recall banned the use of 'some random animal' optimisation technique.b2A1I9n14a1r18y25_g7l12o15b2e5@DuttaA "there aren't much questions about swarm intelligence". What's the threshold for creating a tag? For me 1-2 questions are enough. The other tags will be created once 1-2 questions on the topic are asked.b2A1I9n14a1r18y25_g7l12o15b2e5I personally like this tag!  Hopefully we'll get more questions related to ant intelligence, since ants are a very successful species, and extremely good at building tunnels and pathfinding, despite having tiny brains.)


















Wondering if we should maybe just have a general tag for "ant-intelligence" that could cover all aspects, including swarm intelligence, engineering (tunnel building) and path finding..
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5@nbro thoughts?b2A1I9n14a1r18y25_g7l12o15b2e5I do not think it will be correct, since ants are not the only animal showing collective intelligence. I just thought creating a new tag for just 1-2 questions is not properb2A1I9n14a1r18y25_g7l12o15b2e5@DukeZhou "Ant intelligence" doest not seem to be a common expression (AFAIK), so new users maybe would be lost. I think that [tag:ant-colony] is a good tag too. ACO is a sub-field of swarm intelligence. As I had said, since there already 5-6 question on the topic, I decided to create it (to be more specific).b2A1I9n14a1r18y25_g7l12o15b2e5@DuttaA but ants do seem to have unique qualities, and have been studied in relation to several types of problem solving.b2A1I9n14a1r18y25_g7l12o15b2e5@nbro Looking at the questions, at least two seem related to pathfinding though...  Does "ant-colony" cover this aspect?b2A1I9n14a1r18y25_g7l12o15b2e5@DukeZhou the thing is that so does bees and termites... Actually some reputed international journal banned the use of 'random animal' optimization. Otherwise researchers were discovering some kind of collective intelligence in some animal and naming it 'that animal ' intelligence.b2A1I9n14a1r18y25_g7l12o15b2e5@DuttaA I hear you.  But I can't see that having a specific tag for ant, or even bees or termites, causes harm.  (Because ants are popular, it might even give us a little boost!)b2A1I9n14a1r18y25_g7l12o15b2e5@DukeZhou just raised a concern..It's subjective though, cause I thought it was not really necessary, not that it's harming anyone.b2A1I9n14a1r18y25_g7l12o15b2e5@DuttaA it's always useful to have these discussions!b2A1I9n14a1r18y25_g7l12o15b2e5@DukeZhou Yes, it is true that a lot of these questions are related to path finding. However, given there is a substantial amount of literature on ant-based algorithms, again, I thought about creating this tag. Maybe we will not create specific tags for other sub-fields of swarm intelligence. It will depend on the number of questions we will receive. For now, we don't have too many questions, but maybe in the future.b2A1I9n14a1r18y25_g7l12o15b2e5I am wondering though if maybe DuttaA's suggestion of "ant-colony-optimization" is helpful in that it makes the tag more explicit.  (Less concerned about the length than clarity.)  Also wondering if we should expand the definition to include all forms of ant optimization, referencing path-finding, so it works as an umbrella tag in the near-term.b2A1I9n14a1r18y25_g7l12o15b2e5@DukeZhou The current description is: "For questions related to ACO". I think that includes all applications, e.g. path finding, but if you want you can add examples of applications to the description. This will not hurt.b2A1I9n14a1r18y25_g7l12o15b2e5aaah.  Just looked at the wiki, and it does state this explicitly. However, this may illustrate the problem--I have a general interest but hadn't initially considered it under this label, in that I was thinking about pathfinding outside of the colony structure...


















In this https://ai.stackexchange.com/questions/12630/infinite-horizon-in-reinforcement-learningquestion (check edit history) you can clearly see the author hosting a IEEE journal paper on a document hosting site (the IEEE links are also provided). Normally, the document should not be  able to be accessed by all (only people with IEEE membership). I am all for free knowledge and very much against monetization of research papers. But are we breaking any laws here by allowing this question or is it upto the OP only?
b2A1I9n14a1r18y25_g7l12o15b2e5Illegal access of documents?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5The author had _also_ provided links to other websites (e.g. Research Gate) where you can request the paper. However, I removed those links, as I don't see the need to provide multiple links to the same paper and they didn't provide an immediate visualisation of the paper. How do you know that the provided pdf cannot be accessed by non-IEEE members? Furthermore, the links to the papers were requested by one of our users (in a comment) and not initially provided by the asker.b2A1I9n14a1r18y25_g7l12o15b2e5@nbro because I clicked the link?b2A1I9n14a1r18y25_g7l12o15b2e5Any article can be requested to the authors and accessed outside IEEE, as far as it is known I got the article from the authors. I believe IEEE does not have the rights over the papers, the authors do.b2A1I9n14a1r18y25_g7l12o15b2e5@MiguelSaraiva but I think they do have the rights whether you can host a paper on a public site.


















Quora has login popup which often prevent reading answer. In my opinion it's definitely not OK to reference  Quora.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Very good point.  I feel like this doesn't happen consistently, but any barrier to the information is suboptimal for an information sharing site (put the motive of mining user data over the mission of the site.)  Kialo is trying to make inroads, but demands registration before even seeing what the site actually is.b2A1I9n14a1r18y25_g7l12o15b2e5@DukeZhou the plagiarism in Quora is mind boggling. Unless the author is quite qualified, I have seen 90% cases it is copy paste job.b2A1I9n14a1r18y25_g7l12o15b2e5@DuttaA You can bypass that login barrier by appending `/?` to the end of the URL.b2A1I9n14a1r18y25_g7l12o15b2e5@DuttaA Yeah. This actually happened to me. I had asked a question on AI.SE and this question was copied and pasted on Quora. I had discussed this on the chat a while ago.


















I believe that, in an academic setting, this would be considered plagiarism, even though you cite or attribute it. If we accept this type of answers, we might encourage users do it again (which would not bring anything new to the web) or to adopt this strategy to easily increase their reputation.

So, I am against this type of answers (especially, if the author of the answer is not the author of the cited article).
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Very good points.  Duplicate information, of dubious value for us. In addition, low effort.  We risk diminishing our reliability by allowing what constitutes advertising and promotion.


















Natural language by itself (that is, without considering computation-related aspects) has little to do with AI. In AI, we want to do NLP, which can be based on natural language, but the tag https://ai.stackexchange.com/questions/tagged/natural-language-processingnatural-language-processing or https://ai.stackexchange.com/questions/tagged/nlpnlp should also include these related discussions or questions. So, the tag https://ai.stackexchange.com/questions/tagged/natural-languagenatural-language should not really exist.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Thanks for reviving this.  Although I agree with Dennis that, in theory, a pure "natural language" tag could have a function, upon review of its usage, it seems clear it should be merged with the "natural language processing" tag.


















Have a look at the source of this answer

$$\underset{\boldsymbol{\theta}}{\operatorname{argmax}}$$
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5beautiful!  appreciate the assist--saved me a lot of time.b2A1I9n14a1r18y25_g7l12o15b2e5@DukeZhou No problem. For this type of questions, have a look at: [https://tex.stackexchange.com/](https://tex.stackexchange.com/). It also helps me a lot. Maybe you could also try a tool like: https://mathpix.com/. I've never tried it, but it might be really useful, if it works.


















Currently, when you flag a question as off-topic, you cannot specify which other SE website it should belong to. I think we should at least have the option to specify that it can belong to Data Science SE, Stack Overflow and Stats SE, given that these three websites are quite related to our AI SE website.
b2A1I9n14a1r18y25_g7l12o15b2e5Flagging a question to be closed as off-topic should offer more optionsb2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Beta sites can't have migration paths (and can't be the target of migration). Use custom flag instead if the question really deserves to be migrated (as the golden rule is: don't migrate crap).


















Currently, the description of the tag https://ai.stackexchange.com/questions/tagged/ai-designai-design is


  For questions related to successful or novel designing standards and procedures of Artificially Intelligent agents.


However, there are questions on this website that look like "How should I design the architecture of a neural network to achieve X?". I believe that this type of questions should fall under the tag https://ai.stackexchange.com/questions/tagged/ai-designai-design or is there an another tag for this type of questions? If not, I suggest to change the description of the tag https://ai.stackexchange.com/questions/tagged/ai-designai-design to make it more broadly applicable.
b2A1I9n14a1r18y25_g7l12o15b2e5The current description of ai-design might be too restrictiveb2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I'm going to think on this one.  Definitely that description could use a revamp!



















Sentience can refer to biological agents, so has a broader scope.  


We sometimes discuss intelligence in general, as a concept underlying AI, and do too with sentience.


Emotional intelligence seems to be an informal term related to a specific kind of decision making


I don't see much relation to sentience in general, except that we regard only sentient beings as having emotions in the conventional sense.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I realized later that emotional intelligence is more about having control of your own emotions. However, I would say that, in general, we should not introduce a tag if the expression is not widely known or standard. I am not sure if sentience is the most common expression to refer to AIs that have emotions. Maybe it is ok to have the tag sentience.b2A1I9n14a1r18y25_g7l12o15b2e5I think there's a more common term to refer to methods that understand or mimic feelings. It's [_affective computing_ or _artificial emotional intelligence_](https://en.wikipedia.org/wiki/Affective_computing), so maybe emotional intelligence already covers the tag sentience. Therefore, I would say, we don't need the tag sentience because emotional intelligence (EI) or AEI already covers everything related to sentient AI and it is a more common term.


















Self-awareness has a lot of usage in general, and I don't think it's entirely synonymous.  Consciousness, in the most basic definition, is merely awareness of an environment.  

Additionally, non-artificial intelligences (humans) have self-awareness.  So it's useful to be able to distinguish.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5How is awareness different from consciousness? AFAIK, they are synonymous. My point is that there is no need to introduce a tag for every single detail. The expression "artificial consciousness" already covers (artificial) awareness. In a site dedicated to AI, there should be no need to just talk about non-artificial awareness or consciousness, that is, the discussion should be related to artificial intelligence in some way. Furthermore, in the context of AI, artificial consciousness is a more common expression. I really don't see the need to introduce two extremely similar tags.b2A1I9n14a1r18y25_g7l12o15b2e5@nbro awareness is synonymous with consciousness, but *self-awareness* is a qualified form of awareness.  (This goes back to at least the Delphic maxim "know thyself", although that is typically understood in the sense of Thoreau--the "examined life".)  My sense is that self-awareness has a lot of use in the literature.b2A1I9n14a1r18y25_g7l12o15b2e5Ok, but I think that artificial consciousness also includes all discussions related to consciousness including artificial self-consciousness or artificial self-awareness. Maybe we could rename the tag [tag:artificial-consciousness] and make it just [tag:consciousness] (in the same way that we have the tag [tag:attention] rather than [tag:artificial-attention]), but I don't think this is necessary. I would say that "self" is even redundant, given that "consciousness" is all about being aware of something, including yourself.b2A1I9n14a1r18y25_g7l12o15b2e5It's just that there does seem to be some basis for asking about the parallel concepts in the natural work, so consciousness in general is distinct from artificial consciousness.  (For instance, questions about Penrose's theory of mind in relation to humans, which would be on-topic, even where it didn't get into AI.)b2A1I9n14a1r18y25_g7l12o15b2e5Ok, then I would suggest having just the tag [tag:consciousness], which should cover both artificial and natural consciousness. I just think that awareness and consciousness are so similar that people will be confused. Indeed, I would not know which one to use (unless I read the description and even in that case it might be confusing).


















I created a soft-question tag, but people don't seem to like using it. But just because a question is "soft" doesn't mean it's invalid--many of the hard science sites have the tag, which was what inspired me to add it here.

I don't know if this is fully sufficient, but at least part of the solution.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Maybe the problem is the name of the tag. Maybe people are not used to the expression "soft question", which is a little bit vague, IMHO. Maybe we can make its description a little clearer. See also https://tex.meta.stackexchange.com/q/1238/63097.


















One of the persistent deficiencies of our Stack is low voting participation.  This is the area we most need to improve.  

Our Q&A is an informal peer review, that ultimately looks to crowdsource information vetting, ideally by knowledgeable participants.  We get a lot of good questions and answers, but the sample size is small in regard to votes.

Yesterday we got a question that received 23 upvotes, and 28 answer votes, in a single day: 


  https://ai.stackexchange.com/questions/13289/are-neural-networks-prone-to-catastrophic-forgettingAre neural networks prone to catastrophic forgetting?


I'm interested in people's thoughts--theories on how the question attracted this level of attention, the nature of question, etc.  

Also, how we can use this type of question to support what seems to be the "meat and potatoes" of the stack, which is more technically specific questions and the math.  

i.e. There are only so many unique questions you can ask about theory, philosophy, social impacts, and so forth, but the technical stuff is a boundless wellspring. The technical Q&As also provide the immediate, tangible utility that built the original Stack.
b2A1I9n14a1r18y25_g7l12o15b2e5Popular Questionsb2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Technically, all the community need is [a few upvotes (mostly on the answers) in the first 8 hours to push a question into the Hot Network Questions](https://meta.stackexchange.com/a/61343/241919) that is shown on the right sidebar of almost all SE sites.


















First of all, I think this question has attracted a lot of people because it is about neural networks, which is a "hot topic" nowadays, and an issue that neural networks face. Given that a lot of people use and like neural networks and were not aware of this issue, people are probably interested in knowing about this problem and how to solve it.

Furthermore, I think the original title of this question, A flaw with nerual networks?, would not have attracted so many people. I realized that the author of such post, to some extent, was asking about the catastrophic forgetting (or inference) of neural networks, so I changed the title to the current one (which is quite descriptive), which I think I has contributed to the current popularity of the question, given that it contains the known (and maybe mnemonic) technical expression "catastrophic forgetting". In general, I have been trying to edit questions, so that to improve their titles and make them more descriptive, which I think can potentially attract more people. The title A flaw with nerual networks? is not very descriptive, because neural networks might have many flaws. So, I encourage every user to edit questions to make their titles more descriptive of the actual problem.

The given answers are also not very technical or long, so they are accessible or understandable by anyone in the field. Hence we should also strive for simplicity, when possible!

There are other questions that I think should have received a lot more attention and upvotes (for example, https://ai.stackexchange.com/q/13317/2444Where can I find the proof of the universal approximation theorem?), but I don't know how exactly Stack Exchange tags a question as a "hot" (and maybe this is just my opinion).
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Appreciate the response and analysis.  This question got a similar level of activity, but it took over a year: https://ai.stackexchange.com/questions/5769/in-a-cnn-does-each-new-filter-have-different-weights-for-each-input-channel-or


















If we want to accept all or most questions that are related to AI and are also on-topic on the Data Science SE, Cross Validated SE, and Stack Overflow websites, then we'd better just merge the websites. We focus on the theoretical and philosophical aspects of AI, but I would not say that all implementation-related questions are off-topic here (but we need to define precisely which ones can be on-topic, which has not yet been done, AFAIK). However, questions that involve the debugging of source code (like "Why am I getting this TypeError in this machine learning program?") should be considered off-topic, because there is already Stack Overflow for these. AFAIK, this website was created because there wasn't yet a website dedicated to the philosophical (and, partially, theoretical) aspects of AI.
(There are a lot of questions on Stack Overflow, Data Science SE and Cross Validated SE that would be better asked here, including some of the questions I had asked there. For example, https://datascience.stackexchange.com/q/26938/10640What exactly is bootstrapping in reinforcement learning?. I remember I had asked it there because, at the time, I had almost no hope in this website and I thought it would not have had a future, given the number of poor questions and answers that I used to see and the small number of competent regular users. I suppose that, if I had asked that question on this website, it would not have received so much attention. There are still users on this website that degrade its quality, because they do not follow the SE standards or because they are just trolling. Furthermore, I think that moderators on this website are too slow and are hesitant to take action regarding certain questions that are not compliant with the supposed goal of the website. For example, there are a lot of broad questions on this website, which could have been avoided, if we had more active moderators that follow the rules. During this year, I've invested a lot of time on this website, so I believe that, in general, the quality of the website (answers and questions) has increased (but this is just my perception of the situation). By the way, I believe that this website still lacks more competent people in certain areas, such as geometric deep learning, POMDP, hierarchical RL, swarm intelligence, etc. People that give good answers on this website are the usual suspects. We need more diversity and perspectives.)
Which implementation-related questions should be on-topic here? I believe that this is a question that should be asked on this meta (if it wasn't already asked). In any case, I believe we should still focus on the theoretical and philosophical aspects of AI. If you also like to answer questions related to implementation issues, then you'd better also use other dedicated websites, such as Stack Overflow and Data Science.

From there, there exist 2 types of people: The ones who are complacent with what they achieved (by just using others' code on their data) or the ones that start to think, How does this work?, or how could I adjust this to also do that?
The latter people I feel are definitely a category of people this site wants to attract (if I've understood this site's purposes correctly). Through implementation, they are trying to understand the process. I understand the counter-claim to this is that questions should be generalized to try to assist as many people as possible, but the number of people this category would invite would make up for this difference (I have no proof/ pure speculation)

There is Data Science SE for these people. However, maybe some implementation-related questions that also involve theoretical or philosophical aspects could also be on-topic here. For example, "How is this concept usually implemented?".
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e51) regarding the more experts-- could there be generated Qs in that field on the site to attract more people interested in those fields? but one issue with have more specific subject matter is that as it is now, it will be recieved poorly (1 vote, if that) as mentioned in a previous question, the site does not vote much even on general Qs.b2A1I9n14a1r18y25_g7l12o15b2e52) Who would be the ones to then start that process of discussing which types of specific Qs should be allowed (is there an occasional group meeting of moderators, or something along those lines?)b2A1I9n14a1r18y25_g7l12o15b2e5Good point about the need for clearer definition of what is on and off topic. Ultimately I think we want whats best for this stack, since we have the broadest scope in terms of AI, but don't want to overly duplicate the function of other healthy stacks.


















Earlier today I answered a question titled "About the paper : “Label-Free Supervision of Neural Networks with Physics and Domain Knowledge”", for which I had to check the original paper. I spent some time answering the question but then, half an hour later the user deleted his question and there goes my answer with it. I do not mind getting no votes or getting downvoted, but information being deleted so easily is quite annoying. 

My question is, isn't there some kind of restriction on deleting answered questions so easily? If there is not, can I block the user so that I won't spend any more time trying to answer questions from him?
b2A1I9n14a1r18y25_g7l12o15b2e5Question deleted after answerb2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Apologies.  I did a search but I can't find the question.  (Link in you can--sometimes they remain searchable.)b2A1I9n14a1r18y25_g7l12o15b2e5https://ai.stackexchange.com/questions/15510/about-the-paper-label-free-supervision-of-neural-networks-with-physics-and-do


















Yes, there are restrictions. For example, you cannot delete a question with more than one answer or with an upvoted or accepted answer. See https://meta.stackexchange.com/q/5221/287113How does deleting work? What can cause a post to be deleted, and what does that actually mean? What are the criteria for deletion? for more info. Apparently, your answer wasn't upvoted. 

Regarding the "block a user" feature, see https://meta.stackexchange.com/q/3353/287113Add the ability to ignore users.

I understand your feelings now, given that you spent time to provide a good answer and information. However, I would advise you not to give much importance to this episode. It may happen, but this usually does not happen!
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Follow up: Isn't there supposed to be a time limit for that? I mean the question itself had 2 upvotes (if I am not mistaken), so those people probably would be interested in learning the answer but they probably never had a chance to see it. And any restriction on the number of question a user can delete in a given period of time?b2A1I9n14a1r18y25_g7l12o15b2e5@serali After having quickly skimmed through the linked answer, it seems there is no time limit or restriction. If there was a link to such a question, I would see it, but I don't have the link to it. I suggest you read https://meta.stackexchange.com/a/5222/287113 for more info.b2A1I9n14a1r18y25_g7l12o15b2e5Do you think the question does any harm, because I can undelete it...b2A1I9n14a1r18y25_g7l12o15b2e5@DukeZhou After having read it, I don't think that the question can harm anyone, apart from the original poster (that is, the OP deleted it for some reason, I suppose). I would undelete it and ask the OP for clarifications regarding its deletion. I can also undelete it, btw, but I only noticed now that the link to the question has been provided.b2A1I9n14a1r18y25_g7l12o15b2e5I went ahead and undeleted b/c in this case, the deletion was unfair to the responder.


















I believe that only questions and answers that have been edited by multiple users and that no longer resemble the original question or answer, respectively, should be made community wiki, given that the upvotes or downvotes are no longer only associated with or attributed to the user that originally posted the answer or question. For example, this answer https://ai.stackexchange.com/a/8688/2444https://ai.stackexchange.com/a/8688/2444 should be made a community wiki, given that its current version and quality is due to multiple users.
In the article https://stackoverflow.blog/2011/08/19/the-future-of-community-wiki/The Future of Community Wiki, it is stated in the section Community Wiki is not a "Quick Fix"

Many sites propose using community wiki to allow content that is on-topic and useful, but can be considered borderline or questionable in other ways. Someone notes that a certain class of question has problems, and proposes using community wiki as a quick fix.
If a question is valuable enough that you believe it belongs on the site, chances are you don’t need it to be community wiki! We welcome all contributions which improve the quality of a site and advertise its greatness to the rest of the world. If you allow a certain class of questions, but only under the stipulation that no one can earn reputation from them, you’ve strongly discouraged these sorts of questions. People aren’t going to put in nearly as much effort to ask them.
Instead, strive for quality. If you're unsure a certain question class belongs on the site, don't tolerate the worst examples — demand that these questions be awesome. Questions shouldn’t be swept under the rug with community wiki; they should get the same respect and treatment as the rest of your Q&A. If those questions are something you are uncomfortable showing to visitors … they probably don’t belong on your site.
Many things which "need" to be community wiki simply don't. Sometimes it’s just a matter of understanding the root of a question: "Software to record video games" can be turned into a great question without needing the crutch of community wiki. Or, you may need to break the original question into smaller parts; a rather well-timed Ask Different Meta post explores this very avenue.

Hence, the question https://ai.stackexchange.com/q/15594/2444What are all the different kinds of neural networks used for? should probably be closed as too broad. However, given that I edited the post to include "I just need a brief overview (1-2 lines) of their applications.", the scope has been slightly limited. So, at this point, more than one user has contributed to the quality and current version of the question, so maybe it should be made a community wiki (according to my belief above).
In the section Community Wiki is primarily for Answers of the same article

If we haven’t said this enough already, questions rarely, if ever, need community wiki. What about answers? We removed the ability for users to make a question community wiki, but left the ability for users to make an answer wiki.
The intent of community wiki in answers is to help share the burden of solving a question. An incomplete “seed” answer is a stepping stone to a complete solution with help from others; an incomplete question is a hindrance and an obstacle to getting a solution as no one understands the inquiry. It is in answers that the goal of community wiki, for the community, by the community, shows its truest colors.
Yet even in answers, true collaboration is scarce. Most of the time, a single individual can provide a complete answer. There are even times where a question looks like it’ll need a massive effort, but one gallant user steps up to the plate with an impressive and comprehensive answer.

See also https://meta.stackexchange.com/q/11740/287113What are "Community Wiki" posts?.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I think the impetus was that it's a broad question, outside of the scope of the normal Q&A which depends on narrow questions, and would function as a general resource.  Thus an exception.b2A1I9n14a1r18y25_g7l12o15b2e5@DukeZhou Yes, but in the article that I quote, there is a section "Community Wiki is not a "Quick Fix". So, too broad questions should not be fixed by making them community wiki.b2A1I9n14a1r18y25_g7l12o15b2e5I don't see that question as needing to be fixed, just that broad questions with suitable answers would seem to be good candidates for community resources.  (For instance, if someone were to ask about the different categories of AI in general, and we got a strong, definitive answer.)b2A1I9n14a1r18y25_g7l12o15b2e5@DukeZhou Given that it is too broad, it should be closed or fixed (to reduce the scope of the question). So, in this sense, this question needs to be fixed. If you make this question a community wiki, someone may edit it to include more neural networks, etc., which will lead to other long answers. I believe that we should really be more strict when it comes to broad questions, which can't really be answered satisfactorily or have a wide range of possible answers. I think this is one of the main problems of this website that needs to be solved.b2A1I9n14a1r18y25_g7l12o15b2e5I have to wonder though, if a few strategic broad questions might yield steady traffic, and help boost site participation in the long term, in that we'd be providing not only narrow Q&A, but a few vetted, general resource pages.  (For me it's always ultimately going to be about utility, even if rules have to bend on occasion.)b2A1I9n14a1r18y25_g7l12o15b2e5@DukeZhou I believe that this is not the right approach. If we allow certain posts to live only to attract more people, then these may degrade the quality of the website, with respect to the "SE standards and philosophy". SE is supposed not to allow all type of questions and answers. Anyway, I hardly doubt that anyone else in the future will have the exact same question as [https://ai.stackexchange.com/q/15594/2444](https://ai.stackexchange.com/q/15594/2444), which means that it won't answer the exact question that someone else will have. This is also why I am against this type of questions.b2A1I9n14a1r18y25_g7l12o15b2e5@DukeZhou For example, I think that a question like "What are some potential applications of Liquid State Machines?" would be a lot more interesting, because the answerer could go more into the details. An answer like "RNNs can be used for sequence prediction" can be found very easily on the web.b2A1I9n14a1r18y25_g7l12o15b2e5LSMs would be interesting, and I notice the Wiki for it is fairly sparse.  (PS I saw your note on  https://ai.stackexchange.com/a/8688/2444 as a wiki, but hesitating b/c it's a duplicate, and doesn't have many votes.  Was part of your thinking that making it a community wiki would allow differentiation from the duplicate?)b2A1I9n14a1r18y25_g7l12o15b2e5@DukeZhou I mentioned that answer as an example of an answer that could become a wiki because its current version does not resemble the original answer. Given that it is already marked as a duplicate and, indeed, it has not received many upvotes, I would not take action in this case.b2A1I9n14a1r18y25_g7l12o15b2e5pps- i declined that flag on the duplicate because it still come up for me on search, so I thought it would be a good idea to leave the link to the original Q&A...


















My main thought is that we've been seeing requests for data sets to use in training, and these would represent resource requests as opposed to reference requests.

Similarly for people looking for published code to utilize (GitHub as a resource.)
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I am not saying that [tag:resource-request] should necessarily be merged with [tag:reference-request], but I think we should clarify the description of these tags.


















There are several problems. Some of them have already been raised but not addressed.


Too broad questions (or posts with multiple questions) are not closed (immediately). See https://ai.meta.stackexchange.com/q/1536/2444Why aren't too broad questions closed?.
Too many duplicate questions, which are not marked as duplicate. See https://ai.meta.stackexchange.com/q/1532/2444What should we do regarding extremely similar questions or duplicates?.
The on-topic and off-topic pages of the site are not clear enough. See https://ai.meta.stackexchange.com/q/1506/2444On-topic and off-topic pages need to be clarified. 
In general, new users should have a clear idea of the most appropriate website to ask a question (among AI SE, Data Science SE, Stats SE, and Stack Overflow), but this has not yet been clarified.
It is still unclear which implementation-related questions are on-topic.
Too many tags that should not exist because they are not directly or strictly related to our scope. See https://ai.meta.stackexchange.com/q/1538/2444On the management of tags on this website. In general, if a question mentions e.g. a certain concept or tool, it does not mean that an associated tag needs to be created. For example, it makes sense to have a tag associated with ant-colony optimization (given that this is a theoretical AI topic), but it makes no sense to have a tag like https://ai.stackexchange.com/questions/tagged/accessibilityaccessibility (which is extremely vague and general). In general, only tags that are associated with common concepts should exist. We shouldn't create a tag for every possible concept or tool. 
Some users that (constantly) provide out-of-context and poor answers. These answers often look like spam, so they degrade the quality of the website.
Currently and generally, moderators are often not very active, responsive and strict enough. 
There's a need for more competent people in certain areas. It seems that the usual suspects tend to answer to almost all questions. We need more diversity and competence.

b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I might disagree that "accessibility" is necessarily off-topic, in that it is a concern of computing in the sense of interfaces, and that AI may be used to facilitate this.  (For instance, speech-to-text and visa versa now not requiring the cloud on mobile devices, per machine learning.)  I'd also argue that tags for specific tools are useful in searching for previous Q&A about those tools.b2A1I9n14a1r18y25_g7l12o15b2e5@DukeZhou There's just one question tagged with [tag:accessibility]. In the meta-post I had created [On the management of tags on this website](https://ai.meta.stackexchange.com/q/1538/2444), I argue that only tags associated with a common AI topic (for instance, topics that have an associated Wiki article) should be created, otherwise, in principle, we could create tags for everything, but, at this point, what would be the point of having tags? I think that tags should be used to group certain questions under certain well-known sub-fields or topics of the field (in this case, AI).b2A1I9n14a1r18y25_g7l12o15b2e5The concept of accessibility may be related to AI, but only remotely. I think that all questions you could tag with accessibility may be tagged with [tag:applications].


















There are the tags https://ai.stackexchange.com/questions/tagged/lstmlstm and https://ai.stackexchange.com/questions/tagged/long-short-term-memorylong-short-term-memory, but they are not marked as synonyms. Of course, the questions associated with one tag should be merged with the questions associated with the other tag.
b2A1I9n14a1r18y25_g7l12o15b2e5The tags long-short-term-memory and lstm should be synonymsb2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5This has already been solved, for those of you reading this.


















It's telling that it's much easier to create tags than remove them, and I have to wonder if this is intentional or just a fail-safe, to avoid untagged questions.

I like tags in general because they allow degrees of specificity.  For instance, most of our questions involve machine learning, but in relation to what?  

That said, there is a lot to digest in your post and I am still going through it, so I don't have any specific response at this time, other than to note that Bayes is a good example. 
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5What does Bayes (the person) have to do with AI? It is not directly related to AI. If you put yourself in the position of the asker, it is highly unlikely that someone will ask a question about the person Bayes, which would be off-topic on this website, by the way.  Even [Math SE](https://math.stackexchange.com/tags) does not have such a tag. I've been a regular user of many SE websites, not just this one. All other websites do not create tags for every possible topic, especially for remotely related topics.b2A1I9n14a1r18y25_g7l12o15b2e5I actually think that tags associated with specific AI topics can surely be created. For example, [tag:ant-colony] is a tag associated with a specific sub-field of [tag:swarm-intelligence]. Both of these tags are directly related to AI. These topics are studied by AI people. On the other hand, there's no AI field that studies the person Bayes. We only use Bayes' work.


















I would not be opposed to making this kind of advise on topic. I think @nbro makes some good points too though. My suggestion is that we experiment with allowing this kind of question, subject to the following provisos:


Questions must be of the form "What is the ideal academic background for someone who wants to work in AI Specialty X.
Questions must not be duplicates or near duplicates.
Questions must be about general job titles, not positions at specific companies (that would be speculative).
Questions must be accompanied by examples of job postings from at least two specific companies (so that we don't get made-up titles, which we otherwise will).

b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5The description of the job titles changes from company to company or over time. In general, asking for advice is OFF-TOPIC, because it leads to primarily opinion-based answers (advice ~ opinion). Furthermore, in 5-10 years, answers to these questions may be misleading or even wrong.b2A1I9n14a1r18y25_g7l12o15b2e5@nbro Some job titles are very stable (e.g. "How do I become a professor in AI?"). Other titles change, but usually not so swiftly that this should be a major concern. For example, programming languages also change over the 5-10 year time frame, and answers to questions about them will become wrong (consider something like "How do I print Hello World in Python?"). Advice like "What should I do, personally?" is clearly off topic, but asking for advice like "Should I use a CNN for image classification?" is on-topic. I think this topic is in between those.b2A1I9n14a1r18y25_g7l12o15b2e5Questions like "Should I use a CNN for image classification?" are on-topic because they can be answered with facts rather than opinions. You can e.g. answer this specific question by referencing a specific research paper that used CNN for image classification and obtained good results. In general, we should really avoid questions that ask for advice rather than facts. See my new proposal for a new on-topic page https://ai.meta.stackexchange.com/a/1616/2444, where I emphasize this point in the notes sub-section.b2A1I9n14a1r18y25_g7l12o15b2e5I've updated my answer: https://ai.meta.stackexchange.com/a/1593/2444. In general, "career ADVICE or RECOMMENDATION" should be off-topic, because these questions lead to primarily opinion-based answers. However, if a question, in the academic context, is phrased in such a way that can be answered objectively, then I think the question is fine. But I am not sure which type of questions, in the context of "career advice", can be answered with facts.b2A1I9n14a1r18y25_g7l12o15b2e5@nbro I don't think that a question like "What skills or qualifications are most essential for someone to become a machine learning engineer?" are purely opinion-based. I do agree that they tend to elicit many opinion-based answers, which are low quality, but there are answers to these questions, and they can be supported by evidence (e.g. the job postings under this title at the FANGs all ask for an undergraduate degree in computer science, a project involving ML, and prefer a masters degree, then there is an objective answer.b2A1I9n14a1r18y25_g7l12o15b2e5"I do agree that they tend to elicit many opinion-based answers, which are low quality", but this is the main reason why we should not accept them or close them as primarily opinion-based because they lead to an overall degradation of the quality of the site. SE sites are different than other sites. "but there are answers to these questions, and they can be supported by evidence", this will rarely be widely applicable. Your evidence will probably be based on your opinion and experience, which is another reason why they should not be accepted.b2A1I9n14a1r18y25_g7l12o15b2e5Also, I am not sure what an ML engineer would be. Every company requires slightly different skills for each job.


















As some have noticed, recently I haven't been able to spend as much time on AI.SE as I did earlier in the site's life. A lot has changed since then; our site specifically has grown and improved a lot. Originally I offered my services as an experienced user of the Stack Exchange network, but now that we are an established site it is much more desirable to have moderators with more subject matter experience.

I therefore believe it's time for a more active and knowledgeable contributor to take my place. A month ago, I notified the other two moderators of my intention to step down. I submitted the official notice to Stack Exchange on October 11 and will retire from moderation on November 12.

Some exciting news has come from this: a moderator election is being planned for AI.SE! Scheduling and details aren't nailed down yet, but it would likely begin some time in January 2020.

In the meantime, I am certain that the fantastic community and remaining moderators will be able to keep the site functioning smoothly. It has been a pleasure and honor to serve as moderator pro tempore, and I wish you all the best!
b2A1I9n14a1r18y25_g7l12o15b2e5Upcoming change in moderatorsb2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Heartfelt thanks for all the time and attention you gave the Stack.  You will be missed!


















I'm interested in running for a moderator position.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I'll note that **nbro led the drive to get math formatting on the stack**, which allowed us to blossom, doing all of the initial work to make it happen.  He spend a huge amount of time on the stack facilitating others by seeking clarifications, cleaning up questions & tags, and strictly adheres to the "be nice" policy. Also notable that he has the second greatest amount of rep, and that was attained in a relatively short time-frame, so I feel it's fair to say he has his finger on the pulse, and a clear vision of what we need to do to continue to improve.


















Thank you for writing to us about this. This isn’t our final response here, but in the interest of being transparent and keeping lines of communication open,I myself, have been yearning for this mod - position for a long period of time.
Therefore, with all my interest and the inner driving force, I'm running for this! I should even be hesitated for it. 

Thanks once again for being informed. Keep us posted of any updates.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Why were you "yearning" for the position for a long time?


















I am happy to run, especially if there is a shortage of candidates, although I think I am not the best candidate for the job.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5You'd make an excellent mod John, even if you had less time to devote than you'd like.  Your background, expertise and judgement make you eminently qualified, and your participation on the mod team would be hugely beneficial to the stack.  (For any unfamiliar with John, I urge them to look at both his excellent answers and comments.)b2A1I9n14a1r18y25_g7l12o15b2e5I should probably also note that **John has degrees in mathematics & AI and a PhD in Computer Science/AI.  He has taught for several years at the college level, and now works in the private sector in an analytics company.**  In my considered opinion, this makes him an ideal candidate to moderate this forum.b2A1I9n14a1r18y25_g7l12o15b2e5(John, let me know if I got anything wrong--I think the information is relevant!)b2A1I9n14a1r18y25_g7l12o15b2e5@DukeZhou that is more or less correct. Both of my graduate degrees are in computer science (think of the MMath in CS as being like an MA in, say, Philosophy). Both of them specialized in AI. Thanks for the endorsement.


















I agree we don't require the tag 'concepts'. But a quick Google search shows there is some https://www.google.com/amp/s/www.researchgate.net/post/What_are_the_differences_between_conceptual_framework_and_theoretical_framework/ampdifference between a Conceptual and Theoretical framework. So either the 'concepts' tage need to be redefined, or a new more detailed/self-explanatory tag name needs to be created.

Although, it is debatable whether users will adhere to such narrow difference of definition to sort questions and answers.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5"Although, it is debatable whether users will adhere to such narrow difference of definition to sort questions and answers.", exactly! As I've said in other meta posts, I think we should only create tags for AI topics that are well-known. The word "concept" is very widely applicable and general. It is not specific to AI, and I think that users may not use it consistently. The tag [tag:theory] should be used in all cases where the user needs to ask a general theoretical question (so a question that does not involve any implementation details), unless there are more specific tags.b2A1I9n14a1r18y25_g7l12o15b2e5For example, if you have a theoretical question related to machine learning, deep learning, neural networks, back-propagation and gradient descent, then you already have 5 tags, so you don't need to use the tag [tag:theory]. However, if your question is related to the definition of AI agents, then you may use the tag [tag:theory] along with the tag [tag:definitions] and [tag:intelligent-agent].


















Summary: Artificial Intelligence Stack Exchange will begin the nomination stage for https://ai.stackexchange.com/election/1a special election on February 17, 2020 to bring in two more moderators.

For full details of the process, see https://meta.stackexchange.com/questions/314459/experimenting-with-pro-tempore-electionsthe announcement on Meta Stack Exchange. The timeline:


Starting on February 17, 2020, users can https://ai.stackexchange.com/election/1nominate themselves. Users can also ask questions on meta for potential moderators to answer. (Use the /questions/tagged/discussiondiscussion and /questions/tagged/electionelection tags.)
On February 24, 2020, if there are three or more candidates, we'll run an election. If not, I'll simply appoint the candidates. (There's a small chance we'll need to https://meta.stackexchange.com/questions/274114/lets-disallow-nominations-from-people-whove-been-suspended-in-the-past-yearremove a nomination, but I doubt that will come up.)
If there is an election, I'll announce the results on meta on March 3, 2020. 


(Note for current moderators: there's no need to nominate yourself even though you'll likely get an email saying you should. The system assumes the first election is a graduation election, which would mean moderators would need to be re-elected. This isn't that sort of election.)

If you have any questions about the process, please stick them in an answer here.




  Note: The election date was pushed back a month, due to some ongoing back-end work on the election mechanics, in order to automate some steps.

b2A1I9n14a1r18y25_g7l12o15b2e5Announcing a Pro Tempore Moderator electionb2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Is there a plan for what to do if there are no candidates? After the recent tumultuous events on MSE I'd almost be surprised if it didn't happen somewhere on the network.b2A1I9n14a1r18y25_g7l12o15b2e5If there are no candidates, we'll extend the nomination period for one week, and cancel the election if that's not enough — our usual process. Though, [it seems there are users interested in running](https://ai.meta.stackexchange.com/q/1602/45) :)b2A1I9n14a1r18y25_g7l12o15b2e5Why are we waiting for so long though?b2A1I9n14a1r18y25_g7l12o15b2e5Because of the holidays that are coming up, @DuttaA :)



















  since we're the general AI forum


We are not a general AI forum. This forum supposedly exists to fill a certain gap. As stated https://ai.meta.stackexchange.com/a/1144/2444in this answer


  It's because the OPPOSITION against creating this site argued (correctly) that we already created sites to handle this subject explicitly. The argument FOR creating this site claimed that we have a missing socio-scientific angle that needed filling.


I believe that ALL implementation questions, such as "Can you explain the parameters of this ML program?", "Why isn't my ML program working?" or "How do you implement this model?", are OFF-TOPIC. They would be on-topic, if we merged this site with Data Science (aka applied machine learning). Similarly, there are already sites for https://hardwarerecs.stackexchange.comhardware and https://softwarerecs.stackexchange.comsoftware (which already has the tag https://softwarerecs.stackexchange.com/questions/tagged/artificial-intelligenceai) recommendations. There is absolutely no need for duplicating services, which are available somewhere else. 

Therefore, I strongly suggest we focus on the social, scientific and theoretical aspects of AI, otherwise, we'd better just merge this website with other websites. Do we want to have a website that 95% overlaps with another website only because people disagree on the meaning of the expressions "artificial intelligence" (or "machine learning") and "data science"? There are so many theoretical questions that have not yet been asked. For example, there could be a lot of questions on https://ai.stackexchange.com/questions/tagged/aixiAIXI, which is a highly mathematical and theoretical topic (that is, a perfect topic for this site), which is not easily understandable, so I would expect a lot more questions, but we only have 2 questions. 

Unfortunately, this website has already taken the wrong direction, IMHO. We already have a bunch of implementation, hardware, and software-related questions, which is partially due to the fact that the community and moderators do not take action with respect to the original goals of the site, which has become quite redundant.

However, there are also topics on other sites that would be better suited for this site, such as reinforcement learning on Stats. To conclude, apparently, there is a lot of duplication of services across sites. Maybe there should be a way of migrating even old questions from one website to the other, as a way of organizing better the communities. For example, there are a lot of theoretical ML questions on Stack Overflow, which could be migrated to this site or Stats.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5The underlying premise of this answer is sound--stick to defined parameters--but I don't think the close/merge line of justification is valid.  We're a healthy stack, not at risk of closure, so it's more a matter of what makes the most sense in terms of the utility we provide.  You make a fair point about https://hardwarerecs.stackexchange.com/ although that stack is still in Beta, and not performing particularly well: https://area51.stackexchange.com/proposals/65287/hardware-recommendationsb2A1I9n14a1r18y25_g7l12o15b2e5@DukeZhou As I said before, almost all questions have utility. We cannot just base our choices on utility, otherwise, everything will be on-topic here! As I say in my answer, if we decide to accept all AI-related questions, then we'd better just merge this site with Data Science. What are your arguments against not merging this site with Data Science (if we decide to accept implementation, hardware and software-related questions)? The arguments will be that we also address philosophical and social issues, which is not the majority of the issues that we address.b2A1I9n14a1r18y25_g7l12o15b2e5Currently, we have 173 philosophical questions and 47 questions tagged with [tag:social]. Of course, there are other tags related to these topics, but the tags with the highest number of questions are neural networks, machine learning, deep learning, reinforcement learning and CNNs, which are all also on-topic on Stats and Data Science. To me, this is a sign of the redundancy of one of these sites.b2A1I9n14a1r18y25_g7l12o15b2e5The scope of Data Science is much narrower than ours, and only involves a specific type of AI (statistically-based.)  https://datascience.stackexchange.com/help/on-topic.  **Interesting quote from their help page: "Data science is a multi-disciplinary field and many new users wonder whether their questions are most appropriate here or on other SE sites" and "If you think a question is equally appropriate on multiple sites, ask on the site with the most users (usually Stack Overflow or Cross Validated)"**b2A1I9n14a1r18y25_g7l12o15b2e5Since we're still an emerging site, on the cusp or graduation but not fully graduated, I tend to respect contributor preferences.  There are clearly users who like hardware, and even implementation questions, in that such questions are reliably upvoted.  (By contrast, where I see multiple close votes, i usually "tip the scales" and close.)b2A1I9n14a1r18y25_g7l12o15b2e5@DukeZhou Well, AI is also a **multi-disciplinary field**. Basically, everything on Data Science could be considered AI, based on the definition of narrow AI. I am not saying that our site is redundant. I am saying that _either_ our site or Data Science are redundant.b2A1I9n14a1r18y25_g7l12o15b2e5Per the DS help advice, in terms of hardware specifically, we have more active users and much more traffic than Hardware Recommendations.b2A1I9n14a1r18y25_g7l12o15b2e5@DukeZhou Well, I am personally not against implementation, hardware and software questions, but there's a lot of redundancy here! Why should we have 2 sites on the SE network that basically do the same thing? It is unproductive! It is like having multiple political parties for each unhappy person. If you disagree on even a tiny aspect, you may decide to create your own political partyb2A1I9n14a1r18y25_g7l12o15b2e5Data Science is more general than just AI, as the field has other applications. AI ∈ DS; DS ⊂ AI.b2A1I9n14a1r18y25_g7l12o15b2e5@DukeZhou How is DS more general than AI? To me, DS is just a buzz word, which essentially means statistics + AI and AI = statistics + logic + heuristics + programming, etc.b2A1I9n14a1r18y25_g7l12o15b2e5Because there are statisticians and analysts who are data scientists, but not AI developers/researchers.  (The field itself is rooted in statistics and analysis, and only recently, Machine Learning.)b2A1I9n14a1r18y25_g7l12o15b2e5Basically, the expression _DS_ only exists because of (the successes of) ML. Of course, there are people in AI that do research on different sub-topics, but this happens in all fields. For example, not all physicists study particle physics. Some of them study or focus on theoretical physics.b2A1I9n14a1r18y25_g7l12o15b2e5The Data Science field may have coalesced with the advent of strong-narrow ML, but it existed in prior form in the general field of analytics.  Data Mining was an exceptionally hot field for about a decade, prior to the ML revolution, per the rise of the internet and social media.  But this is tangential to the question here posed.b2A1I9n14a1r18y25_g7l12o15b2e5I agree with this answer. I think expanding to allow hardware-related AI questions, at this point, would make things unwieldy. Hardware-related questions are a different ballgame, and, at this point, it's probably better to remain focused.


















We had done a consensus-based edit last year: https://ai.meta.stackexchange.com/questions/1430/what-should-the-ai-se-site-description-beWhat should the AI.SE Site Description be?.
(Essentially, a bunch of active users contributed to the thread, and then the edits were made by the active mods.  Although I was hoping for more people to participate, we had to go with the input and consensus we had at the time.)
I do think this is something that should be revisited at regular intervals, especially since we are not fully graduated as a stack, and more flexibility in terms of modifying our scope.  ("https://www.masslive.com/patriots/2017/11/the_2017_new_england_patriots.htmlBend don't break" is my motto!)
When we revisit again, I strongly think we should take a cue from the Data Science help page b/c they provide good advice about topic overlap between stacks: https://datascience.stackexchange.com/help/on-topichttps://datascience.stackexchange.com/help/on-topic
I also personally think we should expand our scope to reference

Journalism (coverage of AI in the press per public perception and fact checking)

History of AI

Mythology of AI (portrayals of AI in popular media which informs public perception)
and hold a referendum on other topics that contributors have chosen to answer over here, per the DS recommendation to "ask on the stack with the most users."


b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I was not talking about the main description of the site. I was talking about clarifying the [on-topic](https://ai.stackexchange.com/help/on-topic) and [off-topic](https://ai.stackexchange.com/help/dont-ask) pages. In my opinion, the on-topic page should list the specific topics, which I list in [my post](https://ai.meta.stackexchange.com/q/1506/2444), which received 7 upvotes, which means that there are a lot of people that agree with the content of that post.b2A1I9n14a1r18y25_g7l12o15b2e5I agree with you that the history of AI should be on-topic, so it should be listed on the on-topic page. I think that journalism and mythology of AI can also be on-topic here, but we must be very careful: we should only accept questions that can be answered based on facts. Every question that will lead to opinions and is not philosophical should not be allowed. So, for example, a question like "Is it true that this model really obtained 95% percent accuracy on this task, as stated in this article?" or "What are the aspects of this AI portrayed in film X can currently be implemented?" are fine.


















What topics can I ask about here?

If you have a question about theoretical, philosophical, social, historical, and certain developmental and academic aspects of artificial intelligence, then you are probably in the right place to ask your question!

Below you can find a non-exhaustive list of specific topics that are considered on-topic here. Next to each topic, you have links to other stacks where the corresponding topics may also be on-topic.

Specific topics

You can ask a question about the theoretical aspects of the following sub-fields of artificial intelligence. 


Artificial general intelligence
Affective computing
Swarm intelligence
Evolutionary algorithms (https://stats.stackexchange.com/help/on-topic1, https://stackoverflow.com/help/on-topic4, https://cs.stackexchange.com/help/on-topic6)
Machine learning (https://stats.stackexchange.com/help/on-topic1, https://datascience.stackexchange.com/help/on-topic2, https://stackoverflow.com/help/on-topic4, https://cs.stackexchange.com/help/on-topic6)
Computational learning theory (https://stats.stackexchange.com/help/on-topic1, https://cs.stackexchange.com/help/on-topic6, https://cstheory.stackexchange.com/help/on-topic7)
Natural language processing and understanding (https://cs.stackexchange.com/help/on-topic6)
Computer vision (https://stats.stackexchange.com/help/on-topic1, https://datascience.stackexchange.com/help/on-topic2, https://stackoverflow.com/help/on-topic4, https://cs.stackexchange.com/help/on-topic6, https://dsp.stackexchange.com/help/on-topic10)
Knowledge representation and reasoning  (https://cs.stackexchange.com/help/on-topic6)
Robotics (https://robotics.stackexchange.com/help/on-topic5)
Planning (https://cs.stackexchange.com/help/on-topic6)


The following philosophical (or theoretical) aspects are on-topic.


Intelligence definitions and testing
Superintelligence
Emotional intelligence
Artificial consciousness


The following social aspects are on-topic.


Ethics (https://philosophy.stackexchange.com/help/on-topic3)
Explainable artificial intelligence
Applications


The following historical aspects are on-topic.


Timeline (e.g. AI winters)
Progress


You can also ask questions about


Terminology and notation
Proofs (https://math.stackexchange.com/help/on-topic8)
Clarifications of certain excerpts from papers, books, etc.
Reference requests (e.g. "Which paper introduced vanilla RNNs?")


Notes


Before posting, please, look around to see if your question has been asked before. Your question could be closed as a duplicate of another, if you don't do it.
You should put some effort into writing your question. If your question is unclear, it could be flagged as unclear, your question could be closed, and you will not receive help. Furthermore, we expect users to do a little bit of research before asking a question.
Ask specific questions! If your question has potentially many answers, your question may be closed as too broad.
https://meta.stackexchange.com/a/39224/287113You should try asking one question or address a single problem per post, unless the questions are really very related to each other. If you ask multiple questions per post, your post may be closed as too broad.
Ideally, we are looking for questions that can be answered objectively. More precisely, do not ask for advice (such as career path recommendation or a tool, which are, in general, off-topic here anyway) but for facts (including references) and arguments. If you have a philosophical question, you should demand a logical, rational and reasonable answer that argues the philosophical perspective (and not just an opinion).
Implementation questions in the context of understanding the theoretical topics are on-topic. For example, if a theoretical topic is described by a certain mathematical formula and you want to understand how a certain implementation is related to the formula, then your question is on-topic. As a rule of thumb, if you can describe your problem without the source code and if you think that a solution to your problem can be given without the source code, then your question is on-topic. The source code can be provided to further clarify the issue, but you should provide a https://stackoverflow.com/help/minimal-reproducible-exampleMinimal, Reproducible Example.
General programming questions are off-topic. For example, if you have a question like "Why am I getting this exception?", "How do I merge two Pandas' data frames?" or "How can I use this Keras API?", then your question is off-topic (and you should probably ask it on https://stackoverflow.com/help/on-topicStack Overflow).
It's also OK to ask and answer your own question.


Overlapping Stacks

If your question is not specifically on-topic for Artificial Intelligence Stack Exchange, it may be on-topic for another Stack Exchange site, such as 


https://stats.stackexchange.com/help/on-topicCross Validated
https://datascience.stackexchange.com/help/on-topicData Science
https://philosophy.stackexchange.com/help/on-topicPhilosophy
https://stackoverflow.com/help/on-topicStack Overflow
https://robotics.stackexchange.com/help/on-topicRobotics
https://cs.stackexchange.com/help/on-topicComputer Science
https://cstheory.stackexchange.com/help/on-topicTheoretical Computer Science
https://math.stackexchange.com/help/on-topicMathematics
https://psychology.stackexchange.com/Psychology & Neuroscience
https://dsp.stackexchange.com/help/on-topicSignal Processing


Certain questions are probably on-topic on multiple of these websites. For example, machine learning questions are also on-topic at https://stats.stackexchange.com/help/on-topicCross Validated, which is more statistics-oriented. There are probably other overlapping sites.

If no site currently exists that will accept your question, you may commit to or propose a new site at https://area51.stackexchange.comArea 51, the place where new Stack Exchange communities are democratically created.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Right now, it may be a little bit too long. We may need to sacrifice certain parts to shorten it, but I prefer a long but clearer on-topic page rather than a short but ambiguous one. Certain parts of this answer could also be used to write a new off-topic page. I am NOT sure whether hardware, software, and mythology should be on-topic. Maybe we are also missing academic aspects. Feel free to propose edits to this answer.b2A1I9n14a1r18y25_g7l12o15b2e5May I suggest: "Programming questions that are not specifically about AI concepts are off topic" rather than all such questions? For example, asking about how an AI algorithm has been translated in to source code in a particular package _is_ a question that requires deep understanding of the AI algorithm, and should (IMO) be on topic here. I think we hamstring ourselves if we declare the language that AI is actually realized in to be off topic. We need to be a technical place, or we'll descend into a futurist board without any foundation in the subject.b2A1I9n14a1r18y25_g7l12o15b2e5@JohnDoucette I think you should read the whole point. I am also saying "_However, if you're looking for a clarification of the implementation of a certain AI concept, then your question may be on-topic. For example, if a theoretical topic is described by a certain mathematical formula and you want to understand the implementation of this formula, then your question may be on-topic._". I am saying that, IN GENERAL, programming questions are off-topic, in the sense that we are not a site where people should be looking for source code or solve mere programming issues (like bugs and exceptions).b2A1I9n14a1r18y25_g7l12o15b2e5I did read the whole point, although I think I did not convey my meaning clearly. I think that the current wording is too strong, and too restrictive, and that leading with "programming questions are off-topic", in bold, suggests that it is the _programming_ part that is off topic, rather than the "not about AI part" that is off topic. I would be happier with "programming questions about AI algorithms are on-topic, but questions about programming languages in general, specific packages, or data manipulation, belong on DS.SE".b2A1I9n14a1r18y25_g7l12o15b2e5Actually, reading further, I would be pretty upset if we adopted this definition of on-topic. This is way to prescriptive. The list of acceptable "approaches" and "theoretical" topics seems arbitrary to me, and much more restrictive than I would like. I'd be much happier to keep the existing wording.b2A1I9n14a1r18y25_g7l12o15b2e5@JohnDoucette Did you know that, in theory, all programming questions are off-topic here? This site would probably not even exist if the premise was to allow also programming questions. Please, see [https://ai.meta.stackexchange.com/a/1144/2444](https://ai.meta.stackexchange.com/a/1144/2444) by a super-moderator. I am already allowing certain implementation questions because otherwise some users are unhappy.b2A1I9n14a1r18y25_g7l12o15b2e5I think our disagreement may stem from a misunderstanding of the difference between Science and Technology. Computer Science includes programming, but is not _about_ programming. AI likewise includes programming, but is not _about_ programming. In contrast, Data Science is about programming, specifically about programming that uses techniques developed in AI. The answer you link to does _not_ say that programming questions are off topic. It says that implementation and tools questions are off topic. They are, and should be. The issue is that programming =/= implementation & tools.b2A1I9n14a1r18y25_g7l12o15b2e5@JohnDoucette "Computer Science includes programming, but is not about programming". Well, this makes no sense at all. You want to say that computer science is about algorithms and data structures and not about specific implementations necessarily. Actually, I think that CS is also about programming and definitely about programming languages, which is just a sub-field of theory of computation and compilers, etc.b2A1I9n14a1r18y25_g7l12o15b2e5As a clearer example, questions involving Math are not off topic just because we have a Math.SE site. The key distinction is questions that use math to describe issues in AI are on topic. Questions that ask things like "What is a derivative" are clearly not. We can, and should, do the same thing for programming questions. The distinction seems very clear (at least to me).b2A1I9n14a1r18y25_g7l12o15b2e5No, CS is not about programming. It includes programming. It _is_ about specific implementations, which use programming, but questions like "what does it mean when my program won't compile?" are not really CS questions. They are programming questions. I think this is a widely held view. Programming language design is part of CS, but that is not the same as programming (the action of programming).b2A1I9n14a1r18y25_g7l12o15b2e5The new text is something I'm a lot happier with. I would actually also be fine explicitly saying something like "questions about how to use specific machine learning libraries or tools to solve problems are probably off topic, and should be asked on DataScience.SE instead". I think that might help to reduce the noise a bit.b2A1I9n14a1r18y25_g7l12o15b2e5Just looking at this but I like this proposal!!!  (The wide range of topics all but ensure we'll continue to grow and always have sufficient questions, but, b/c it's passed through your rigorous filter, nothing is out-of-scope.b2A1I9n14a1r18y25_g7l12o15b2e5@DukeZhou I tried to accommodate also certain implementation-related questions, which some users think are on-topic, even though I wasn't sure. However, I think I find a good comprise in my description above. I've also included "Hardware or software", but provided that people ask for **facts** (rather than suggestions, recommendations or opinions). I tried to emphasize this point in the notes. We should really demand users to ask for facts rather than recommendations.b2A1I9n14a1r18y25_g7l12o15b2e5Under History I might suggest adding "milestones" and expanding the description of "timeline" to include "important events, discoveries, implementations, AI winters, etc."b2A1I9n14a1r18y25_g7l12o15b2e5I like that implementation compromise.  (My sense is we have to deal with the naive perception of what the scope of the stack is on an on-going basis, and should dismiss that as we're still in Beta.  Unifying those tensions via compromise is optimal.b2A1I9n14a1r18y25_g7l12o15b2e5@DukeZhou I think that progress includes also milestones. Actually, I used to have AI winters under that section, but I removed it for simplicity (given that this possible on-topic page will already be relatively long). I think that users can understand well enough what "history" means. Anyway, we can be more specific. This won't hurt!b2A1I9n14a1r18y25_g7l12o15b2e5On hardware & software evaluation I fully agree--that was my intent in creating the hardware tag.  I suspect we'll still have many answers that are merely recommendations, but that's not going to kill us.b2A1I9n14a1r18y25_g7l12o15b2e5@DukeZhou What's really missing is a description of the academic topics that are on-topic. Any ideas?b2A1I9n14a1r18y25_g7l12o15b2e5@DukeZhou Regarding the recommendation questions, we should really ask users to ask for facts. I think we should really be strict, in this case, to improve the quality of the website. I think questions can be formulated in such a way. If the users do not decide to reformulate them in terms of facts, then we should close them as primarily opinion-based, in my opinion. For example, if they ask a question like "Why is Python used in AI" rather than "What are the possible advantages of Python for AI development?" (or something like that).b2A1I9n14a1r18y25_g7l12o15b2e5Academics is a big one--let me think about it.  (We should probably ping John Doucette and Dennis Soemers on that.)b2A1I9n14a1r18y25_g7l12o15b2e5re: hardware/software evaluation.  Absolutely let's require that of the OP asking the question.  (My comment was that many answers may still be recommendations, but the OP, even if they are seeking recommendations, can still formulate the question in the manner you suggest.)b2A1I9n14a1r18y25_g7l12o15b2e5@DukeZhou I've changed the order of the "overlapping sites". Clearly, CrossValidated, Data Science, Philosophy, Robotics, Computer Science and Stack Overflow and the most similar stacks to ours. Moreover, I am not sure if it is a good idea to have such a long list. For example, I think that quantum computing, software engineering, and computational science are only vaguely related to this stack. I've added stacks like software recommendations because we receive a lot of those questions. Anyway, this long list should not harm anyone.


















I adjusted https://ai.meta.stackexchange.com/a/1616/2444@nbro's answer to remove the parts I thought were too restrictive. AI is a broad field, and the whitelist of "on-topic" areas omits a huge number of topics which are certainly within AI (consider, for contrast, https://aaai.org/Conferences/AAAI-19/aaai19keywords/the topics that are present at AAAI this year alone, all of which are active areas of research). I think that the entry under the "What topics can I ask about here?" is specific enough. If we want to use a list of valid topics, we should formulate it by starting with actual active areas of research for the field, perhaps by amalgamating the keywords and topics that are present at AAAI, NIPS, UAI, IJCAI, AAMAS, CEC, and other major conferences. I suspect that's a lot more work than it's worth however.

I also adjusted the wording of the programming portion to better reflect the idea that programming questions are fundamentally on-topic here, as long as they are about AI algorithms or implementations, and not applications. I think that without this, the stack is going to lack a connection to academic AI, and will descend into a sort of futurism/singularity board. We want to encourage more programming related content, not less, but only of the kind that actually relates to AI.

What topics can I ask about here?

If you have a question about theoretical, philosophical, historical, social and algorithmic or academic aspects of AI, then you are probably in the right place to ask your question! 

Notes


Before posting, please, look around to see if your question has been asked before. Your question could be closed as a duplicate of another, if you don't do it.
You should put some effort into writing your question. If your question is unclear, it could be flagged as unclear, your question could be closed, and you will not receive help. Furthermore, we expect users to do a little bit of research before asking a question.
Ask specific questions! If your question has potentially many answers, your question may be closed as too broad.
https://meta.stackexchange.com/a/39224/287113You should try asking one question per post, unless the questions are really very related to each other. If you ask multiple questions per post, your post may be closed as too broad.
Ideally, we are looking for questions that can be answered objectively. More precisely, do not ask for advice (such as career path recommendation or a preferred tool, which are, in general, off-topic here anyway) but for facts (including references) and arguments. If you have a philosophical question, you should demand a logical, rational and reasonable answer that argues the philosophical perspective (and not just an opinion).
It's also OK to ask and answer your own question.
Programming questions about the implementation of AI algorithms, or the source code of implementations of those algorithms, are on-topic. Programming questions about applying AI tools to specific problems are off-topic, and probably belong on DataScience.SE, or the main StackOverflow site. If you're looking for a clarification of the implementation of a certain AI concept, then your question is on-topic. For example, if a theoretical topic is described by a certain mathematical formula and you want to understand the implementation of this formula, then your question is on-topic. However, if you have a question like "Why am I getting this exception?", "How do I merge two Pandas' data frames?", or "How can I use Tensorflow to train a neural network to recognize cats?" then your question is off-topic (and you should probably ask it on https://stackoverflow.com/help/on-topicStack Overflow).


Similar websites

If your question is not on-topic for Artificial Intelligence Stack Exchange, it may be on-topic for another Stack Exchange site, such as 


https://datascience.stackexchange.com/help/on-topicData Science
https://stats.stackexchange.com/help/on-topicCross Validated
https://stackoverflow.com/help/on-topicStack Overflow
https://robotics.stackexchange.com/help/on-topicRobotics
https://cs.stackexchange.com/help/on-topicComputer Science
https://philosophy.stackexchange.com/help/on-topicPhilosophy


Certain questions are probably on-topic on multiple of these websites. For example, machine learning questions are also on-topic at https://stats.stackexchange.com/help/on-topicCross Validated, which is more statistics-oriented.

If no site currently exists that will accept your question, you may commit to or propose a new site at https://area51.stackexchange.comArea 51, the place where new Stack Exchange communities are democratically created.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5How is this new version better than the current one? The point of my answer is that we should be more specific and not ambiguous, to avoid allowing everything on this site. I'm not saying that all topics listed in my answer are exhaustive, but I should have emphasized that those are the main topics. Which main topics do you think are really missing from my answer?b2A1I9n14a1r18y25_g7l12o15b2e5@nbro I'm not even really sure the listed topics are the main topics. They seem to me to be an odd cross section of AI, and not very reflective of the field's organization as I understand it. I do agree that if we portrayed a set of topics as the _main_ topics of the site (and not the only ones), that would be okay though. I'm quite concerned about the idea of white-listing topics, but I like the idea of suggesting some guidelines.b2A1I9n14a1r18y25_g7l12o15b2e5Feel free to suggest a better list of main topics. In fact, I think that my listings are not very well organized and complete, and I will probably improve them.b2A1I9n14a1r18y25_g7l12o15b2e5"Programming questions about applying AI tools to specific problems are off-topic", I mean, every implementation exists to solve a certain problem, so I don't really get this point. Furthermore, with "Programming questions about the implementation of AI algorithms, or the source code of implementations of those algorithms, are on-topic", you're basically allowing every programming question that is related to AI on-topic here, which contradicts the point above, IMHO. Someone could ask a question without mentioning that that implementation is to be applied to a (real-world) problem.b2A1I9n14a1r18y25_g7l12o15b2e5@nbro It seems to me like you are not following the distinction between implementation of an algorithm, and application of an algorithm. Apologies if I am mistaken. In the case of neural networks, for example, an AI algorithm might be back propagation. The algorithm itself is clearly part of AI, and questions about how it works would clearly be on topic here. Similarly, the _implementation_ of the algorithm (literally, the translation of that algorithm into source code) is something I think should be on topic here, because understanding that implementation _requires_  ... continued...b2A1I9n14a1r18y25_g7l12o15b2e5requires understanding the algorithm. In contrast, the _application_ of that algorithm (myNN.backprop()) is _not_ on topic. It's likely to be an API function provided in some standard toolkit. It's clearly something for DS.SE, and not for us. You don't need to know about the algorithm to answer it, you need to know about the tool.b2A1I9n14a1r18y25_g7l12o15b2e5You're just shifting the problem to the level of libraries and tools that are allowed to use in the implementation of an algorithm.b2A1I9n14a1r18y25_g7l12o15b2e5@nbro I'm not sure I see the problem here. Most AI practitioners do not develop new algorithms. AI researchers (scientists, not technologists) develop new algorithms. DS.SE is meant for practitioners. These people use existing algorithms to solve problems. Tools and libraries used to implement a new algorithm are usually quite different from tools that apply existing algorithms, and indeed, many algorithms do not use specialized tools or libraries, just generic programming language constructs. I think it should be on-topic to ask questions about these.b2A1I9n14a1r18y25_g7l12o15b2e5@nbro In fact, maybe that's a good distinction. Perhaps you would find it acceptable to say that it is on-topic to ask questions about the generic source-code implementing AI algorithms, but that any question involving using AI-specific libraries is off topic? So translating algorithmic pseudo-code into Python, or asking about the internals of a library written in C, are on-topic, but asking about the TensorFlow API belongs in DS.SE.b2A1I9n14a1r18y25_g7l12o15b2e5To make it clear, _personally_, I am not against any type of programming question, even the ones that involve the application of implementations of AI algorithms and models to real-world problems. However, originally, this site was meant to cover only the conceptual, philosophical and social aspects of AI, _AFAIK_. Nowadays, everything can be asked here. The distinction you're making is not a good one, in my opinion, because nowadays almost everyone (even researchers) uses a library (like Keras) to implement any AI model.b2A1I9n14a1r18y25_g7l12o15b2e5In my answer, I am deliberately now allowing all types of AI programming or implementation questions. I am only allowing those programming questions that are needed to fully understand the concepts. At least, I tried to do describe this with an example: "_For example, if a theoretical topic is described by a certain mathematical formula and you want to understand the implementation of this formula, then your question is on-topic._".b2A1I9n14a1r18y25_g7l12o15b2e5@nbro Thanks for accommodating, I'll take a look. I do think that you are right _about deep learning research_. I suspect we're going to have to punt a lot of that over to DS.SE, because it is largely library based, and the choice of library makes it a tools-specific question very quickly. OTOH, deep learning is really just a small (if publicly visible) chunk of AI research. I am an AI researcher, and most of the algorithms I have implemented have used off-the-shelf generic tools, with only a sprinkling of specialized libraries. I just don't work in deep learning.



















Does it really make sense to have all these separate websites (especially, CrossValidated, Data Science and ours), only because of these small differences

No, it doesn't make any sense, because whatever people are saying on meta, in practice if you look at the questions posted on AI.SE, over 90% of them are on-topic on CrossValidated and Data Science. This creates plenty of crossnetwork question duplicates, which personally kills my motivation to participate.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I agree with you. But how should we solve this duplication problem?b2A1I9n14a1r18y25_g7l12o15b2e5@nbro I can think of  two solutions: 1) Merge into 1 Stack Exchange website. 2) implement this proposed feature: [Build and strengthen the Stack Exchange community with “crossover questions” between sites](https://meta.stackexchange.com/q/199989/178179)


















My sense is that answer that provide a religious perspective can be on-topic for certain issues related to social or philosophical subjects, but do need to be well supported, and ideally should be well referenced.  
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5But can we take a religious text as a reference?b2A1I9n14a1r18y25_g7l12o15b2e5@DuttaA where relevant, absolutely.  But my assumption is that this is an extremely limited case.  (For instance I might compare the superrational strategy in game theory to the golden rule, and reference the Mahābhārata and Old Testament.)


















Here's a non-exhaustive list of my favorite questions and answers, which does not mean they are perfect or cannot be improved.
Questions

https://ai.stackexchange.com/q/7416/2444Can neural networks be used to prove conjectures?

Questions to which I gave an answer

https://ai.stackexchange.com/q/13261/2444Why do we need common sense in AI?
https://ai.stackexchange.com/q/13289/2444Are neural networks prone to catastrophic forgetting?
https://ai.stackexchange.com/q/12971/2444What sort of mathematical problems are there in AI that people are working on?
https://ai.stackexchange.com/q/145/2444What is the relevance of AIXI on current artificial intelligence research?
https://ai.stackexchange.com/q/17044/2444Why is dropout favoured compared to reducing the number of units in hidden layers?
https://ai.stackexchange.com/q/17670/2444How can supervised learning be viewed as a conditional probability of the labels given the inputs?

My questions

https://ai.stackexchange.com/q/11679/2444Why doesn't Q-learning converge when using function approximation?
https://ai.stackexchange.com/q/27830/2444Why is the equation $\mathbb{E} \left[ (Y - \hat{Y})^2 \right] = \left(f(X) - \hat{f}(X) \right)^2 + \operatorname{Var} (\epsilon)$ true?
https://ai.stackexchange.com/q/27854/2444Why was the VC dimension not defined for all configurations of $d$ points?
https://ai.stackexchange.com/q/24375/2444Why does a negative reward for every step really encourage the agent to reach the goal as quickly as possible?

Answers

https://ai.stackexchange.com/a/11133/2444What is the Bellman operator in reinforcement learning? (with mathematical details)
https://ai.stackexchange.com/a/17328/2444Why is a softmax used rather than dividing each activation by the sum? (with mathematical details)
https://ai.stackexchange.com/a/14247/2444Why do we need explainable AI?

My answers

https://ai.stackexchange.com/a/28566/2444How can we find the value function by solving a system of linear equations? (with mathematical details; topic: RL)
https://ai.stackexchange.com/a/17881/2444How to estimate the capacity of a neural network? (with mathematical details; topic: learning theory)
https://ai.stackexchange.com/a/10818/2444What is the difference between First-Visit Monte-Carlo and Every-Visit Monte-Carlo Policy Evaluation? (with mathematical details; topic: RL)
https://ai.stackexchange.com/a/8909/2444How is iterative deepening A* better than A*? (with mathematical details; topic: search)
https://ai.stackexchange.com/a/27831/2444Why is the equation $\mathbb{E} \left[ (Y - \hat{Y})^2 \right] = \left(f(X) - \hat{f}(X) \right)^2 + \operatorname{Var} (\epsilon)$ true? (with mathematical details; topic: ML)
https://ai.stackexchange.com/a/22000/2444Do convolutional neural networks perform convolution or cross-correlation? (with mathematical details; topic: CNNs)
https://ai.stackexchange.com/a/10377/2444What is the relevance of AIXI on current artificial intelligence research? (topic: AGI/AIXI)
https://ai.stackexchange.com/a/13293/2444Are neural networks prone to catastrophic forgetting? (topic: neural networks)
https://ai.stackexchange.com/a/10624/2444What is self-supervised learning in machine learning? (topic: ML)
https://ai.stackexchange.com/a/11387/2444What is artificial intelligence?  (topic: AI field)

Of course, I am biased towards questions and answers where I am involved, but this does not mean that there aren't many other good questions and answers on this site.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Thanks for doing it!


















It's New Year's Day in https://en.wikipedia.org/wiki/Zulu_TimeStack Exchange land...

A distinguishing characteristic of these sites is how they are moderated:


  We designed the Stack Exchange network engine to be mostly self-regulating, in that we amortize the overall moderation cost of the system across thousands of teeny-tiny slices of effort contributed by regular, everyday users.
  -- http://blog.stackoverflow.com/2009/05/a-theory-of-moderation/A Theory of Moderation


While there certainly are https://stackoverflow.blog/2018/11/21/our-theory-of-moderation-re-visited/Moderators here, a significant amount of the moderation is done by ordinary people, using the privileges 
they've earned by virtue of their contributions to the site. Each of you contributes a little bit of time and effort, and together you accomplish much.

As we enter a new year, let's pause and reflect, taking a moment to appreciate the work that we do here together. 
And what could be more festive than a big pile of numbers? 
So here is a breakdown of moderation actions performed on Artificial Intelligence over the past 12 months:

                 Action                  Moderators Community¹
---------------------------------------- ---------- ----------
Users suspended²                                  3          6
Users destroyed³                                  1          0
Users deleted                                     1          0
Users contacted                                   9          0
Tasks reviewed⁴: Suggested Edit queue           300        604
Tasks reviewed⁴: Reopen Vote queue               17         49
Tasks reviewed⁴: Low Quality Posts queue         65         99
Tasks reviewed⁴: Late Answer queue               64        127
Tasks reviewed⁴: First Post queue               666      1,284
Tasks reviewed⁴: Close Votes queue              684        744
Tags merged                                      14          0
Tag synonyms proposed                             9          0
Tag synonyms created                             10          0
Revisions redacted                                1          0
Questions unprotected                             0          2
Questions reopened                               19          0
Questions protected                               1         38
Questions migrated                               47          0
Questions merged                                  2          0
Questions flagged⁵                                2        534
Questions closed                                215         65
Question flags handled⁵                         273        263
Posts unlocked                                    0         11
Posts undeleted                                  10         45
Posts locked                                      1        101
Posts deleted⁶                                  213        899
Posts bumped                                      0        910
Comments undeleted                                9          0
Comments flagged                                  1      1,362
Comments deleted⁷                             1,567      1,116
Comment flags handled                         1,223        140
Answers flagged                                   4        502
Answer flags handled                            384        122
All comments on a post moved to chat              5          0


Footnotes

¹ "Community" here refers both to https://ai.stackexchange.com/usersthe membership of Artificial Intelligence without https://ai.stackexchange.com/users?tab=moderatorsdiamonds next to their names, and to the automated systems otherwise known as https://ai.stackexchange.com/users/-1user #-1.

² The system will suspend users under three circumstances: when a user is recreated after being previously suspended, when a user is recreated after being destroyed for spam or abuse, and when a network-wide suspension is in effect on an account.

³ A "destroyed" user is deleted along with all that they had posted: questions, answers, comments. https://meta.stackexchange.com/questions/88994/what-is-the-difference-between-a-deleted-user-and-a-destroyed-userGenerally used as an expedient way of getting rid of spam.

⁴ This counts every review that was submitted (not skipped) - so the 2 suggested edits reviews needed to approve an edit would count as 2, the goal being to indicate the frequency of moderation actions. This also applies to flags, etc.

⁵ Includes close flags (but not close or reopen votes).

⁶ This ignores numerous deletions that happen automatically in response to some other action.

⁷ This includes comments deleted by their own authors (which also account for some number of handled comment flags).   

Further reading:


Wanna see how these numbers have changed over time? I posted a similar report here last year: https://ai.meta.stackexchange.com/questions/1483/2018-a-year-in-moderation2018: a year in moderation...
You can also check out https://stackexchange.com/search?q=title%3A%222019%3A+a+year+in+moderation%22this report on other sites
Or peruse https://meta.stackexchange.com/questions/341507/2019-a-year-in-closingdetailed information on the number of questions closed and reopened across all sites


Wishing you all a happy new year...
b2A1I9n14a1r18y25_g7l12o15b2e52019: a year in moderationb2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Some metrics (that probably needed to be improved) have improved, such as the number of comments flagged. It would be easier if you could provide an automatic way of visualizing these metrics and their evolution throughout the years.


















Given that the IBM logo disappeared from our website, I suspect that https://ai.meta.stackexchange.com/q/1404/2444IBM no longer sponsors us. Meanwhile, CrossValidated is now sponsored by https://stats.meta.stackexchange.com/q/5833/82135AWS (machine learning). Are we still sponsored by IBM? If not, why not? Anyway, this sponsorship does not seem to have been beneficial to us. We need a more effective way of attracting experts.
b2A1I9n14a1r18y25_g7l12o15b2e5Are we still sponsored by IBM?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5They don't tell me anything, but my guess is the sponsorship expired.


















Yes, https://charcoal-se.org/#whats-smokeySmokeDetector is active on Artificial Intelligence as well, and it's https://meta.stackexchange.com/q/291301/295232automatically flagging posts of which it's 99.75% sure it's spam. Fortunately, Artificial Intelligence https://metasmoke.erwaysoftware.com/sites/dash?utf8=%E2%9C%93&site_id=322&months=12&tab=alldoesn't see as much spam as the rest of the network, and only 117 flags have been cast last year. Most (all?) other bots in that blog post are tuned towards Stack Overflow content and can't be ported directly to Artificial Intelligence, though some of them might be after some adjustments.


  If one decided to create a bot for accelerating moderation by flagging duplicates and off-topic questions, is that specifically allowed in the website? A bot that helps to automatically flag questions and duplicates may help a lot in removing and noticing unwanted posts and answers


Yes, that is allowed, as long as you don't do anything stupid. You need to be reasonably sure the flag accuracy is at least as high as the average human user (which is about 95% IIRC). If you get flag banned because of a bad algorithm, that's your own problem.


  and with a machine learning algorithm one can classify it to a very high degree of accuracy.


Well ... that might surprise you. SmokeDetector relies heavily on old-school regexes. We've tried a few times to classify spam based on machine learning, and we got nowhere near the 95% mark, let alone the 99.75% needed for autoflagging. (That percentage is so high because validated spam flags carry a heavy penalty.) Determining off-topic and duplicate questions looks even more challenging to me, but I hope you can surprise us.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Oh I see. Maybe one can develop a system to simply notify a user if it detected a duplicate question, though not immediately flag it.b2A1I9n14a1r18y25_g7l12o15b2e5Btw thanks very much for your information.b2A1I9n14a1r18y25_g7l12o15b2e5You're welcome. There is a bot ([SOCVFinder](https://stackapps.com/q/6910/34061)) which provides live notifications (via chat) for duplicates on Stack Overflow. Its author is no longer on Stack Exchange; it runs under [this account](https://stackoverflow.com/users/6294609/queen) so you might want to ping PetterFriberg in the SOBotics chatroom.b2A1I9n14a1r18y25_g7l12o15b2e5Oh I see. Thanks very much for your answer. Maybe I will try to design a bot to detect replicates and spams as a fun project. Thanks very much again for your answer m


















When viewing this site (main or meta) in my main browser, there is an empty 'SPONSORED BY' label just under the top bar:

https://i.stack.imgur.com/VzK3w.png
https://i.stack.imgur.com/UIsyY.png

When viewing in another browser, the AWS logo is showing correctly:

https://i.stack.imgur.com/aNhyH.png
b2A1I9n14a1r18y25_g7l12o15b2e5Empty 'SPONSORED BY' label under top bar - AWS logo not shownb2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I can see it is sponsored by AWS machine learning tho..b2A1I9n14a1r18y25_g7l12o15b2e5@ClementHui thanks, it seems browser-related.b2A1I9n14a1r18y25_g7l12o15b2e5Oh I see thanks.b2A1I9n14a1r18y25_g7l12o15b2e5@Glorfindel I am using Chrome and I am not seeing the AWS logo.b2A1I9n14a1r18y25_g7l12o15b2e5Are you using adblocker? I'm using uBlock Origin and it catches the sponsorship logo but not the "Sponsored by"... which is interesting because it doesn't catch the logo on Quantum Computing.b2A1I9n14a1r18y25_g7l12o15b2e5@Catija thanks, that's exactly what's causing this; see the answer below.


















https://ai.meta.stackexchange.com/questions/1636/empty-sponsored-by-label-under-top-bar-aws-logo-not-shown#comment3208_1636Catija's hunch was right: the logo is blocked by uBlock, since it's a link to ad.doubleclick.net.

I would have checked that, if I hadn't seen the AWS logo on https://stats.stackexchange.com/Cross Validated a few weeks ago. But right now it's not showing there either. I guess the ad link is important enough (in terms of revenue, or just part of the sponsorship contract) to keep it, so I'm no longer considering it a https://ai.stackexchange.com/questions/tagged/bugbug.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Yeah, so I talked with the ads team. Apparently AWS wants to track link clicks, which goes through a tool that causes the ad blockers read the image as an ad. Apparently the one on QC doesn't have that, so it doesn't get blocked. :)


















Having a look at different https://stackexchange.com/sites#namesites of Stack Exchage, it feels like Computer Vision page is really missing!

There obviously exists almost relevant pages, such as https://ai.stackexchange.com/AI, https://robotics.stackexchange.com/Robotics, https://dsp.stackexchange.com/Signal Processing, https://computergraphics.stackexchange.com/Computer Graphics and https://stackoverflow.com/stack overflow in which people can ask questions.

Why does not Stack Exchange make one specific page for researchers or anyone with interests in the area of Computer Vision? 

Is there any particular reason or is it more of multidisciplinary subjects according to the founder of Stack Exchange?
b2A1I9n14a1r18y25_g7l12o15b2e5Computer Vision as an Independent site on Stack Exchangeb2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Please, see [https://meta.stackexchange.com/q/344835/287113](https://meta.stackexchange.com/q/344835/287113) meanwhile.



















  Why does not Stack Exchange make one specific page for researchers or anyone with interests in the area of Computer Vision?


Apparently, there was a proposal for a computer vision SE site, but https://stats.meta.stackexchange.com/a/2799/82135the proposal was deleted because of low activity. In general, if there aren't enough users interested in the topic and enough activity, the site will not be created.

Computer vision is clearly an AI topic, so, in general, any theoretical CV question is on-topic here. See https://ai.stackexchange.com/questions/tagged/computer-visionall our CV questions.

Signal Processing SE is also an appropriate site to ask CV questions. In fact, in the past, I've asked some questions there. https://stats.stackexchange.com/tagsStats SE may also be an appropriate site to ask your question.

See also https://stats.meta.stackexchange.com/q/2794/82135Stack Exchange site to ask questions about computer vision?.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5So there’s no possible way to revive that proposal anymore? Maybe there’ll be more activitiesb2A1I9n14a1r18y25_g7l12o15b2e5@FäridAlijani Yes, there's the possibility to create a new proposal. [Here's the site](https://area51.stackexchange.com/) where you can possibly create it.


















I believe that the current description of the site does not highlight certain important aspects of the site (e.g. AI history) and it contains redundant or noisy information. 

In the current description of the site, the topics that I believe are redundant or noisy are


mathematics (theory)
discovery (theory/development), 
design (theory/development), 
practice (development), 
embedded uses (development), 
cognition (theory)
policy (social)
impact  (social)


So, here's my initial new proposal (based on the current first paragraph of the https://ai.stackexchange.com/help/on-topicnew on-topic page).


  Artificial Intelligence Stack Exchange is a question and answer site for people interested in the theoretical (including mathematical), philosophical, social, historical, and certain developmental and academic aspects of artificial intelligence.


Maybe we could also explicitly mention "research"?
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I might still include math explicitly.  *(i.e. people new to the field might not recognize that math in this context generally = theory.)*  New paragraph is much better.


















ai.meta.stackexchange.com is (correctly) showing that I have no badges.

It suggests "Take the Tour and earn your first badge".

I do that, and it says I've been awarded a badge.

But when I go back to the original page, it still says I have no badges and still suggests "Take the Tour and earn your first badge".

Is something broken here?

UPDATE:

As far as I know, the "meta" sites don't normally even offer a tour, much less keep insisting on it.

But now that I've submitted this question, the original problem has of course gone away and I've been awarded a "student" badge.

However, unlike all the other sites, I haven't been automatically awarded a "biographer" badge.  (E.g. expatriots.meta or travel.meta)

I really don't care about the badges themselves, but something unusual is happening on this site.
b2A1I9n14a1r18y25_g7l12o15b2e5Stuck in "Take the Tour and earn your first badge"b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Hi and welcome to AI SE! I am not sure and I would need to check this, but you probably need to take some concrete action to get your first badge. By "concrete action" I mean an action such as asking a question, answering a question, or voting.b2A1I9n14a1r18y25_g7l12o15b2e5@RayButterworth I noticed something similar myself, not only on this site but on other ones, where this issue went away later, including as I recall in cases where I did nothing. I suspect the issue is most likely due to caching which is used in many places on the SE sites due to the relatively large number of queries which are executed and, especially on sites like StackOverflow & other larger ones (e.g., mathematics), the many people who are simultaneously using the sites.


















The "sponsored by" is gone, for now, because the site sponsorship is currently paused.

While we don't have a set date yet for the sponsorship to return, current conversations with AWS point to relaunching in early Q3, though the date isn't locked in yet.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Does the sponsorship provide any intellectual contribution or is it just monetary contribution alone?b2A1I9n14a1r18y25_g7l12o15b2e5@DuttaA while we're certainly open for people from those companies participating and would encourage it, that's not mandatorily part of the deal. By contract, site sponsorships are monetary contributions.b2A1I9n14a1r18y25_g7l12o15b2e5How much money does a company need to provide, to be a sponsor?



















  Should such questions remain open?


Yes. The CR argument is probably the most famous argument in the philosophy of artificial intelligence. It's about the meaning of intelligence, imitation and understanding. The typical bad answer to this question is one where someone just says "yes" or "no" without providing a rational explanation or considering previous debates, discussions, and philosophical positions on the topic.

In general, philosophical questions related to AI are on-topic on our site, as https://ai.stackexchange.com/help/on-topicour on-topic page explicitly says. 

Questions that are considered opinion-based are e.g.


Which book do you think is the best (for task X)?
Do you think that AI will take over the world?


All questions that ask explicitly for opinions (e.g. that start like "What do you think..."?), rather than for an objective answer, are opinion-based, and you should flag them to be closed as such. 

Sometimes, certain opinion-based questions can be rephrased. For example, the question "What is the best tool to solve task X given constraints Y?" could be rephrased as "What are some available tools to solve...?", which would be more acceptable. 

The question above "Do you think that AI will take over the world?" could also be "saved", if rephrased differently. For example, we could ask instead 


  What are the existing arguments of real philosophers about the topic 'AI takeover'? Why do they think it will happen or not?


These questions can lead to more useful answers, where users will need to refer to existing philosophical work rather than providing their own opinion based on their possibly wrong intuition. (Btw, I don't think this question has already been asked, so feel free to ask it!)

As a rule of thumb, avoid term/expressions such as


Do you think...?
What is the best...? 
Do you like...?

b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5The tone of the question is a little bit off and it seems as if OP is asking for a definite objective answer.b2A1I9n14a1r18y25_g7l12o15b2e5@DuttaA It's true that it could have been phrased differently. Maybe next time we should try to rephrase these questions so that they can be answered more objectively.


















These tags seem to be effectively interchangeable for all questions I've seen them used in. Should they be merged?

(Note: I agree https://ai.stackexchange.com/questions/tagged/graph-neural-networksgraph-neural-networks should remain distinct.)
b2A1I9n14a1r18y25_g7l12o15b2e5Merge [graphs] and [graph-theory] tagsb2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Maybe you could list the posts tagged with "graphs" that could be merged with "graph theory" (or maybe the ones where merging would not make sense).


















Can we ask for an intuitive explanation of models, algorithms, and topics related to Artificial Intelligence and Deep Learning?
b2A1I9n14a1r18y25_g7l12o15b2e5Can we ask for an intuitive explanation of models, algorithms and topics?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Some of us definitely learn and understand better if we have a non-rigorous intuitive view of a concept.  I remember when we studied Green's Theorem in calculus.  I could follow the mathematical proof, and accepted the result, but never felt that I actually understood it.  Later, when they introduced Green's Theorem in physics, it was immediately obvious *why* it had to be true (e.g. with a light-bulb in a room, the same total amount of light reaches the surface of the room, regardless of the size or shape of the room.)


















From Sutton and Barto's book Reinforcement Learning (Adaptive Computation and Machine Learning series), the following definition is given for Q-Learning :
https://i.stack.imgur.com/6rEPb.png
I', planning to ask a question in combining the above algorithm with policy gradient learning but I'm struggling to format it correctly with MathJax. Here is what I have so far which looks awful in comparison to above algorithm:
$$
Algorithm \hspace{1mm} parameters: step size \hspace{1mm} \alpha \in (0 , 1] , \epsilon > 0 \\
Initialize \hspace{1mm} Q \hspace{1mm} ( s, a ), \  \forall s \in S^+ , a \in A ( s ), arbitrarily \hspace{1mm} except \hspace{1mm} that \hspace{1mm} Q ( terminal , . ) = 0 \\
Loop \hspace{1mm} for \hspace{1mm} each \hspace{1mm} step \hspace{1mm} of \hspace{1mm} episode: \\
Choose \hspace{1mm} A \hspace{1mm} from \hspace{1mm} S \hspace{1mm} using  \hspace{1mm} some \hspace{1mm} policy  \hspace{1mm} derived  \hspace{1mm} from  \hspace{1mm} Q (eg  \hspace{1mm} \epsilon  \hspace{1mm} greedy)
$$
Can some pointers in writing out RL algorithms with MathJax be shared ?  Ideally can my mathjax code be amended such that it renders the same output as above Q-Learning algorithm (in image) ?
Is mathjax being used in this site or some other math notation rendering library ?
b2A1I9n14a1r18y25_g7l12o15b2e5Writing algorithm formulas using MathJaxb2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5can you not just put the image in your question above and refer to the lines needed for your question?b2A1I9n14a1r18y25_g7l12o15b2e5@DavidIreland yes I could but I thought it would be more clear to have the complete algorithm with the lines I've changed instead of pointing out each line I'm changing.b2A1I9n14a1r18y25_g7l12o15b2e5@blue-sky This question is more appropriate for our Meta. I will migrate it.b2A1I9n14a1r18y25_g7l12o15b2e5[There is a relevant discussion on CS.SE](https://cs.meta.stackexchange.com/questions/1470/how-can-i-format-the-algorithm-better-inside-a-question) I think most of the above figure can be done in Unicode, although that takes additional effort. As far as I'm aware, there hasn't been any more support for algorithm formatting since, so if unicode will not do, then using markdown lists is probably the best we can do.


















Don't use MathJax unless you need to. Here are some hacks to do formatting like this:

Blockquotes (>). Useful for marking out a block of text as different, without doing much additional formatting to them.

Inline MathJax. You can enclose MathJax in $ to make it render in line (ie. not on a seperate, centered line. eg. $\alpha$ gives $\alpha$

Indenting. Number of ways to achieve this. $\quad$ (and similar) might be most familiar to you, but piles of unbreakable spaces (&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;) also works as a hack-y way to do this.

Linebreaks. You can do linebreaks by having multiple spaces at the end of a line, or using the html tag <br/>


To see it in action with your specific example:

Algorithm parameters: step size  $\alpha \in (0 , 1] , \epsilon > 0$
Initialize  $Q  ( s, a ), \  \forall s \in S^+ , a \in A ( s ),$ arbitrarily except that $Q ( terminal , \cdot ) = 0$
Loop for each episode:
$\quad$Initialize $S$
$\quad$Loop  for  each  step  of  episode:
$\qquad$Choose  $A$ from $S$ using some policy derived from $Q$ (eg $\epsilon$-greedy)
$\qquad$Take action $A$, observe $R, S'$
$\qquad Q(S,A) \leftarrow Q(S,A) + \alpha[R+\gamma \max_a(S', a) - Q(S, A)]$
$\qquad S \leftarrow S'$
$\quad$ until $S$ is terminal

Which is produced from:
> Algorithm parameters: step size  $\alpha \in (0 , 1] , \epsilon > 0$   
Initialize  $Q  ( s, a ), \  \forall s \in S^+ , a \in A ( s ),$ arbitrarily except that $Q ( terminal , \cdot ) = 0$    
>
> Loop for each episode:  
$\quad$Initialize $S$   
$\quad$Loop  for  each  step  of  episode:    
$\qquad$Choose  $A$ from $S$ using some policy derived from $Q$ (eg $\epsilon$-greedy)   
$\qquad$Take action $A$, observe $R, S'$   
$\qquad Q(S,A) \leftarrow Q(S,A) + \alpha[R+\gamma \max_a(S', a) - Q(S, A)]$   
$\qquad S \leftarrow S'$    
$\quad$ until $S$ is terminal

b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5thanks! also works with StackEdit.io which uses KatEx


















There are lots of questions of persons describing a target and asking how to do it, without any other information. The target is something very generic as "maximize the sales" or "recognize cars". Moreover, usually authors of these questions has none or near than none knowledge on AI and have not done any first try.
Answers can not be specific due to lack of question concretion, usually they contain only the name of the involved AI area. Worst, an usual answer is "yes, use a NN and train it".
Should this kind of question be closed as off-topic ?
Some recent examples:
https://ai.stackexchange.com/questions/24174/how-to-properly-build-a-neural-net-of-a-physics-simulationHow to properly build a neural net of a physics simulation
https://ai.stackexchange.com/questions/24188/distinguishing-customers-from-customer-repsDistinguishing Customers from Customer Reps
it is easy to find more direct ones.
b2A1I9n14a1r18y25_g7l12o15b2e5Should all "how to do (generic target)" questions be closed?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Can you provide an example of such a question/post? (By the way, I did not downvote this post, and, actually, I think that this question/issue is important). This seems to be related to how much information we are expecting our users to provide in their posts and how much research they should do before posting. I have definitely seen many posts where information was missing or the answer was just one line. In those cases, you should vote to close the post as "needs more details" or flag for deletion (in the case of the one-line answer).b2A1I9n14a1r18y25_g7l12o15b2e5Thanks for providing an example. I now have a better idea of what you mean. In that specific post, the user seems to know little about machine learning and is trying to get some advice on how to solve his/her problem. It's true that we can't be specific enough, so an answer will need to be general. We have been having indeed many similar questions. This is probably due to the fact that people (outside of ML community) are trying to use ML without really having a solid knowledge of the topic. This type of question definitely does not improve the quality of our site...b2A1I9n14a1r18y25_g7l12o15b2e5... but the question is: do we also want to help these people? I think that there are more problematic posts (than that specific one) that members of our community still do not care about. For example, this post: https://ai.stackexchange.com/q/24167/2444, which is missing details and can't really be answered properly without making assumptions. This is the type of post that I expect the members of our community, including you, to vote to close as "needs or more details", though nobody did it yet.


















I encountered a few times by now that people make formatting errors in their answers. Sometimes, they just set back ticks ("`") incorrectly, which may destroy the formatting of an entire answer or causes at least some other inconveniences, e.g. making links disappear as is the case in https://ai.stackexchange.com/a/25130/37982this post.
All these things are natural to happen occasionally, but the strange thing is that they cannot easily be fixed by the community since edits must alter at least 6 characters of a post to be admissible. Thus, in the case of the aforementioned post for example, I myself could not correct the formatting of the post since a correction would have involved deleting only 2 (instead of 6) "`"-signs.
Since this is not the first time that I encounter situations like this, I was wondering whether it is possible to decrease the minimal number of characters to be changed for an edit to become admissible.
b2A1I9n14a1r18y25_g7l12o15b2e5Minimal number of edits possibly too lowb2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5`\`` is called a back tickb2A1I9n14a1r18y25_g7l12o15b2e5I agree with you. I haven't yet fully researched why there's this limitation, but I don't really think it's necessary. The alternative would be to try to perform other changes (which may not be necessary, though, which makes this limitation unnecessary). Check [this](https://meta.stackexchange.com/q/81520/287113).b2A1I9n14a1r18y25_g7l12o15b2e5@DavidPostill: Thanks, I updated the expression. @ nbro: Thanks for the reference. I see now why this is the case. Still, I don't know whether the intended benefit outweighs the "harm" of that rule. Guess I need to accumulate more reputation to get the problem fixed myself ;)


















Can I ask the questions related to the practices of researches in the field of artificial intelligence?
For example, I am facing an issue in understanding the existing codes in GitHub related to my research. It is due to several reasons including version updates, less documentation, etc., So, I have a genuine question on what other researchers in the domain do for coding. So, can I ask a question like

Do most of the researchers of deep learning go through the existing code and understand it in detail or just use it as a module for their research without complete understanding?

b2A1I9n14a1r18y25_g7l12o15b2e5Is it okay to ask questions related to the practices of researchers in the field?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5We have had some of these questions (such as [this](https://ai.stackexchange.com/q/23983/2444)), i.e. questions related to how AI researchers deal with certain problems, but I don't think we have clearly defined whether these questions are or not on-topic here. However, you're asking about questions that involve the implementation, so I'm not fully sure whether they should be considered on-topic. As long as the question is related to how AI researchers "do research", then I think this would fall into the "research/academia" part of the site, but I'm not sure. I will consult other moderators.



















As we say goodbye to the old year and welcome the new one, we have https://ai.meta.stackexchange.com/search?q=%22year+in+moderation%22+is%3Aquestiona tradition of sharing moderation stats for the past 12 months.
As most of you here are aware, sites on the Stack Exchange network are moderated somewhat differently to other sites on the web:

We designed the Stack Exchange network engine to be mostly self-regulating, in that we amortize the overall moderation cost of the system across thousands of teeny-tiny slices of effort contributed by regular, everyday users.
-- http://blog.stackoverflow.com/2009/05/a-theory-of-moderation/A Theory of Moderation

That doesn't eliminate the need for having https://stackoverflow.blog/2018/11/21/our-theory-of-moderation-re-visited/moderators altogether, but it does mean that the bulk of moderation work is carried out by regular folks. Every bit of time and effort y'all contribute to the site gives you access to more privileges you can use to help in this effort, all of which produce a cumulative effect that makes a big difference.
So as we welcome 2021, and in keeping with tradition, let us look back at what we accomplished as a community... by looking at some https://i.stack.imgur.com/pU1Al.jpgexciting stats. Below is a breakdown of moderation actions performed on Artificial Intelligence over the past 12 months:




Action
Moderators
Community¹




Users suspended²
9
5


Users destroyed³
2
0


Users contacted
12
0


Tasks reviewed⁴: Suggested Edit queue
236
353


Tasks reviewed⁴: Reopen Vote queue
10
61


Tasks reviewed⁴: Low Quality Posts queue
12
95


Tasks reviewed⁴: Late Answer queue
8
207


Tasks reviewed⁴: First Post queue
206
1,831


Tasks reviewed⁴: Close Votes queue
107
485


Tags merged
55
0


Tag synonyms proposed
102
0


Tag synonyms created
102
0


Revisions redacted
1
0


Questions unprotected
1
0


Questions reopened
111
0


Questions protected
27
8


Questions migrated
125
0


Questions merged
7
0


Questions flagged⁵
0
572


Questions closed
795
36


Question flags handled⁵
288
282


Posts unlocked
6
30


Posts undeleted
55
75


Posts locked
14
177


Posts deleted⁶
721
1,094


Posts bumped
0
1,342


Comments undeleted
172
0


Comments flagged
0
182


Comments deleted⁷
4,833
642


Comment flags handled
156
26


Answers flagged
1
224


Answer flags handled
178
46


All comments on a post moved to chat
82
0



Footnotes
¹ "Community" here refers both to https://ai.stackexchange.com/usersthe membership of Artificial Intelligence without https://ai.stackexchange.com/users?tab=moderatorsdiamonds next to their names, and to the automated systems otherwise known as https://ai.stackexchange.com/users/-1user #-1.
² The system will suspend users under three circumstances: when a user is recreated after being previously suspended, when a user is recreated after being destroyed for spam or abuse, and when a network-wide suspension is in effect on an account.
³ A "destroyed" user is deleted along with all that they had posted: questions, answers, comments. https://meta.stackexchange.com/questions/88994/what-is-the-difference-between-a-deleted-user-and-a-destroyed-userGenerally used as an expedient way of getting rid of spam.
⁴ This counts every review that was submitted (not skipped) - so the 2 suggested edits reviews needed to approve an edit would count as 2, the goal being to indicate the frequency of moderation actions. This also applies to flags, etc.
⁵ Includes close flags (but not close or reopen votes).
⁶ This ignores numerous deletions that happen automatically in response to some other action.
⁷ This includes comments deleted by their own authors (which also account for some number of handled comment flags).
Further reading:

Wanna see how these numbers have changed over time? We posted a similar report here last year: https://ai.meta.stackexchange.com/questions/1631/2019-a-year-in-moderation2019: a year in moderation

You can also check out https://stackexchange.com/search?q=title%3A%222020%3A+a+year+in+moderation%22this report on other sites

Or peruse https://meta.stackexchange.com/q/359735/208518detailed information on the number of questions closed and reopened across all sites


A big thank you to https://stackexchange.com/users/620/shog9Shog9 for writing the queries and script to facilitate fetching and posting this data to all the sites in the network, and to https://stackexchange.com/users/459488/brian-nickelBrian for the subsequent work making the whole thing more user friendly.
Wishing everyone a happy 2021!
b2A1I9n14a1r18y25_g7l12o15b2e52020: a year in moderationb2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5season greeting could you address this plz https://ai.meta.stackexchange.com/questions/2835/my-answer-was-deleted-by-a-diamond-moderator-to-gain-votes-and-answer-for-himsel


















After a quick look at the stats, with respect to the last year, I want you to note a few things

moderators have definitely closed more posts. This is probably due to the fact that we started to have a clearer idea of the direction that the site should take.

moderators have deleted a lot more comments than in 2019, and the community fewer comments (which suggests that the community was not that engaged: see note number 7)

there have been a lot more posts deleted (this is probably a good thing because I've been trying to get rid of low-quality posts, which are still around, unfortunately)

moderators have been less involved in the review queue (I have definitely noticed this, although we have more moderators than in 2019!)


In any case, it would be better to have a more sophisticated way of seeing the evolution of these stats over the years.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5What I'm seeing that I love is that the community picked up most of the review tasks.  I remember when the queue was clogged every time I logged in.  Now it's much less stressful.   (Pretty sure I destroyed one of those users, which means they really must of had it coming, and been given every chance to reform;)


















There are many questions on our site that of the form (for example, https://ai.stackexchange.com/q/2787/2444this one)

Which algorithm/model can potentially solve this task X successfully?

This question is a bit problematic, because, unless you already solved the same or a similar problem, the best answer will probably be only an "educated guess" of the algorithm/model that would be appropriate to solve task X. For example, if someone is dealing with images, then convolutional neural networks may be a good first choice, but, who knows, maybe CNNs are not the best solution for this specific task, so this educated "suggestion/recommendation/guess" (which is not necessarily an "opinion") may not actually be appropriate, although, initially, it looks reasonable. So, this type of question is problematic because of what I just said, but it's a recurrent one, and, often, people need some guidance in order to solve a problem.
Assuming that this type of question is on-topic here, should we have the tags

https://ai.stackexchange.com/questions/tagged/algorithm-requestalgorithm-request
https://ai.stackexchange.com/questions/tagged/model-requestmodel-request

for this type of question?
This would allow users to have the list of all such questions in one place, so that they can eventually search for a question that they also have before asking a duplicate one.
Or maybe we should use the existing tag https://ai.stackexchange.com/questions/tagged/reference-requestreference-request for these questions too? I think that references are papers, books or any other source of information that can support something (e.g. a claim, quote, etc.), as the dictionary puts it

reference: the use of a source of information in order to ascertain something:

So, I don't think that algorithms and models are "references", so we shouldn't use that tag for these questions.
This question is related to https://ai.meta.stackexchange.com/q/1695/2444this one.
b2A1I9n14a1r18y25_g7l12o15b2e5Should we have the tags "algorithm-request" and "model-request"?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Yep I think such tags make senseb2A1I9n14a1r18y25_g7l12o15b2e5@DennisSoemers In [this case](https://ai.stackexchange.com/q/26039/2444), which tag would you use? I think that in this case all of these 3 tags would be potentially applicable.b2A1I9n14a1r18y25_g7l12o15b2e5Hrmmm I'd guess `model-request`, if that also covers things like architectures and not just requests for already-trained models with their trained parameters. Otherwise... `algorithm-request`?b2A1I9n14a1r18y25_g7l12o15b2e5@DennisSoemers Yes, I guess model-request, but sometimes it's not very clear, that's why I was wondering about your take on this one.


















Just a note that Stack Overflow is looking to give away their closed questions on theoretical aspects of AI/ML to Cross Validated:

https://meta.stackoverflow.com/questions/404799/lets-gift-wrap-our-good-machine-learning-theory-questions-for-cross-validatedLet's gift wrap our (good) Machine Learning theory questions for Cross Validated (SO Meta)
https://stats.meta.stackexchange.com/questions/6066/would-cross-validated-want-machine-learning-theory-questions-that-are-no-longerWould Cross Validated want Machine Learning Theory questions that are no longer on-topic for Stack Overflow? (CV Meta)

I guess that AI SE would be also interested in hosting some of these questions, hence this post here.
I was not at all involved (in fact I have argued in SO Meta that we should keep them there, but I am clearly with the minority), but to the best of my knowledge, no other relevant SE site (namely AI and Data Science) has been asked if they would be possibly interested to receive some of them, too.
b2A1I9n14a1r18y25_g7l12o15b2e5Stack Overflow is planning to give their theoretical AI/ML questions wholesale to Cross Validatedb2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Thanks for letting us know. I don't know what others think about this, but I would be interested in questions related to reinforcement learning, artificial intelligence, evolutionary computation, so I would definitely not mind having them migrated to AI SE.b2A1I9n14a1r18y25_g7l12o15b2e5In my personal experience, it's difficult to decide what AI questions belong on Cross Validated vs ai.stackexchange, but I think it's likely that a significant amount of them on stackoverflow probably belong here. When I ask AI-related questions, I've started differentiating between questions that are significantly based on statistics, such as statistical learning questions and many statistical-learning-leaning ML questions, and questions that are not, such as computer-science-leaning ML questions (architecture questions, algorithms questions, higher-level ML considerations, etc.).


















Hmmm I don't feel like they should necessarily be the same. In most machine learning contexts especially, as you say, I would view "evaluation" as something broader or more general than "testing". I guess I'd associate "testing" specifically with the classic train/validation/test data splits.
I could also see testing being used for an entirely different purpose though: testing whether an implementation is correct. Think of things like unit testing. A lot of that would probably just be about software engineering and be off-topic, but I could see questions about testing the correctness of specific things in AI being relevant. For example: How can I test that my gradient computations / gradient descent implementation is correct? (and an answer could get into things like numerically approximating gradients and checking that they're about the same as the analytically computed ones)
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Ok, so what should we do? Should we reserve [tag:testing] for the specific meaning of testing when we split the data into training/validation/testing datasets, or should we use it for a more general scope (as it seems to be the case now, according to the current description)? Should we have another tag [tag:evaluation] for general "evaluations of algorithms and models"? That doesn't look necessary, given that "evaluation", as we seem to agree, is not a well-defined term. Maybe we should wait for a third person to give their perspective before taking action.b2A1I9n14a1r18y25_g7l12o15b2e5@nbro Keeping `testing` as is, i.e. a bit more general, seems fine to me. I don't think a distinct `evaluation` tag is necessary. It could be a synonym... except if people start regularly using it with the intention of referring to like a "heuristic evaluation function". But currently it's unused, so that doesn't seem to be happening?b2A1I9n14a1r18y25_g7l12o15b2e5A few days/weeks ago, I had also introduced the tag [tag:evaluation-functions] (which can be combined e.g. with the tag [tag:search]), so I guess we can just make [tag:evaluation] a synonym for [tag:testing], to avoid people using multiple tags when they basically refer to more or less the same thing. In case something else pops up that we didn't think about, we can remove the synonym.


















I'd say that questions related to game-theory can very often end up being on topic on AI.SE, but it probably doesn't need to be explicitly listed as being on-topic in its entirety. Game theory does show up in various areas of AI (not just like minimax for search in games, but also for like any other kinds of multi-agent interactions, and probably some other areas I don't know enough about), so anything related to that should be on-topic in my opinion. I wouldn't explicitly list game theory as a whole as a topic, because if someone really has a complex, pure game theory question outside of any other AI context, they'd probably be better served on an economics or math website.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I skimmed some pretty interesting recent category theoretic game theory papers a couple of years ago, and I feel like that approach can subsume pretty much everything!  ("Game" and "player" seem to become arbitrary, b/c it's all just functions.) I agree with you on the complex questions being mor suitable for math or economics—that's a pretty specialize area, with different concern than our concerns.


















I was just reading https://ai.stackexchange.com/q/26311/16521this question regarding the use of deep neural networks for RNA data. I noticed that the user had used the 'biology' tag instead of a 'bioinformatics' tag, so I went to edit their post and saw that there is no 'bioinformatics' tag! I think a 'bioinformatics' tag is much more suitable for such questions than a 'biology' tag: https://en.wikipedia.org/wiki/Biologyhttps://en.wikipedia.org/wiki/Biology https://en.wikipedia.org/wiki/Bioinformaticshttps://en.wikipedia.org/wiki/Bioinformatics
Also, it seems that bioinformatics.stackexchange does not have any good tags for AI questions, so I think this is suitable for us.
Shall we create a 'bioinformatics' tag? (I don't think I have the reputation to do it here on my own.)
b2A1I9n14a1r18y25_g7l12o15b2e5'Bioinformatics' tagb2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Right now, the description of the tag [tag:biology] seems to cover topics that are not really on-topic here, so, if we also want to keep this tag, we definitely need to clarify which types of questions should be tagged with [tag:biology]. They need to be somehow related to artificial intelligence. I believe people use this tag when there's a question in AI that is somehow related to the biology. For example, [this one](https://ai.stackexchange.com/q/9296/2444). However, this may not always be the case, and, in any case, we would still need to clarify the description.b2A1I9n14a1r18y25_g7l12o15b2e5I also agree with you that [tag:bioinformatics] may be a tag that we can have on the site, but would also need to clarify which questions should be tagged with that and we need to check whether other sites (especially, Stats SE and DS SE) already cover similar questions.b2A1I9n14a1r18y25_g7l12o15b2e5@nbro Agreed. A lot of the AI/ML methods used in bioinformatics are definitely more statistical in nature (such as PCA, etc.), and so are more suitable for stats.stackexchange. Furthermore, bioinformatics often involves truly huge amounts of data, to the point that it, in the true technical sense, qualifies as "big data"; my understanding is that many of these "big data" data mining methods are more statistical in nature and lean towards being off-topic for ai.stackexchange. However, there are definitely some questions, such as some in DNN, that are probably more suitable for ai.stackexchange.b2A1I9n14a1r18y25_g7l12o15b2e5Also, I should point out that I'm not very familiar with datascience.stackexchange, so I'm not totally sure of the style of questions they ask there.b2A1I9n14a1r18y25_g7l12o15b2e5Meanwhile, I changed the description of the [tag:biology] tag to make it more acceptable. The new description is: "For questions related to biology in the context of artificial intelligence. For example, use this tag when you want to ask if a certain machine learning model was inspired by some biological counterpart.".


















Some of you may have noticed the Meta Stack Exchange post - https://meta.stackexchange.com/questions/364007/testing-three-vote-close-and-reopen-on-13-network-sitesTesting three-vote close and reopen on 13 network sites (it's linked in the featured on meta sidebar) - we've finally got this project under way and Artificial Intelligence is one of the sites we'll be running the test on.
Starting tomorrow, I'll be changing the site setting and closing and reopening will require only three votes. This test will run for 45 days and will be turned back to five votes to close and reopen while I review the data from the 13 sites. After we've seen the impact, I'll be posting results and, if there aren't negative impacts, we will change the setting to three permanently.
A few weeks into this, I'll be posting a question here on meta to ask for your thoughts about this change, so you will have an opportunity to discuss the impact.
Thank you so much for your patience while we got this prioritized and scheduled. There's a lot more information in the MSE post, so please review it.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Catija, thanks for the heads-up, and I'm glad we'll be testing this on SE:AI.  As a thriving small stack with typically lower voting participation, I suspect this will have utility here.b2A1I9n14a1r18y25_g7l12o15b2e5Hello Catija! Thanks for addressing this issue. I really think our community almost never closes a post with 5 votes nowadays. By the way, we have a post on the review queue, which has 4 upvotes, so it should have been already closed, but it wasn't yet.  See [here](https://ai.stackexchange.com/q/27635/2444). (Update: it was finally closed with 5 votes!)


















I am asking this question to get a list of standard textbooks read by top users or any user of our main site.
There are many domains in and around artificial intelligence such as machine learning, reinforcement learning, deep learning, probabilistic graphical models, optimization, etc., One may be a subset of another or can be overlapping.
Although there are tags in our main site that allows us to ask for recommendations, they did not contain all the books read by a user of our site.
The answers to this question also allow new users to check or read the books to understand and to ask new questions that have high chances of getting an answer.
What are the domains and the textbooks of that particular domain you read?

I am providing  a sample answer for reference here:
Mathematics
Probability

https://www.vfu.bg/en/e-Learning/Math--Bertsekas_Tsitsiklis_Introduction_to_probability.pdfIntroduction to Probability
Book by Dimitri Bertsekas and John Tsitsiklis

http://julio.staff.ipb.ac.id/files/2015/02/Ross_8th_ed_English.pdfA FIRST COURSE IN PROBABILITY by Sheldon Ross

................


Stastistics

........................................
......................................
............................

Core
Deep Learning

................................
.................................

Graphical Models

...................................

and so on..................
b2A1I9n14a1r18y25_g7l12o15b2e5What textbooks have you read?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I'm not sure whether meta is a good place to discuss this (check here: https://ai.stackexchange.com/help/privileges/participate-in-meta, https://ai.stackexchange.com/help/whats-meta), but I like the idea of sharing with all community members the "background" (in AI, of course) that (experienced) users have acquired by reading books. I will ask other moderators whether they think it's a good idea to have this post or not.b2A1I9n14a1r18y25_g7l12o15b2e5Another moderator from another site pointed out that a similar experiment (type of question) worked well on another site. See [here](https://english.meta.stackexchange.com/questions/2573/what-good-reference-works-on-english-are-available), although the question seems to be slightly different, as it's not asking for what the experienced users have really read, which is what you're asking. So, I think we could also allow it. Meanwhile, when I have more time, maybe I will prepare an answer, which shouldn't be very long anyway :D


















One can see that there are two closed proposals of AI on area 51: https://area51.stackexchange.com/proposals/6607/artificial-intelligence10 years ago, https://area51.stackexchange.com/proposals/57719/artificial-intelligence7 years.
I Joined in our main site an year back. I asked only https://ai.stackexchange.com/users/18758/hanugm?tab=questions&sort=newest25 questions and answered no questions. Because, the answers by expert or senior users are very well drafted and it may take sometime for me to study the topics in detail to answer.
I can experience a consistent support from https://ai.stackexchange.com/users/2444/nbronbro♦. And our main site has experts from several domain. For example, I believe that https://ai.stackexchange.com/users/1847/neil-slaterNeil Slater is a domain expert from reinforcement learning (since he answered for RL questions by me and several others).
I am getting great answers from several other users as well. But, I have a small concern regarding the moderation and activity by experts in our main site and feeling slight dissatisfaction.
Very few senior/expert members are providing answers, upvoting, editing etc., It may discourage new users to join and contribute as well.
My question: Why do many (domain) expert users remain silent or calm?
I feel that our main site can achieve really great stature if such expert users are not silent.
I am guessing the (any or some) following reasons:

They are contributing to other related sites like Cross validation, Data sciences, Stack overflow, Computer science.;

They are not impressed by the quality of questions asked by the users;

They are busy with their professional or personal activities;


Are my reasons true? If not, what may be the reason for such inactivity? Or am I going wrong anywhere?
b2A1I9n14a1r18y25_g7l12o15b2e5Why domain experts of our main site are mostly calm?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I am just sharing my experience. Please don't take it as a complaint.b2A1I9n14a1r18y25_g7l12o15b2e5I personally got to the point where I learned enough to know how little I actually know, and became much more reticent.  But activity tends to wax and wane with many long term contributors.  Even on stacks where I have very high expertise, I come an go as time allows, and inspiration demands.  We're still a mom and pop stack, but we'll get there.


















Artificial intelligence is developing at rapid level and there are several experts around the world. Coming to academics, there are large number of professors available compared to last decade. Artificial intelligence also became a compulsory course in developing countries.
Although I asked some questions on https://datascience.stackexchange.com/users/47826/hanugm?tab=questionsData Sciences and https://stats.stackexchange.com/users/42883/hanugm?tab=questionsCross Validation stack exchange sites. I personally feel that our main site is less in no way and I can opine that our main site has better chances to contribute in a better way than other sites. I feel that our site is mostly visited by the beginners or intermediates like me.
Beginners generally tend to ask more and more questions.
So, there is a great need to increase in the critical mass of the experts. Else, in long run, beginners may feel either hopeless or neglected. It may in turn decline our site progress.
In order to not make it happen, along with the efforts to make the experts on our main site active, we need to attract the new expert users that are either unaware about our site or contributing on other sites etc.,
What kind of activities I(any one) can do in order to attract the new experts to our main site?
b2A1I9n14a1r18y25_g7l12o15b2e5What can I do to attract expert users?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Might it be helpful to kinda have programming questions about AI also included in the AI .stackexchange? In the hope to attract people that try to implement papers, what in-turn might attract experts that might have written the papers or tried implementing it themselves.


















I agree with your points. This is a question that I've been asking myself for a long time, but I don't have a definitive answer/solution. Some potential solutions are

Advertise our website (but not sure how and where); I've tried to do this sporadically and not very seriously (e.g. by pasting links on other chats, but this actually led to some hot debates between me and others, so I've stopped doing this)
Talk about this site to your friends/colleagues/classmates (when you have the occasion)
Mention the name of this site in events like conferences or workshops

We should highlight the strengths of our site and we should especially try to attract users that are interested in those strengths and topics. We tend to attract several users interested in reinforcement learning (which is very nice, given that RL is very central to AI), but, unfortunately, we do not attract many qualified users in other areas, like the philosophy of AI, cognitive architectures, AGI, evolutionary computation or even just the regular machine learning topics.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5as an example days ago I was trying to answer the contributions in AGI of Russia. They have one project related to that in a paper from 2012 I contact the founder through linkedin because the website is offline and if the project is still open and he answer:>No, this project is inactive now. We joined SingularityNET.and I respond him >I was trying to answer this [question](https://ai.stackexchange.com/questions/4112/is-russia-contributing-to-open-research-concerning-friendly-ai) I think this is a good way to attract expert users to AI.SE finding interest in the question and answer of this site


















In theory, this is a good idea, in my opinion. In practice, Stack Exchange websites do not seem to like or want to collaborate with each other (at least, this is my impression).
Why? Because I tried to do something similar in the past (like publishing links to some of the interesting posts on our site on their chat rooms or stating that RL questions can also be asked here and, in some cases, I said "should be asked here" because RL is central to AI, in my view: this "should" was probably what scared or made them angry, because RL is also on-topic there...), although without officially asking them (which was probably a mistake), but the guys at Cross Validation Stack Exchange didn't really like my actions, given that, in my view, they feel threatened that this can reduce their number of users and some of them would argue that our site shouldn't exist because they already cover a big part of our scope, which is true, although our site also covers topics that they do not cover and we focus on Artificial Intelligence and not Statistics, that's why we exist, I would say.
In any case, this is something that should also be asked on their metas to really understand what the status/consensus is now. In my view, collaboration can only help us and them. However, to be honest, I will not invest more of my energies and free time on these debates with them because I already lost too much time and effort in vain (but I admit that my approach in the past was not ideal and diplomatic, to start with, and that might have contributed to the unsuccessful attempts to try to attract more experts and users to our site). This does not mean that you or others can't try to do that by starting with asking the same question or proposing the same idea on their metas.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I will try on meta.


















I am in favour of this type of question being on-topic here. In particular, it seems that those questions would be at the intersection of "history of AI" (which is on-topic here) and "terminology" (in the sense that you want to know something about terms). We have had some of those question in the past. I remember one that I actually provided an answer to which was never closed as off-topic and I had never considered it as such: https://ai.stackexchange.com/q/20044/2444Why is it called back-propagation?.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5By the way, I am currently reading a book about the history of AI and, occasionally, the author provides info about the origin of a term.


















I don't think I have ever fully read any technical book or textbook (on an AI-related subject/topic). Typically, I start reading a book, then, after a while, I don't have more time to read it, so I interrupt the reading, which I may resume later.
So, I have partially read multiple books and consulted others multiple times. Below, I list some of the books that I read or consulted the most, as far as I remember. There are probably other books that I've partially read. Currently, I'm also reading another book (not mentioned below), and I may start reading another one. I will be updating this list.
Artificial Intelligence

Reinforcement Learning: An Introduction (by Barto and Sutton, this is probably the book I read the most, almost all chapters of the first edition, and I regularly consult it)
Artificial Intelligence: A Modern Approach (by Russell and Norvig, I read several chapters, especially the ones related to search, and I often consult it)
Superintelligence: Paths, Dangers, Strategies (by Bostrom, the first chapters, then I got tired of reading the speculations)
Universal Artificial Intelligence: Sequential Decisions Based On Algorithmic Probability (by Hutter I think only the first and maybe second chapters; very technical book, so it's not an easy reading at all, even if you're familiar with the theory of computation)
Multiple view geometry in computer vision (by Richard Hartley; this book introduces some traditional computer vision topics; I didn't read much)

Computer Science

Introduction to Algorithms (by CLRS, any computer scientist should be aware of this book; do you want to know about red-black trees or binary search? this is the book!)
Introduction to the Theory of Computation (by Sipser, which is one of my favorite books, among all of these; do you want to know about finite-state machines, push-down automata, Turing machines, formal languages, the pumping lemma, the Halting problem, undecidability, complexity theory [e.g. NP-completeness], reducibility, etc.)? This is the book you should read!)
Quantum Computing for Computer Scientists (by Mannucci and Yanofsky, which is also one of my favorite books)
Computational Geometry: Algorithms and Applications (by Mark de Berg et al., I didn't read much)
Structured Computer Organization (by Andrew S. Tanenbaum; we had used this book in a course "Computer Architecture" during the first year of my bachelor's in CS; I don't remember what I had read...)

Math

Elementary Analysis: The Theory of Calculus (by Ross; this is a very nice book that will help you consolidate your knowledge of calculus, if you go through the details, proofs, etc.; my professor, when I was doing my bachelor's, in fact, noticed, from my one of my exams, that I had read the book; I didn't fully read it, only a few chapters, but it's a book to keep an eye on if you want to have a solid knowledge of the topic)

b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Great post!  I need to add these to my library, since my current program is not rigorous.  (I've been using Bohm for quantum mechanics, but, so far, I've only been interested in fundamental definitions, such as his expression of orthogonality in ℝⁿ.  Now that I've forgotten other expressions, I want to try and create my own expression in ℤ-space for n-dimensional regular grids, which should be trivial.  Sipser sounds like it would be a great help in general for formal statements.)b2A1I9n14a1r18y25_g7l12o15b2e5And it seems like, if I were able to do this, I could then check Berg to see if it's consistent.  I found Tanenbaum 2016 for $4 in paperback.  There's a million textbooks that *look* good, but they don't come with a trusted recommendation.  I bought the Bohm b/c I was seeing him him cited everywhere.


















I flagged as unfriendly/unkind the following comment in https://ai.stackexchange.com/questions/29950/is-it-abuse-of-notation-to-use-tilde-operator-in-this-contextthis thread:

@desertnaut I don't have the time nor will to continue this useless discussion here.

Moreover, I flagged the following comment in the same thread as "no longer needed":

@desertnaut If you want to post it on meta, please tell me. Else I will do it.

The reason for the 2nd flag should be obvious; I should not be asked beforehand if I intent or not to post anything on Meta. But, in any case, I was the sole recipient of this comment, and, since I had been already informed, the comment arguably does not serve any other purpose, and it can be safely deleted as no longer necessary.
Both flags were declined.
What makes things arguably more complicated for both raised flags is that the commenter is indeed a moderator [EDIT: this is true only for the first (U/U) comment, not for the second "no longer needed" one); so, I would naturally expect that, since these are cases where a mod is involved, the flags should not be handled by the subject mod, due to a clear conflict of interest. At the very least, they should be handled by a different mod.
So, do we have a code of conduct in place, dictating that in cases were a mod is involved, the relevant flags should not be handled by the involved mod?

If yes, was this code of conduct followed in the case described above?

If no, should we? Does it makes sense that cases were a mod is involved cannot be resolved by decisions of the involved mod?


b2A1I9n14a1r18y25_g7l12o15b2e5Conflict of interest in declined flagsb2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I already asked another moderator to handle this situation. I am now curious to see how far this discussion can go to end up with the same conclusion that questions about notation in ML papers are on-topic here, as clearly and explicitly stated in our on-topic page, which has been the same for months.b2A1I9n14a1r18y25_g7l12o15b2e5@nbro kindly re-read closely the post, which has absolutely nothing to do with what you are saying here. It is quite interesting how both subject flags were processed in lighting speed, while other U/U comment flags are seemingly [left to rot](https://ai.stackexchange.com/questions/28598/how-does-a-decision-tree-split-a-continuous-feature/29937#comment45951_29937)b2A1I9n14a1r18y25_g7l12o15b2e5I read this post, but everything started because you _wrongly_ believed that a certain post is off-topic here.b2A1I9n14a1r18y25_g7l12o15b2e5@nbro I regret to say that this has *absolutely nothing* to do with the question here. You are a mod, and you should be the example here. You are very welcome to consider the discussion there as "useless" and my opinion wrong, but putting this on a comment in writing is arguably both unproductive and U/U; similar arguments hold for the 2nd flag (explained in-post). Kindly do not try to move the goal posts *here*; if you wish to discuss the other issue, please do it in a separate thread - this is *not* what is discussed here.b2A1I9n14a1r18y25_g7l12o15b2e5"Absolutely nothing" is wrong, as you're linking to the post that you wrongly voted to close as off-topic and where you started the discussion that led to this question. Comments on the main site should not be used for long discussions, as you well know, that's also why I said that discussion is useless. I think you're exaggerating a little bit, but this is my perspective. In any case, the question you're asking here are interesting. The _suggestion_ by moderators that have been moderators for a long time would probably be to leave the handling of the discussion/problem/flag to another mod.b2A1I9n14a1r18y25_g7l12o15b2e5I decided to decline the flags because I don't think my comment is really unkind, although I could have left the "useless" out, and because the question by the OP was very opportune (and you flagged as no longer needed before you posted anything on meta).b2A1I9n14a1r18y25_g7l12o15b2e5@nbro So, you don't see any issue in "*I decided that **my** comment was not really unkind, so I declined the flag myself*", right?b2A1I9n14a1r18y25_g7l12o15b2e5Yes, it's somehow an issue (that's why I say your question(s) are interesting), but, in my opinion (but again this maybe becomes a circular reasoning), we can judge our own actions objectively too (to some extent at least), although there may be some bias.b2A1I9n14a1r18y25_g7l12o15b2e5I am sorry, but I am not going to open a philosophical discussion here about if we can judge our own actions objectively (!). Neither opinions nor intentions are discussed here, *actions* are.b2A1I9n14a1r18y25_g7l12o15b2e5We all make mistakes and have bad days, even mods.  We are sometimes under pressure and have to move quick.  (People have been pissing me off so much at work and in my academic program that I had to stay away until my general rage subsided, such that I could be impeccably kind and friendly in my role as a mod.)  But nbro take the lion's share of the responsibility since he came on as a mod, and even before that he spent an enormous amount of time getting this stack focused, and getting us math formatting.  So he deserves a lot of consideration, ever where he may be sometimes brusque.b2A1I9n14a1r18y25_g7l12o15b2e5I've been moderating this stack since ~AlphaGo, and I can tell you this stack would not exist had nbro not joined and pushed us to our present form.  And believe me, we argued for a couple of years before he took on the mod role, such the people thought we were enemies.  But we were just working through the problems and issues, and neither of us hold back in debate.  (That's why I personally love nbro—he's the guy who will call me on everything, *every time*.  Keeps me honest and continually forces me to up my game.  Some of the best insights I've had come via our arguments over *years*:)b2A1I9n14a1r18y25_g7l12o15b2e5@DukeZhou thank you for the (unsolicited) information, but I fail to see how it is relevant to the topic here, which is specifically about conflicts of interest and the code of conduct; except if you are implying that we can tolerate violations of that code based on good past behavior...b2A1I9n14a1r18y25_g7l12o15b2e5No worries!  Mainly I'm saying is that everybody is human, we all have bad days (typically when we're stressed).  But I'm not sure SE:AI would still be around if nbro hadn't come on board. (Just my opinion, having moderated this stack for nearly 5 years prior, largely on my own, and not feeling qualified in every area.)b2A1I9n14a1r18y25_g7l12o15b2e5When I first came on Stack, it was a brutally unkind place, and I think we've been improving across the board since do many of use pushed for the "be nice" rule. But we don't always hit that mark.  We all have a lot of stressors in our lives, so I usually reset to sincerity over individual instances of behavior.


















Just to quickly comment on that particular situation:
Since that particular discussion went on for way too long anyway, I moved it in its entirety to https://chat.stackexchange.com/rooms/128104/discussion-on-question-by-hanugm-is-it-abuse-of-notation-to-use-tilde-operator-ia chat room. Which kind of resolves all those flags on all those comments automatically. If it had not been moved into a chatroom, personally I would have agreed with the second flag (the "no longer needed flag"), but not agreed with the first flag (the "unfriendly/unkind") flag. Nbro had already rightfully pointed out that meta would be the appropriate place to continue that topic, and it's fine to try to put a stop to that discussion continuing on forever.

To respond to the actual questions:

So, do we have a code of conduct in place, dictating that in cases were a mod is involved, the relevant flags should not be handled by the involved mod?

If yes, was this code of conduct followed in the case described above?
If no, should we? Does it makes sense that cases were a mod is involved cannot be resolved by decisions of the involved mod?


The only thing I've been able to find on this topic is https://meta.stackexchange.com/q/306740/376651this meta discussion. There doesn't really seem to be such an official rule, but it is sort of an unofficial rule... with a bunch of exceptions, because sometimes it really is just reasonable and useful for a moderator to immediately handle flags on their own content. Personally, yeah I think it makes sense to try to refrain from resolving flags on your own content, especially at the point in time where it turns out to be a contentious topic... but more so as a rule of thumb than as a hard rule.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5"*it's fine to try to put a stop to that discussion continuing on forever*" - I couldn't agree more. But the only thing one has to do in this case is to simply *stop posting*; there is no need to "announce" it like that, even less to include derogatory terms like "useless conversation", which the U/U flag was clearly about. "*Nbro had already rightfully pointed out that meta would be the appropriate place to continue that topic*" - yes, and that should be all indeed!


















Since the user you are referring to is me, let me clarify some things to avoid misunderstandings.
In principle, there is absolutely nothing wrong in asking such questions in the comments.
The whole issue has also nothing to do with "friendliness" (we can disagree and still be friendly); in hindsight, I should have worded the comment slightly differently, as:

I need not be asked beforehand if I intent or not to post anything on Meta.

and that's all.
IMO, I just think that such questions of intent are not particularly useful, and that's all. What if I had replied "yes, I will" and then do nothing (because I am busy, away, changed my mind etc)? What if I had replied "no, I will not", and then, on a second thought (everyone is entitled to a 2nd thought, right?), proceeded to open a thread at Meta? Why should I commit, at the certain point of time, about doing or not doing something in the future, and why this (non)-commitment from my side should affect you and your own intended actions? Even if we both decided to open a Meta question, there is no guarantee of sorts that these questions would be identical (either in spirit or in letter).
So, while nothing wrong, my personal recommendation here would be to refrain from doing it, only because it does not seem to me to be particularly useful or productive, and not for any other reason. Even if the recipient chooses not to reply (for any reason, including that they have not made up their mind yet), they run the danger of looking somewhat rude; why you would want to put anyone in such a (potentially awkward) situation?
So, that was all behind my own comment, and nothing more. Hope it is clear now, and if it came out in any unfriendly way, let me hereby assure you that something like that was nowhere close to my intentions.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Comments are not for extended discussion; this conversation has been [moved to chat](https://chat.stackexchange.com/rooms/128159/discussion-on-answer-by-desertnaut-is-it-not-recommended-to-ask-the-intent-of-ot).b2A1I9n14a1r18y25_g7l12o15b2e5@nbro Thank you for clarifying that what you meant is that me (and only me) am not entitled to my opinion :) And good job in hiding the comments from plain sight (I understand)...


















Our main site has https://ai.stackexchange.com/users?tab=moderatorsfour moderators. Some (https://ai.stackexchange.com/users/2444/nbronbro♦) are/is active and some are rarely active due to various reasons.
If there is a possibility in increasing the number of moderators, are you interested in becoming a moderator to our main site?
b2A1I9n14a1r18y25_g7l12o15b2e5Are you interested in moderating Artificial Intelligence Stack exchange?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5There's one moderator that rarely visits the site (although in the past he was very active for several months and he can really be useful when it comes to giving advice, as he's more experienced than me), but there's another one that regularly visits the site (and helps me when I ask explicitly him for help) and another that occasionally also does it (and, in the past, he used to help me a lot more).b2A1I9n14a1r18y25_g7l12o15b2e5It would be better if we had 4 really active moderators, but it's more important that we have active regular users, like you, that _regularly raise flags, ask for clarifications under the post, edit posts, ask and answer questions, etc._ Right now, you're doing a good job, and I really appreciate the work you've been doing.b2A1I9n14a1r18y25_g7l12o15b2e5Anyway, [it's usually a super-mod or mod that asks this question to the community](https://ai.meta.stackexchange.com/q/1602/2444), but I am also interested to know if anyone is interested in this role.b2A1I9n14a1r18y25_g7l12o15b2e5Thanks @nbro I will try to preserve it.b2A1I9n14a1r18y25_g7l12o15b2e5What we really need is greater voting participation to better validate answers.  This stack improved enormously when nbro and Dennis joined the mod team, by bringing more clarity and focus, which renewed our energy.  I don't even remember when I became a mod on this stack, but it was sometime around AlphaGo, if I recall correctly.  I still consider myself a beginner in AI!  (But I'm glad we continue to attract both experts and serious students applying themselves rigorously.) I tend to see this as a project of decades.  This stack had almost no utility at the outset. Today it's very useful.


















I am ambiguous about it and almost completely biased towards not becoming a moderator now.
Reasons:
I am a beginner in AI and hence I don't know much of the concepts in Artificial Intelligence. I may get confusions easily in editing or other tasks.
Along with less expertise in AI, I feel that my style of framing sentences may not be correctly interpret-able to many users on our main site.
But, I want to continue my contribution in some or other way as a member of or community rather than a moderator which needs some skills that currently I don't have.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I don't think being a moderator on a site should require you to be one of the high-ranking experts. In fact I think there's a clash in terms of time spent (do you want to answer questions, or contribute other things to the site?), and also possible conflicts of interest that you need to navigate. Instead I think you should consider your site reputation, which is a measure of how much the community thinks you contribute to the routine issues on the site. It means you are already trusted with a lot of the content as a regular user. The other issues you claim impact you are salient though, IMO.b2A1I9n14a1r18y25_g7l12o15b2e5@NeilSlater **The reputation is not always a good indication of how much we should trust a user**.  In the past, we had several users that got a lot of reputation, but they couldn't really be trusted. You probably remember them. Moreover, we often see people with 150k reputation being suspended or doing other bad things. So, I think that reputation is necessary to some little extent, but it's really not the most important thing to become a mod. You can have 500 rep and be a good mod, as long as you've shown, in other ways, that you cared for this community during the years.b2A1I9n14a1r18y25_g7l12o15b2e5@NeilSlater Having said that, I agree that you don't necessarily need to be an expert in all AI topics to be a mod (e.g. if you're an expert in RL but you don't know anything about expert systems, ok, fine), but I think it's important to have a good overall knowledge of the field or be interested in all aspects of AI, because, in certain situations, you also need to take certain decisions that would require knowledge of AI.


















A few days ago, I posted https://ai.stackexchange.com/questions/30150/is-this-a-valid-argument-against-the-possibility-of-agithis question that was later closed for being off-topic. I don't mean to beat a dead horse, but I genuinely don't think the question broke any rules.
The question I asked was:

Question. Is my argument valid? Are there any significant holes or logical fallacies? Has any form of this argument been made before?

Here's why I don't think this question was off-topic:

https://ai.stackexchange.com/help/on-topicThis help article lists the following topics as off-topic: career path recommendations, general programming questions, implementation questions unrelated to theoretical topics, and questions seeking pre-trained models. My question does not fall into any of these categories.

https://ai.stackexchange.com/help/dont-askThis help article describes the type of questions that should be avoided. In particular, it states that subjective questions should usually be avoided, but are sometimes okay. But even if my question is to be classified as subjective, it fulfills all the criteria for an allowable subjective question.

The comments mentioned that my post was "not a question, but a discussion point, and "this could lead to discussions because some of your assumptions may not be correct."
Though I did ask a specific question, I understand that it could have lead to discussion. But doesn't every question lead to some degree of discussion? I don't see how my question, which was focused on a specific argument against AGI, would lead to more discussion than open-ended questions like https://ai.stackexchange.com/questions/26007/are-there-any-approaches-to-agi-that-will-definitely-not-work?noredirect=1&lq=1this and https://ai.stackexchange.com/questions/7875/is-the-singularity-something-to-be-taken-seriouslythis.
Also, if someone finds incorrect assumptions in my question, they could have posted those as an answer. My question was asking whether or not I made any incorrect assumptions or other logical missteps.

I meant for my question to be like the https://math.stackexchange.com/questions/tagged/solution-verification?tab=Newestproof-verification questions on Math Stack Exchange. I didn't mean for it to be some kind of ongoing debate or discussion. I was looking for answers of the form, "This argument is flawed because _____."


Question. Why was my question marked off-topic? Is there a specific rule/guideline that I broke?
b2A1I9n14a1r18y25_g7l12o15b2e5Why was this question marked as off-topic?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I'm sorry to hear that. Unfortunately your post is no longer accessible, so I can't see the original message.b2A1I9n14a1r18y25_g7l12o15b2e5Hmm, the post was automatically deleted by Community a few days ago :/. Is there any way to recover it?b2A1I9n14a1r18y25_g7l12o15b2e5I don't know about that. You could try searching for that, or trying something like Internet Archiveb2A1I9n14a1r18y25_g7l12o15b2e5@AndreGoulart I reposted Frank's question below.  Thanks for contributing!b2A1I9n14a1r18y25_g7l12o15b2e5See: https://biology.stackexchange.com/a/40581/49363  and the list of "introductory posts on Biology.SE", in particular: https://biology.stackexchange.com/q/35532/49363 and https://biology.stackexchange.com/q/21058/49363  - and https://biology.stackexchange.com/a/81579/49363 --- So it's probably more "on-topic" there, and an opinion answer here; since there are unsupported claims (theories) to be rejected.



















Is it allowed to do?

No, this is not allowed in general for images, or in fact any content that you discover online or anywhere else.
To use an image in a question or answer, you need to be the original image author, or to have been given copyright that is compatible with uploading to Stack Exchange.
The Stack Exchange terms and conditions https://stackoverflow.com/legal/terms-of-service#licensinginclude a section on content permissions and this has a section called "Subscriber Content" which covers this in detail.
In short, all content that you post - any question or answer - is licensed to the Stack Exhchange by you under https://creativecommons.org/licenses/by-sa/4.0/a Creative Commons v4 license. You must have the rights to do this, otherwise you are in copyright violation (and so is Stack Exchange, but they can hold you responsible).
As well as being an image author, you may have received it in a way that means it is OK to re-use it in Create Commons content. For instance, it may be public domain or already licensed as Creative Commons or compatible license.
If you are not sure about rights to re-use an image on the site, then you have a few options:

Link the image where you found it, don't embed it.

Contact the image author and ask.

Search for a similar image that is Creative Commons already. Google image search allows you to do this, and https://commons.wikimedia.org/wiki/Main_PageWikimedia Commons allows you to search for images on its site that might cover your needs.

Re-draw your own version.


A lot of people do not understand the fine details of copyright rules. That also means that a lot of technically invalid content gets posted, and also that a fair amount of that is de-facto OK, because the original owner does not mind (they just don't know or care about the licensing to do the work to share legally). However, the safe advice is to not use images that you are not sure about.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I'm taking some classes in an online masters with regional accreditation, and the professors have PhDs. But in the orientation, the school itself seems to be teaching students to use synonyms and rearrange sentences and paragraphs to avoid getting caught by a last-gen plagiarism checker.  My feeling is, based on Spry Fox v. Lolapps (settlement) and Tetris v. Xio (district ruling), it's not entirely clear that recombinant sentences and paragraphs don't constitute infringement. I see it as a syntactic structure with the same keywords, which is how I imagine an NLP algorithm might.b2A1I9n14a1r18y25_g7l12o15b2e5My takeaway from the referenced cases is that, if reskinning a game constitutes copyright infringement, and straight ripping a game just because it's not patented constitutes infringement, then recombinant sentences and paragraphs could constitute infringement when used for commercial purposes, if some deep pocket private enterprise decided to pursue it.  It's too much work for a human to check, but my guess is it's either possible today for NLP, or on the present horizon. (People seem to have forgotten when Zuck tried to exert copyright over all the FB content.)b2A1I9n14a1r18y25_g7l12o15b2e5With something fundamental, such as redrawing a graph, I don't see a problem.  (Ideally, the student understands the concept fully so they can recreate the graph from first principles, similar to not having to repurpose prior linguistic content b/c one understands the material.)  And I do think there may be some wiggle room via "fair use" for journalism or non-commercial research. However, I **strongly agree** that it is better for Stack if people stick to creative commons, and avoid posting material that is or may be copyrighted.


















We tried to specify in https://ai.stackexchange.com/help/on-topicour on-topic page examples of questions that would be off-topic here (see the section "Off-topic"), but we didn't provide an extensive list of types of questions that would be off-topic. I think we could indeed create a meta-post with a list of all types of questions that would be off-topic, but I am not sure if it's worth it, as the on-topic page should already be quite clear. Let me know what isn't clear enough by reading the on-topic page, so that we can clarify that.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Great to see there is already such a page! In my opinion, it's too big. (Estimated reading time: 4 minutes, 51 seconds. Contains 972 words). It should be more compact, or more structured (like using tables), more organized (using sub-bullets and sub-headers), or even using emojis (❌,✅) for easy, fast visual clues.b2A1I9n14a1r18y25_g7l12o15b2e5@AndreGoulart Yes, we can definitely improve the structure of the page.b2A1I9n14a1r18y25_g7l12o15b2e5I just took a look—been a while.  I parsed that page in 30 seconds, and could easily identify what section would contain the info I might be looking for.  Reading carefully, per Andre's timing, is another matter.  (My sense is people fall into two categories "read the manual" or "don't read the manual", and tech will always have both.  I'm the latter b/c I prefer to learn systems by observing and poking at them;)


















I reviewed the question, which I like very much, but here's why it was closed:
It's more of a thesis that gets around to the question.  In the previous incarnation of this stack, we were allowing it.  But it becomes too easy to abuse, and so the community felt it was better not to allow.
I don't see this question as that, but I think it would be more suitable if you addressed a single claim per question.  I want to see more of these questions, so I hope you'll give the subject another shot.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5In short, it was ON-TOPIC. But it seems more like a debate than an objective question. Is that so? @Frank, I liked your post. If you can reformulate a specific and objective question - or split into several shorter questions - that will be great.b2A1I9n14a1r18y25_g7l12o15b2e5@AndreGoulart I would very much like to get these topics reposted, and think 4 or 5 questions is better than one, and better for the stack.  (We could link the related questions in first comment or subscript at the end of the posts.


















I personally think all of the game theories can comment at a much more fundamental level than search, because I see it as the root of all rational decision making, which is the basis for intelligence (utility in an action space.)
I don't know that we need an explicit on-topic reference, but, in view of genetic algorithms/evolutionary game theory, I think we might want to consider it...
(Because I'm doing a database program, I'm currently thinking about game theoretic approaches to data storage, structure, and management.  I don't know if it will be fruitful, but it will be interesting!)
I'd want to specify that we're interested in game theory in regard to things like search, genetic algorithms, and rational agents, not specific real world economic questions like those explored by think tanks.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5(I also think there is probably a huge amount of bias in the applied game theory space, where you can twist logic to support preferred, non-cooperative strategies.  You see this most clearly in attempted refutations of Nash, with simple logic that doesn't hold in the most basic iterated dilemmas, because there is a faction that rejects cooperative behavior.)


















I've been a mod here for a long-*ss time, and this question has come up a lot.
https://ai.stackexchange.com/questions/31798/is-it-okay-to-use-publicly-available-instagram-videos-to-train-an-ai/31804#31804Is it okay to use publicly available Instagram videos to train an AI?
I consult with attorneys on such subjects, work in the field currently, and have come to understand the mechanics of law.

Algorithmic patents are such a specialized area, SE:Law may not have that niche expertise

As an example, I successfully argued to the US patent board that a games are a form of computation, and therefore machines.  At that time, most patent attorneys were advising that, post-Alice, game mechanics were no longer patentable.  The good attorneys advised that "nobody knows".

Use of public data for datasets is a specialized and novel area of copyright law

The limitations of copyright for code are well understood (only that specific expression, not other methods of completing the task), but we've only had strong NNs for a half-decade, and the internet for less than 50 years.

This is a new area of law, specific to the AI field, and should be on-topic here

Nobody knows the answer to these questions in most cases, because it's a matter of precedent, current legal climate, and true intent of the laws (material effect.)
There may even be cases in the AI field where a researcher creates a useful function and should be able to benefit, which does require patent.  Patents have been a staple of enginering fields for centuries. They are the only intellectual property protection engineers have.

There area other newly defined domains of law specific to AI

Facial recognition, as an example.  Privacy takes on a whole new meaning when you have narrow artificial super-intelligence.

AI law constitutes a unique subfield, and should be on topic here

I'm actually thinking about this area of law for a future career, b/c it's interesting, and SE:AI is the forum I'd want to come to, because it's here I'm going to learn what is relevant, common, and on the horizon.  I'd want to answer AI law questions here, not on the general law forum.
There are so many dimensions including:

AI personhood is a hypothetical social and legal question, and the legal aspect has much greater material effect.

Someone already tried to claim a genetic algorithm as an inventor to the patent board, which was rejected b/c the algorithm isn't a "natural person".
So I kind of feel like some aspects of law are already on-topic.
b2A1I9n14a1r18y25_g7l12o15b2e5Should AI intellectual property Law be on topic?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Yeah, it should be on-topic.


















Consider the following https://ai.stackexchange.com/tourintroduction lines regarding our main site

Artificial Intelligence Stack Exchange is a question and answer site
for people interested in the theoretical (including mathematical),
philosophical, social, historical, and certain developmental and
academic aspects of artificial intelligence.

What exactly is the philosophy that is related to artificial intelligence? I can understand the other aspects such as mathematical social historical aspects of artificial intelligence, but it is not known to me what is meant by the philosophical aspect of artificial intelligence.
b2A1I9n14a1r18y25_g7l12o15b2e5What exactly is the philosophical aspect of AI in this context?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5you should start with this audiobook: [John Searle - Minds, Brains, and Programs 1984](https://www.youtube.com/watch?v=9QbOvGJDlbk)  also check this [posts](https://philosophy.stackexchange.com/questions/tagged/artificial-intelligence?tab=Votes) for give to you an idea what is meaning the philosophic aspects of artificial intelligence.b2A1I9n14a1r18y25_g7l12o15b2e5[As someone pointed out in a comment below](https://ai.meta.stackexchange.com/users/30751/rubengavidia0x), maybe it wasn't a good idea to migrate your question to meta, although you were mentioning something about our site and its scope. This question could indeed have been left on the main site, as it's about the "AI field" and not just our site, and the answers to it could indeed be useful to more people.b2A1I9n14a1r18y25_g7l12o15b2e5One thing we could do is: you ask the same question again on the main site and we post our answers again there. Let me know what you would like to do and what are your thoughts. It was my bad to act so quickly in this case. So, if you decide to ask this question again on the site, let me know, and I can delete the old one (if not already deleted), and make sure you tag it with [tag:ai-field].b2A1I9n14a1r18y25_g7l12o15b2e5@nbro No issue. I will do.b2A1I9n14a1r18y25_g7l12o15b2e5Maybe it's better I get the feedback from all moderators before doing this. I will talk to them. It's also ok to have this question here. The question is: would this question be suitable for the main site?!b2A1I9n14a1r18y25_g7l12o15b2e5It seems that the other moderators would agree that this question could also be asked on the main site. You don't have to delete it from here, but maybe you reformulate the question so that it doesn't focus much on the scope of our site, but more on the "AI field", i.e. ask a question as a person that is new to the field and doesn't know what the AI field has to do with philosophy. This is just my suggestion. Feel free to ask it differently or even not to ask the question again on the main site (as you already have answers to it).



















https://en.wikipedia.org/wiki/Ethics_of_artificial_intelligenceEthics of artificial intelligence is a new field

This is a new area of moral philosophy that only became non-hypothetical when we have the processing and memory to achieve strong-narrow superintelligence around 2015.

Neoluddism

I don't mean this in a strictly negative way, but in terms of the core principle, which can be summarized as:

New technologies create problems that cannot be predicted.

The classic example is the "blackening of London" due to pollution beginning in the 1660's.  (See: https://www.tandfonline.com/doi/pdf/10.1080/00022470.1978.10470577Air Pollution in Industrializing England, Brimblecombe, 1978)
By contrast, the old-school https://en.wikipedia.org/wiki/LudditeLuddites got it wrong about the https://en.wikipedia.org/wiki/Jacquard_machineJaquard looms.
Not hypothetical, and one can argue supportably that the present social dysfunction is a largely a function of automated algorithmic decisionmaking (See: Facebook, Youtube, et al.)
Key topics here involve voluntary human obsolescence—offloading not only repetitive tasks, but https://en.wikipedia.org/wiki/WALL-E#Plotoffloading competency and responsibility (militarized drones as an example.)

If strong Artificial General Intelligence is ever achieved, the question of personhood will become non-hypothetical

There was already an attempt to list an algorithm as an inventor on a patent, which was rejected because the algorithm is not a "natural person."  (https://www.jurist.org/news/2021/09/federal-court-rules-artificial-intelligence-cannot-be-an-inventor-under-us-patent-law/Thaler v. Hershfeld,  09/02/21)
This is a legal question but deeply philosophical.  What does it mean to be a person?

The Grecian Room

I'm calling to change the https://plato.stanford.edu/entries/chinese-room/unfortunate name of this thought experiment to something more consistent with the mythology of AI.  (Phillip K. Dick, here understood as a narrative philosopher, wrote about the difference between https://en.wikipedia.org/wiki/Xenoglossyxenoglossia and https://en.wikipedia.org/wiki/Speaking_in_tonguesglossolalia, which comment on Searle, in regard to Ancient Greek specifically. [See https://en.wikipedia.org/wiki/Valis_(novel)VALIS trilogy.] Dick is a major narrative philosopher along with Asimov, https://en.wikipedia.org/wiki/Stanis%C5%82aw_LemLem, and recently, Rajaniemi. Dick and https://en.wikipedia.org/wiki/I,_RobotAsihttps://en.wikipedia.org/wiki/Foundation_seriesmov have probably had more influence that Searle in the public understanding of AI. They use mythology of AI to explore social concepts in the manner of https://en.wikipedia.org/wiki/AtlantisPlato.)
There are more examples, so others should answer as well if I've missed anything.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Why is "Chinese room" unfortunate? Actually, Chinese is a good example because it's written so differently from European languages. If it was a French room you could guess the meanings of many words.b2A1I9n14a1r18y25_g7l12o15b2e5@user253751 Because it is an extension of the trope that Chinese people are "inscrutable".  The point about ancient Greek is that it's not a living language.b2A1I9n14a1r18y25_g7l12o15b2e5I think Greek is still spoken in Greece. Was the ancient version a completely different language?


















I find this an unfortunate choice by Searle in the present era, and argue

The Grecian Room is more suitable

My feeling is that Chinese Room creates a negative perception of Asian people and Asian Americans as "other". When Searle used it, this notion of otherness was surely an influence. At the time, it wouldn't have been seen as a problematic choice, but it bothers me every time I have to reference it.

I don't think the thought experiment is so important that we have to use that name.

This would be one argument:

Phillip K. Dick, here understood as a narrative philosopher, wrote about the difference between xenoglossia and glossolalia, which comment on Searle, in regard to Ancient Greek specifically. [See VALIS trilogy.] Dick is a major narrative philosopher along with Asimov, Lem, and recently, Rajaniemi. Dick and Asimov have probably had more influence that Searle in the public understanding of AI. They use mythology of AI to explore social concepts in the manner of Plato.

This is sort of a https://en.wikipedia.org/wiki/Washington_Redskins_name_controversyWashington Redskins type of deal here—and that's my home team.
Searle is important, but I don't think he's foundational in the same way as Von Neumann, Turing, Shannon, Godel, Hilbert, etc.
I don't think Searle's intentions were bad, but I don't like this label in 2021.
b2A1I9n14a1r18y25_g7l12o15b2e5What would we need to do to relabel the "Chinese Room" on SE:AI?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Can you clarify why you think it (the name of the argument or the argument itself, I've not understood which one) "creates a bad perception of Asian people"? I am not Asian, so maybe I don't fully understand this. However, as I write in the comments below, I don't really see the connection between calling the argument "Chinese-Room argument" (and the argument itself, where the Chinese characters are used) and the creation of a "bad perception of Asian people". Why "bad"? It's not really saying anything "bad" about Chinese people. It's about the language and the understanding of it.


















Whether or not people like this name, this is how it has been known in the AI community for many years, so I don't think we should relabel it. It's called the Chinese-Room argument because it questions/involves the "understanding" of the Chinese language, which many people think to be very difficult, more difficult than, for example, German or Russian. (Of course, for Chinese people, it might be easier than other languages, but maybe not necessarily). So, in a sense, this is a good name for the philosophical argument because it is suggestive/descriptive.
I don't think it creates a negative perception of Asian people. I've never thought of that. Searle had to pick something that people would think that you really need "understanding" to deal with and you can't just manipulate symbols. The Chinese language was chosen probably because it may be difficult for many people.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I don't think it is the *difficulty* of the language that Searle was invoking, but complete lack of familiarity with the glyphs and grammar of the written form, for many readers. Hence all the conversation tasks are opaque to the operator in the room, and there seems to be no route to the machine "understanding" what it is doing - e.g. stats on the symbols or phrases cannot capture meaning in isolation.b2A1I9n14a1r18y25_g7l12o15b2e5@NeilSlater Ok, but the idea is that you don't or might not understand the language or something in general by just having the rules to manipulate it. Searle could have used any other language that is not English and that he doesn't know, but he had to pick something. I just don't understand why you think it's unfair for Chinese-speaking AI researchers or practitioners. People need to take the context into account (Searle was an English native speaker and the Chinese language was just an example; he could have picked Japanese, Arabic, Russian, or something else).b2A1I9n14a1r18y25_g7l12o15b2e5So, for me, it's unclear why it "creates a negative perception of Asian people". Why? If people told me that my native language is not understandable to them, that's perfectly fine. They didn't grow up listening to my native language and they didn't take the time to study it, so it's perfectly normal. I simply can't understand why the Chinese-Room argument, only because it has "Chinese" in the title/name would create a negative perception. I don't see the connection.b2A1I9n14a1r18y25_g7l12o15b2e5It would be like suggesting that we should rename "the vanishing gradient problem" to something else because it creates a negative perception of the gradient or gradient descent. Actually, this is a bad example. I should have come up with something else. My point is that I don't see the connection between the Chinese-Room argument and the fact that this is unfair to Chinese/Asian people or creates a negative perception of them. This doesn't make sense to me. Wise people will read the argument and take context into account.b2A1I9n14a1r18y25_g7l12o15b2e5I am neutral on the term being offensive, so cannot answer that. To me, I think it is unfair only in the mildest sense that it is slightly harder to understand as a metaphor when the language to be learned is not "other" (it involves a futher step removed in empathy with the person in the room). I am not suggesting we rename anything, but I am supportive of any suggestion that it could be renamed **if** there is a possibility of offense or exclusion. Any actual renaming would need to be guided and enacted by people who had reason to care about it.b2A1I9n14a1r18y25_g7l12o15b2e5I don't think I am in a position to judge whether any term in AI or IT should be renamed or not. I am not the potential beneficiary. So I believe my role here is to be supportive of those that have reason to care or worry about these things. The only thing I would be concerned about is well-intentioned changes made on *behalf* of any group, where there is no concern or complaints from a group. I understand that can be an issue too, which is why I recuse myself from anything like this and will happily use new names if they become accepted.


















The philosophical aspects of AI are related to the following arguments, issues, or questions.

Is it really possible to create an AGI?

Can a machine "think"?

(One of the first people who asked this question, although he correctly thought to be ambiguous, was Alan Turing, in his https://academic.oup.com/mind/article/LIX/236/433/986238influencial paper, which describes the Turing test)


Can a machine be conscious and/or self-aware?

This raises the obvious question: what is consciousness and/or self-awareness, and could these "things" be implemented/replicated in software?


Can a machine have free will?

If we created an AGI, should we give "rights" to it?

Are humans and other animals (or organisms) also computers? Do we just compute or do we have something that isn't "just" computation?

Is intelligence just symbol manipulation?

If we created an AGI and it had the ability to self-improve, could it become so intelligent (i.e. become a super-intelligence) that we humans wouldn't understand anymore its intentions?


Some of these issues are very related. If you want to find more about this, you could read the related chapter in Norvig & Russell's book.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I think this question will be good to migrate again to AI.SE the title is not related to a specific question with ai.meta asking about topics of this website is more related to the AI field than meta. and also is a good question for AI.SE I like the answers maybe is a good idea move to AI.SE for people see. what do you think?b2A1I9n14a1r18y25_g7l12o15b2e5@rubengavidia0x The question was asked in the context of our scope, i.e. it seemed to me that the OP wanted to understand about our scope, so that's why it was migrated to meta. However, I understand that it could have been left on the main the site, but it seemed to me to be too broad. It would be like asking "What are the theoretical aspects of the AI field (mentioned in description of our site)?". That would require us to give an overview of the field (which could lead to long answers, but not necessarily).


















Currently, our main site is in the public beta stage and the next stage is the graduation of our main site.
With this context, I want to know whether our main site is eligible in all aspects to get a graduation.
If our main site is eligible to get graduation in all aspects then who has to take the decision of graduating the site?
b2A1I9n14a1r18y25_g7l12o15b2e5Is our main site eligible for graduation and who has to take the decision of graduation?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I had already asked [a similar question](https://ai.meta.stackexchange.com/q/1551/2444) in the past. I looked at our statistics [here](https://area51.stackexchange.com/proposals/93481/artificial-intelligence), and they don't look perfect. In particular, I've noticed that the number of questions asked has decreased. I will talk to other more experienced moderators and ask them if they want to answer your question.b2A1I9n14a1r18y25_g7l12o15b2e5I updated the status because the Moderators have spoken to this in a separate post.  https://ai.meta.stackexchange.com/questions/2828/artificial-intelligence-is-graduating-becoming-full-non-beta-site. The site will lose the Beta label on December 16th.


















We're excited to announce that Intel will be sponsoring AI beginning November 11th through February 7, 2022. We wanted to give you a heads up and walk you through what it will look like.
How and where will the sponsorship be displayed?
The sponsorship will be shown in the top right header of the site in a manner that's similar to the mockup below:
https://i.stack.imgur.com/kcsIM.png
What else changes?
Nothing! Quoting from https://meta.stackexchange.com/questions/307861/site-sponsorships-bringing-resources-back-to-stack-exchangethe original MSE announcement on sponsorships:

First — sponsors do not own these Q&A sites. Sponsors work alongside our communities who ultimately build these sites. Communities ask the questions; communities create the tags; communities conduct elections as they do now, and we are not renaming our current sites like a garish sport stadium to the highest bidder. Any ads a sponsor submits still have go through our crazy-strict ad editorial process… as it has always been. Companies do not have access to personal data, and all Q&A content remains irrevocably licensed under Creative Commons for sharing and attribution.

Sponsorships are a tool that our clients can use to let folks who would be interested in their products know about them.
What if I think I've found a design glitch/bug?
If something looks off please report it as a https://ai.stackexchange.com/questions/tagged/bugbug. so we can investigate and squash it.
That's it. If you have any other questions or concerns please leave them as answers below.
Also, thank you. These types of partnerships help us bring more resources to our communities and they wouldn't be possible without the work you've put into making AI successful.
b2A1I9n14a1r18y25_g7l12o15b2e5Intel will soon be sponsoring AIb2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Hello Rosie. You write "_Sponsorships are a tool that our clients can use to let folks who would be interested in their products know about them._". So, it seems that this would be useful for the sponsor, in this case, Intel, given that, by having their logo (and link to their website) on our site, this would attract more people to their website. You also write "_These types of partnerships help us bring more resources to our communities_", but can you please provide more details? How exactly will this sponsorship help **Artificial Intelligence Stack Exchange**?b2A1I9n14a1r18y25_g7l12o15b2e5I know I already asked you this, but it would be nice to know the answer to this question. We had other sponsors in the past and I didn't notice any improvement e.g. in the number of visitors or the quality of questions or answers (due to these sponsorships), so I am wondering about the utility of these sponsorships for us.


















Since we learned that https://mattermodeling.meta.stackexchange.com/q/298/5Matter Modeling is graduating and https://quantumcomputing.meta.stackexchange.com/q/517/2293Quantum Computing is graduating and https://freelancing.meta.stackexchange.com/q/340/25010Freelancing is graduating, I'm curious if AI will be too?
b2A1I9n14a1r18y25_g7l12o15b2e5Will our Beta label be removed?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Is there any general post regarding this instead of meta posts on individual sites?b2A1I9n14a1r18y25_g7l12o15b2e5Apparently a post will be made on Meta.SE in December, but for now we're all just curious about which sites will be graduating!


















The question is your example is a bit vague/ambiguous because it's not clear what you mean by "perceive variables". So, that's the first problem with that question.
Having said that, generally, I think that questions in the context of understanding theoretical AI/ML concepts (which includes mathematical notation and terminology used in AI) should be on-topic here, provided they have an objective answer and don't lead to just opinions.
You already asked a question https://ai.stackexchange.com/q/23983/2444here that falls into the category you're describing. How do people in AI imagine higher dimensions or objects in higher-dimensional spaces? The reason why this question is on-topic here is that you're specifically interested in how "AI researchers" approach this problem (so you assume that AI researchers approach this problem differently than other researchers, which may or not be the case), but, generally, an answer to these questions may also be applicable to other cases.
So, here are my recommendations

Don't ask mathematical questions (like "what is a vector space?") and just put them in the context of machine learning as an excuse for making it on-topic here. If something is just purely mathematical, it may be a good idea to ask your question on Math Stack Exchange. It depends also on the type of answer you're looking for. Of course, on AI SE, you may find people with a different background than on Math SE, so you may get different types of answers here. If you think that something is done differently in AI or ML than in other fields, then you should ask your question here. For example, if you think that a "vector space" may have different connotations in AI/ML than in other fields (e.g. statistics) then you probably should clarify this in your post (e.g. I found that this article describes X as Y, but I thought X was Z in mathematics), so that people know why you're asking that question, which apparently is a question that should be asked on Math SE.

Try to formulate your questions so that they do not lead to opinions, but, preferably, for example, common practices/guidelines. If a question can lead to answers like "In my opinion, I think you should view higher dimensions as X", then your question might have been formulated incorrectly or could be closed as opinion-based.


b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Sure, I will follow all.


















We [= the AI.SE mods] are happy to share that we have been informed that our Artificial Intelligence site will be graduating, which means that it will lose its status as a "Beta" site and instead be recognised as a full site on the StackExchange network. It is currently expected that this will happen on December 16. At that time, the Community Management team of StackExchange will post more detailed information about exactly what this means, which sites are graduating, and why. We think it's very nice to see the value that the site adds be recognised and appreciated!
Most users' regular usage of the site will likely remain largely unaffected; all the existing questions, answers, and comments stay, all your reputation stays, there are no plans to change what is considered on- or off-topic, and so on.
Additionally, this change will involve a new Election for moderators on the site, which community members (assuming they meet certain requirements), including the current moderators, may nominate themselves for. There is no precise timeline for when this will be scheduled, but it may be a while still (since many different beta sites across the network are going to be graduating). More info on that will of course be on this Meta site when it happens!
Until we get more official info (expected on December 16 as mentioned above), you may already get an idea of more details around this from https://meta.stackexchange.com/questions/331708/congratulations-to-our-29-oldest-beta-sites-theyre-now-no-longer-betathis post from 2019 about a previous time when a larger batch of beta sites was selected for graduation. Note that, as in 2019, the plan is that the reputation thresholds required for various privileges will NOT (yet) change, even though usually (but not in this case) https://meta.stackexchange.com/a/160292/376651full sites have different reputation thresholds for certain privileges.

In general, one of the criteria for graduation is that at least 70% of the open questions should have at least one open answer. This is the only criterion that we do not yet satisfy. Due to the following reason, SE believes that an exception is warranted and we are ready to graduate anyway:

However, when we were looking at AI specifically we realized that your site has had the most Sponsorships of any MSE site and we felt that that deserved special recognition and consideration because the dedication to contributing quality content by your community has contributed so much to the success of MSE. If you would like to loose your Beta label we think you are ready for that.

b2A1I9n14a1r18y25_g7l12o15b2e5Artificial Intelligence is Graduating (Becoming Full, Non-Beta Site)b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5What's MSE? Also I think they meant "lose" not "loose".


















Thanks for the update!
Now I'm a bit confused because very recently, a diamond moderator at Medical Sciences Stack Exchange said that https://medicalsciences.meta.stackexchange.com/a/1313/16670one requirement was that at least 70% of the questions would have to be answered  for graduation out of Beta.
Likewise, a diamond moderator at Freelancing Stack Exchange quoted the https://freelancing.meta.stackexchange.com/q/340/25010specific reason why they will be graduating.
Since AI doesn't have 70% of the questions answered, could you help us understand better like they did at Medical Science and Freelancing?
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5My understanding is that the Community Managers are planning to explain which sites are graduating, and why, in their post planned for December 16. But I'll check if we can already elaborate on that here earlier.b2A1I9n14a1r18y25_g7l12o15b2e5Considering that dozens of sites are graduating, I doubt they'll be able to say why each specific site is graduating, especially the special cases like AI where one of the "requirements" was not even satisfied!b2A1I9n14a1r18y25_g7l12o15b2e5The CMs are planning to address this in their December 16 post, but we are also already allowed to share the specific considerations for our site; see my edit in the post above.


















There are several questions on our main site regarding the format of input needed for neural networks or other models.
When I search for tags, only the https://ai.stackexchange.com/questions/tagged/input-layerinput-layer tag is available. The description is

Input layer is the first layer of any neural network and contains the
input. Use this tag for asking questions related to this layer of the
neural network.

Input layer can be treated as a part of the neural network. Input is what we pass to the network. There can be questions on input itself rather than the model.
So, I am thinking that the new tag input is needed for us. What is your opinion on this?
b2A1I9n14a1r18y25_g7l12o15b2e5About the consensus regarding the `input` tagb2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5We already have the tag [tag:features] that should cover some of the cases that are related to inputs, but "feature" is more a synonym for "independent variable", while input would be like an observation/instance with can contain multiple features. The problem is that [tag:observation] may also refer to an observation in reinforcement learning, which may not be the same thing. Generally, I would avoid introducing tags that could be used for different purposes or inconsistently. When do you think people would use the tag "inputs"?b2A1I9n14a1r18y25_g7l12o15b2e5I mean, there are probably many cases, but I am just trying to understand if this tag could be used inconsistently or not.b2A1I9n14a1r18y25_g7l12o15b2e5[This](https://ai.stackexchange.com/questions/32721/what-are-the-types-of-inputs-used-for-rnn-in-literature-given-sentences) question can be an example to use input tag. @nbro


















Raising concern here as Flags and request for moderator intervention has failed. Requesting intervention of AI staff moderators.
Is it general norms that a diamond moderator https://ai.stackexchange.com/users/2444/nbronbro(https://ai.stackexchange.com/users/2444/nbrohttps://ai.stackexchange.com/users/2444/nbro)  can misuse his powers to delete another user's answer to gain reputation for himself?
It has come to my notice my answer was copied into this site by the diamond moderator https://ai.stackexchange.com/users/2444/nbronbro,
which was already addressed on Nov 25 (
https://ai.stackexchange.com/questions/32415/are-there-any-resources-that-introduce-the-basics-of-online-machine-learning/33920#33920Are there any resources that introduce the basics of online machine learning?)
If my answer wasn't plagiarised by diamond moderator nbro, the right thing to do NOT DELETE or keep seeking reasons to delete my posts and answers.
COPIED ANSWER SCREENSHOT
https://i.stack.imgur.com/OPvil.jpg
b2A1I9n14a1r18y25_g7l12o15b2e5My answer was deleted by a diamond moderator to gain votes and answer for himselfb2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5"It has come to my notice my answer was copied into this site by the diamond moderator nbro"

Which answer did he supposedly copy from which other answer by you? I looked at his answer, including all previous revisions of it, and they seem completely different from yours.


















Aside from being off-topic, the "locked due historical significance" seems rather dubious and definitely does not satisfy the https://ai.stackexchange.com/help/locked-postsreasons for locking a post in such a way listed here. As hanugm rightfully pointed out in a comment to that now-deleted question, we already have plenty of much older questions of a similar nature with much more activity on them. We're not losing anything major by deleting this, so the deletion is fine.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5When a question is off-topic, it's closed as such. When it cannot be made on-topic (e.g. by editing without invalidating current answers) and has no historical significance, then, sometimes, I happened to lock it as obsolete, before eventually deleting the post. In this case, I locked the post as "historically significant", but that was the wrong lock. I wanted to close it as "obsolete", to avoid interactions and because this type of post can really become obsolete easily, apart from being too broad and leading to opinion-based answers.


















https://ai.stackexchange.com/help/locked-postsHere's the reason.

An extremely popular question which is now considered inappropriate for the site may be locked for "Historical Significance": this alters the appearance of the question, automatically locks all answers as well, and disables flagging completely. This lock should be reserved for cases where a cherished cultural artifact would otherwise be deleted

If you want, I can delete the post. However, I thought that, given it's related to RL, it may have some significance for us (but not much, in my view).
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Thanks. Do you plan to lock or delete all off-topic questions?b2A1I9n14a1r18y25_g7l12o15b2e5Only posts that can still be "useful/interesting" for us (i.e. with respect to our current scope) will be locked and not deleted. Off-topic posts that have little value and that exist because our site was still in a "definition" phase may be deleted (without being locked first). Note that our site was in public beta for many years and **many** off-topic (and poor) questions were asked. So, there was the need to clean up a lot of these off-topic posts.


















Please consider https://ai.stackexchange.com/questions/30012/do-researchers-generally-treat-tensors-just-as-mathematical-objects-with-certainthis question for better understanding the question as this doubt originated while going through the question.
The core part of the question is How do researchers generally treat tensors?
For this question, I think, it is better if I modify a certain portion of the answer as follows

I would say they are treated as multidimensional arrays of
numbers. They are not visualized in their actual dimension.
Sometimes small ones will be visualized when someone is trying to
explain a concept that requires it.

I just boldified the relevant part of the answer that needs attention.
Is such activity recommended without the knowledge of the actual poster?
b2A1I9n14a1r18y25_g7l12o15b2e5Is it okay to boldify(higlight) the portion of answer that is deserved to be, without posters permission?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Regarding "without the knowledge of the actual poster", original posters are notified on the site when someone edits one of their questions or answers. That doesn't answer whether or not this kind of edit is a good idea.


















Closing a question is (usually) not a unilateral decision; it is usually only closed when multiple people have voted for it to be closed. An exception is that moderators can directly close, but that is not what happened here; three different people voted to close.
It is of course possible that they each of slightly different reasons for voting to close / different details they think are missing. I can't speak for them. I have taken a look though and can explain what I would recommend taking a look at to improve the clarity:
The title is not descriptive, it does not summarise the core of the question: "Training an agent to choose a string from a list of strings".
That title somewhat sets the context of the question (it's about training an agent in an environment where it needs to choose strings from some list of candidates apparently), but not the core of the question. To me, the core of the question seems to be that you're curious about how the actions should be represented; should you represent them simply by giving every possible word in the vocabulary a unique index, or should you actually use a multi-dimensional representation where you represent actions as the arrays of characters / strings.
Furthermore, directly just mentioning the name of the game you're interested in (Wordle) is probably more descriptive than the somewhat vague description of the task as "to choose a string from a list of strings". Lots of other tasks could be described like that too. So, I think I would recommend a title more like:

How to encode actions for training a Wordle agent?


Apart from that, I think the main body of the question itself right now is reasonably clear. It is possible that some of the people who voted to close actually already did before you edited, or maybe they still see things they find unclear.
One thing that could maybe help would be to more explicitly state whether you really really want to use a Reinforcement Learning solution (for instance, because you want to learn more about that specific field), or whether you're just looking for any AI solution in general. Otherwise, you get comments like Neil's first comment, for example, when people may believe that RL may not necessarily be the best/easiest solution, but are not sure whether or not that's important for your question.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Thanks for the feedback. I edited my original question accordingly.


















Since one of our previous (and most active) moderators is no longer moderating for our site, we currently have a lack of active moderators and are considering to hold a new election relatively soon.
To avoid finding ourselves in a situation where an election would fail due to an insufficient number of candidates, though, I'm posting this to try to assess the community members' willingness to step up and nominate themselves, when the actual election's nomination period starts.
Please leave an answer if you'd be willing to run for a moderator position, should we decide to run an election.
Note: This is not an official election nomination thread, just a "pulse check" to get a notion of how many people here would be willing to step up.
Currently, February 28th is the tentative date for such an election, starting with nominations, but only if we can get enough people willing to run for moderator positions.
b2A1I9n14a1r18y25_g7l12o15b2e52022 Potential Moderator Election: Community Interest Checkb2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e528 February is way too early. It is 15 February right now. What do you think? Also, has there been any announcement about what happened (or at least when it happened) to the other moderator? When I [search "nbro" on Meta](https://ai.meta.stackexchange.com/search?tab=newest&q=nbro) and sort from newest to oldest, the last thing I see is complaints about a question being deleted by nbro towards the end of December 2021.b2A1I9n14a1r18y25_g7l12o15b2e5@NikeDattani That date was suggested to me by the Community team. As far as nbro is concerned, nothing happened, he just decided he no longer wants to continue moderating.


















In my opinion, in principle, yes that could be on-topic. However, I would try to keep the following things in mind:

The "whether" version of the question would likely not be great, if the expectation is that it's just going to receive a "yes" or a "no" as answer without any elaboration. That's not the type of question that we would want on the StackExchange network in general. So it'd have to lean more towards "how could we apply AI for this?", or even "what would we have to be careful of / what could go wrong if we tried to apply AI for this?".

Make sure that the question is actually about the AI perspective. From your example, if the question is just about whether or not there would exist a connection at all between the grammatical structure of a sentence and its "rudeness", that would probably more so be a question about linguistics (or even culture more broadly), rather than AI. But if we assume that such patterns do indeed exist, a question about how AI could (reliably) pick up on that (or any other form of structure/patterns in text) would be more likely to be on-topic.

Make sure that the question is not overly broad. Especially for people who are not already experts at AI, I think it can be very difficult to not make it either overly broad, or too "small". Like I mentioned in (1), the "whether" question with just a yes/no answer would not be interesting. But a pure "how can AI be used for this problem?" question would be too broad. Valid answers to that could be getting into essentially all AI techniques that have been developed for all kinds of Natural Language Processing tasks over the past several decades, but they could also get into huge practical answers about the required data collection, or they could more into the required software engineering to put the idea into practice... several different directions, and all very broad. We prefer specific, precise questions that can be answered in specific and targeted ways.


b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5This is very helpful because I thought "whether" was more open-ended to Answers going in any direction, but actually "whether" easily implies that answers ought be binary. That distinction really helped!


















I started with AI at SO, and too with Quora, but both places seem to not really be used by people working in these areas. I am judging by traffic. Are there other places where people meet and discuss their stuff?
b2A1I9n14a1r18y25_g7l12o15b2e5What is the best place to ask questions about deep learning, reinforcement learning, neural networks?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5If you are looking for the best place to "discuss stuff", then Stack Exchange is probably not for you, it is for Q&A content only (unless you count the chat rooms). If you want the best Stack Exchange site for your purpose, then you should ask on Meta Stack Exchange, and you should give more details of the kinds of question you want to ask. Any of Cross Validated, Data Science, AI, Robotics, Signal Processing might be appropriate depending on your focus.


















We have three very related tags

https://ai.stackexchange.com/questions/tagged/neural-networksneural-networks
https://ai.stackexchange.com/questions/tagged/deep-neural-networksdeep-neural-networks
https://ai.stackexchange.com/questions/tagged/deep-learningdeep-learning

The second could be merged with the first because it's partially redundant, and

the definition of a a deep neural network is a bit fuzzy
we can use the first and third tags when talking about deep neural networks (whatever that really means)
people may use the three tags when only 2 of them are probably necessary

However, it's also true that having all three tags is not a big problem. People may use the second tag without using the other 2 just because they want to know specifically about the architecture of a deep neural network without caring about learning. We also have examples of other tags that are very specific (e.g. https://ai.stackexchange.com/questions/tagged/deterministic-policydeterministic-policy), which some people could argue are not really necessary (and https://ai.stackexchange.com/questions/tagged/policiespolicies would be sufficient maybe in combination with the a tag that doesn't yet exist https://ai.stackexchange.com/questions/tagged/determinismdeterminism). In the past, we also had the tag https://ai.stackexchange.com/questions/tagged/strong-aistrong-ai, which was merged with https://ai.stackexchange.com/questions/tagged/agiagi, as they are often synonyms.
In conclusion, I think I am in favour of the merge because deep neural networks are neural networks but with "more layers" (which is vague), but, apart from that, they don't have anything special. What is really more special is "deep learning", i.e. learning techniques for neural networks that have "many layers".
b2A1I9n14a1r18y25_g7l12o15b2e5Should we merge the tags neural-networks and deep-neural-networks?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5I guess it would make much more sense to consider merging [tag:deep-neural-networks] with [tag:deep-learning] (they are practically synonyms), rather than with the more generic tag [tag:neural-networks].b2A1I9n14a1r18y25_g7l12o15b2e5@desertnaut My main thesis is: "deep neural networks" are not well defined. They are neural networks that are deep, but what "deep" means is not well-defined. DL, on the other hand, is concerned with learning in NNs where problems like the "vanishing gradient" occur, so the DL term actually refers to some specific problems and algorithms. The reason why I suggested to merge with NNs is because DNNs are NNs, they are not deep learning. Deep Learning is about learning, i.e. algorithms like gradient descent. However, it doesn't really matter with which tag we merge DNNs - both are fine, IMHO.


















I think it is okay to keep intact as there is a fundamental difference between them both in the technical and historical arena.
It is true that deep neural networks form at most a subset of neural networks but have a uniqueness in terms of representation as mentioned in https://proceedings.mlr.press/v28/bengio13.htmlthis quote

It has been hypothesized, and supported with experimental evidence,
that deeper representations, when well trained, tend to do a better
job at disentangling the underlying factors of variation.

Although your proposal is considerable, most people are habituated to using neural networks for generic architectures as well as for those with fewer layers and deep neural networks for more focused architectures. So, I believe that it will be useful to keep them intact as it attracts more questions from deep neural networks with few tags attached.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5It seems that deeper networks can learn certain representations better, but a single hidden layer neural network is, in theory, as powerful as a deep one. So, I am not sure if there's a "fundamental difference". Anyway, my concern is that the definition of "deep neural network" is unclear, as far as I know - there's no solid science that tells that certain NNs are deep while others aren't. This can lead to a misuse of the tag [tag:deep-neural-networks] - this is one reason why I am in favour of the merge.b2A1I9n14a1r18y25_g7l12o15b2e5For example, I think it makes more sense to have the tag [tag:deterministic-policy] because its definition is quite widely accepted in RL (the only concern is whether we would have enough questions about this topic or not to have a dedicated tag for it). So, there isn't much room for ambiguity and misuse of this tag. Having said that, [tag:deep-neural-networks] wouldn't be misused so badly - people would still talk about neural networks. That's why I think it wouldn't be a big problem to also keep this tag.b2A1I9n14a1r18y25_g7l12o15b2e5These example questions highlight the need for different tags: "[Need help in debugging **Shallow** Neural network using numpy](https://stackoverflow.com/q/62576811/3648282)", "[Training speed on a **shallow** neural network with a small dataset](https://stackoverflow.com/q/53290220/3648282)", "[A Logistic Regression with Neural Network mindset VS a **shallow** Neural Network](https://stats.stackexchange.com/q/366707/197829)", "[Does Deep network (e.g. # of hidden layer=2) always better than **shallow** network (i.e. # of hidden layer=1)?](https://stats.stackexchange.com/q/120840/197829)",etc.b2A1I9n14a1r18y25_g7l12o15b2e5@Rob Those questions were not asked on AISE. Anyway, I know that there are some questions where this tag would be somehow appropriate. My main point is that the term "deep neural network" is not well-defined.b2A1I9n14a1r18y25_g7l12o15b2e5@nbro, the prior comment was written to support hanugm's answer, but I welcome your input. The first, second, and shallow -n-n, are three separate tags, as explained in this link list: https://proofassistants.meta.stackexchange.com/questions/192/how-to-write-a-tag-wiki-excerpt#comment430_192 to the FAQ, and related examples. If it's unclear if it's shallow, deep, or even long the catch-all first tag is available - that's why there's umbrella tags in addition to more specific ones.b2A1I9n14a1r18y25_g7l12o15b2e5@nbro, if examples from this site are preferable we can search here for: [shallow+neural+networks](https://ai.stackexchange.com/search?q=shallow+neural+networks); it shows how people have tagged, sometimes with deep-* and often with the umbrella tag [tag:neural-networks] ([tag:shallow-neural-networks] being missing) - probably time better spent checking the tagging, before or instead of [burnifying](https://meta.stackexchange.com/tags/burninate-request/info).b2A1I9n14a1r18y25_g7l12o15b2e5@Rob Can you define what a deep and shallow neural network is? People will answer by saying a DNN is a neural network with many layers, say, more than 10 or 20. Ok, I say that this is not a standard definition, AFAIK. Why don't we choose to define DNNs as NNs with more than 3 layers? AFAIK, there isn't a standard "scientific" definition of what DNNs, although people talk about "them", without knowing what they are really referring to exactly. It's like talking about "intelligence". Everyone talks about it, but often people are not talking about same thing or are masking different assumptions.b2A1I9n14a1r18y25_g7l12o15b2e5Again, I am not saying that it's completely a mistake to have the tag DNN. It's not a big problem. Maybe the problem is to well define what a DNN is or for the AI community to agree upon a single definition, and then retag questions currently tagged with DNN appropriately, if they are not. What I think is a mistake is to have a tag which can be misused. Tags should be used for specific purposes. So, when people need to search for questions, they can narrow the list of questions down using the tags.b2A1I9n14a1r18y25_g7l12o15b2e5In response to [this comment](https://ai.meta.stackexchange.com/questions/2871/should-we-merge-the-tags-neural-networks-and-deep-neural-networks/2872?noredirect=1#comment3521_2872), A simpler explanation of shallow is here: https://towardsdatascience.com/shallow-neural-networks-23594aa97a5 - shallow is easier to understand, good for learning or in instances where it is suitable (quick implementation / local memory) but deep is better for overall speed:  https://qr.ae/pvCYoP but too deep isn't *better* https://qr.ae/pvCYPk - more than a few layers is deep (IMO, and somewhat agreed upon).b2A1I9n14a1r18y25_g7l12o15b2e5In response to "... What I think is a mistake is to have a tag which can be misused. Tags should be used for specific purposes.". All tags can be *misused*, what's important is a clear excerpt and for users with edit privilege (even suggested edits) to spruce and prune the tags proposed by the asker; who might be in need of help, both with the question itself but also the use of tags here.


















Often in elections, there's a questionnaire compiled by the community full of similar questions to the ones you've posted that candidates are encouraged to answer. Since this is technically a pro-tem election, that didn't happen this time.
During the "nomination" phase of the election, you can leave comments on the nominations. Once voting has opened, that's no longer an option, unfortunately.
I personally can be found in https://chat.stackexchange.com/rooms/43371/the-singularityThe Singularity, which is the main chat room for Artificial Intelligence Stack Exchange, and am willing to answer questions posed there.

As for how many moderators are being elected, on the top right of the /election page it says this:

candidates 6 | positions 1

There are six candidates running; one will be selected to be added to the moderator team.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Also, since I'm already a diamond moderator on different sites, I can superping any of the candidates in the chat room to give them a notification. if you'd like to pose questions to one of the other candidates, I might be able to summon them into that chat room.b2A1I9n14a1r18y25_g7l12o15b2e5Now that I see there is only one open position, I don't feel a need to contact any of the candidates. Thank you for your offer of help!b2A1I9n14a1r18y25_g7l12o15b2e5I would like to ask Rob how he plans to become familiar with the scope of this site if he is elected.  That is, what he already knows about what is [on](https://ai.stackexchange.com/help/on-topic) and off topic and how committed he is to adjusting to the community's norms where he might disagree.b2A1I9n14a1r18y25_g7l12o15b2e5@JosiahYoder - Rob actually has me blocked on chat, I believe, so I'm not sure I'll be able to summon them, unfortunately.b2A1I9n14a1r18y25_g7l12o15b2e5That is unfortunate.b2A1I9n14a1r18y25_g7l12o15b2e5Has Rob requested neutral pronouns? I've seen a couple of folks using them.


















During the nomination phase, you could interact with the candidates. Unfortunately, I was the only one to do so, i.e. I was the only one to ask clarification questions, and I asked clarification questions to all of them (but Mithical, which I interacted with in our chat room and I knew them a little bit since I was once a mod too). So, it seems that almost nobody is interested in selecting the right person for this mod role...
I wish people could still see the comments, but, anyway, 2 people didn't really address my concerns at all (most of them are about their activity and contributions to the site, which were lacking or poor). I will write here their names because I think it's important for the community to choose the best candidate: quintumnia and Simbarashe Timothy Motsi. The other candidates tried, to some extent, to address my concerns, but I was not fully satisfied with their answers...
Personally, I think most nominations/candidates are not suitable for the role because, actually, all of them have been inactive for many years or never contributed to the site at all in any way, and only became active to nominate themselves (can you believe this? your judgement here!!!) and only some of them have showed to have some knowledge of AI and only 1-2 know how SE really works and seem to have an idea of what it means to be a mod.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Since there is only one open position, this is less of a concern.  It's deciding between those 1-2 who know how SE works that I'm thinking through....

I think it's OK to un-name the two candidates you name as I feel they are unlikely to be elected anyway.b2A1I9n14a1r18y25_g7l12o15b2e5@JosiahYoder I think that's a mistake. Selecting a mod only based on their knowledge of SE and how it works is a mistake. Mods on specific sites, especially one like ours (which falls under the "science" category), should have some knowledge of AI to be elected. I discussed this with Mithical on the chat. You can go there and read, if you want. But I will let the community decide what they think is the best!b2A1I9n14a1r18y25_g7l12o15b2e5What chat? I've got 2k on SO proper, but still feel like a newcomer to the whole network!b2A1I9n14a1r18y25_g7l12o15b2e5@JosiahYoder You're already there: [The Singularity](https://chat.stackexchange.com/rooms/43371/the-singularity) ;)b2A1I9n14a1r18y25_g7l12o15b2e5I think none of the candidates have enough experience on this site to become a diamond moderator. I would like to vote for Ron (Re-open nominations). I didn't get the notification that an election was going on for some reason. Maybe SE didn't want me to participate.


















Sounds good, I just suggested (and approved) them. Non-mods should still be able to suggest and vote on suggestions for synonyms by the way! But I guess only mods can circumvent the votes and just approve them right away, which does make things faster..
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Suggesting synonyms and voting also requires a certain score in answers in that tag, which not a lot of people will meet.


















Thank you all for putting your trust in me as a moderator! I look forward to helping with the upkeep of the site with my fancy new powers and making sure the site stays healthy alongside the existing team. :)
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Great to have you join and help out! :)


















I'm sorry you feel that way. Instructions for how to delete your account may be found https://ai.stackexchange.com/help/deleting-accounton this page of the Help Center.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Thanks, I'll follow those instructions. Instead of being sorry I feel this way, you should consider doing something about the site policies or at least make moderators substantiate why they tag a question as being too stupid or too lame or too much of a waste of bytes.b2A1I9n14a1r18y25_g7l12o15b2e5@frodeborli I assume you are referring to [this post](https://ai.stackexchange.com/q/36443/1641). Note that no moderators were actually involved in closing (or deleting) that particular post. It was voted to be closed by three non-moderator members of the community, with as reason "This post is about specific software, hardware, datasets, or pre-trained models." I looked at the question, and it indeed looks like it's essentially asking for recommendations for tools/software, which is [not on topic on our site](https://ai.stackexchange.com/tour).b2A1I9n14a1r18y25_g7l12o15b2e5Well, the question is not about specific software. It is not asking for recommendations, and it is not asking for pre-trained models. It is asking for the *existence* of tools to experiment with AI which is in fact **not specifically** made for any particular programming environment. 

I strongly disagree with this site's policy of maintaining a barrier to keep out newcomers by deeming their question as *too uneducated*. The chosen network name 'AI' is MUCH TOO broad, since the site policy seems restricted to an extremely narrow academic part of the field of AI. @dennis-soemersb2A1I9n14a1r18y25_g7l12o15b2e5@frodeborli It's not at all a matter of such questions being considered "too uneducated" or "stupid" or "lame" or anything like that. They're simply deemed to be beyond/outside the scope of this site. More appropriate sites may include e.g. https://stackoverflow.com/ or https://softwarerecs.stackexchange.com/. If you like it's also possible to debate what should or should not be on topic in a new meta post right here (not in extended comments), dedicated to that topic, but then please search and check out previous posts on that topic throughout the past years first.


















I am trying to solve Kropki Sudoko using CNF formulas.
Here are the formulas that I have created till now



For each pre-assigned entry on the board in the initial board, a unit clause is defined as:
$S_{xyz}$

There is at least one number in each entry :-
$$
 \bigwedge_{x=1}^{9} \bigwedge_{y=1}^{9} \bigvee_{z=1}^{9} S_{xyz}
 $$





Each number appears only once in a given row :-
$$
  \bigwedge_{z=1}^{9} \bigwedge_{x=1}^{9} \bigwedge_{y=1}^{8} \bigwedge_{i=y+1}^{9} (\neg S_{xyz} \vee \neg S_{xiz})
  $$

Each number appears only once in a given column:-
$$
  \bigwedge_{z=1}^{9} \bigwedge_{y=1}^{9} \bigwedge_{x=1}^{8} \bigwedge_{i=x+1}^{9} (\neg S_{xyz} \vee \neg S_{iyz})
  $$

Each number appears only once in each sub-grid :-
$$
  \bigwedge_{z=1}^{9} \bigwedge_{i=0}^{2} \bigwedge_{j=0}^{2} \bigwedge_{x=1}^{2} \bigwedge_{y=1}^{3} \bigwedge_{k=x+1}^{9} \bigwedge_{l=1,y\neq l}^{9} (\neg S_{(3i+x)(3j+y)z} \vee \neg S_{(3i+k)(3j+l)z})
  $$


Now I am having trouble representing black dots (which means adjacent squares should be double of each other) and white dots (which means adjacent squares should be consecutive) in CNF formulas like above
b2A1I9n14a1r18y25_g7l12o15b2e5Krpoki Sudoko Translation in CNFb2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5MathJax help: https://or.meta.stackexchange.com/a/372/51  or Unicode: 

• \• ◦ \◦


















Update Jan 26, 2023: Due to technical changes in the election system that are still being worked on from Stack Exchange's side, it looks like the start of the election will be slightly delayed. I don't have an exact date yet, but we'll keep you posted when have more info.

As a heads up, we're going to be holding a diamond moderator election here on Artificial Intelligence Stack Exchange, starting at some point in January 2023. I wanted to take this opportunity to explain what will be happening and how you can participate.
What do diamond moderators do?
Broadly speaking, moderators handle things out of the ordinary. These include processing flags, issuing suspensions, acting as a point of contact between staff and the community, investigating vote fraud, and managing disputes, among other things. You can read more at https://stackoverflow.blog/2009/05/18/a-theory-of-moderation/A Theory of Moderation on the Stack Overflow Blog for a general overview.
What do we expect of moderators?
In terms of time commitment, not a ton. Here on AI.SE, the moderation workload isn't huge. A few minutes a day is quite enough time to dedicate to moderator activities, for the most part. In terms of temperament, we're generally looking for people who can communicate well, keep their cool, and evaluate things from an objective standpoint. Having a decent grasp of the subject matter is a definite plus, as well as having previously shown involvement in the moderation and upkeep of the site (such as helping with the review queues and flagging).
How do I participate in the election?
There are two main ways you can participate in the election: by nominating yourself, and by voting.
During the nomination period of the election, which lasts two weeks, any user with 300+ reputation and in good standing (i.e. has not been suspended in the past year) can nominate themselves. You'll have to write a nomination post on the election (https://ai.stackexchange.com/election/3https://ai.stackexchange.com/election/3) explaining why you think you'd be a good moderator and why people should vote for you. People can leave comments on your nomination with concerns or questions for you.
After the nomination phase, if there are more than 10 candidates, there will be a primary in which people will vote up or down on candidates. The top 10 candidates after the primary - or all of them, if there is no primary - then move to the election phase.
During the election phase, any user with 150+ reputation can vote in the election. You order any candidates you want to vote for in order of preference. (If your top choice for candidate is eliminated, your vote is trasferred to the next candidate in your order of preference.)
When the election is over, the top candidate is elected as moderator and will be granted a diamond.
Remember, this post isn't a nomination thread - save your nomination for the election itself! This is meant as a heads-up that the election is happening, and to make sure that everyone's up to speed on how an election works. Discussion about the election and general chat can happen in https://chat.stackexchange.com/rooms/43371/the-singularityThe Singularity, the main chatroom for AI.SE. Feel free to ask any questions about moderation or the election process - someone should be able to answer them. This includes any questions you might have for the current moderator team - we'll be hanging around and can answer questions.
Good luck to anyone planning on running!
b2A1I9n14a1r18y25_g7l12o15b2e5Upcoming moderator election in January 2023b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Its importent to note that not being suspended in the past year is on any stack exchange site and not only AI SEb2A1I9n14a1r18y25_g7l12o15b2e5At what point should the link (https://ai.stackexchange.com/election/3) start working?b2A1I9n14a1r18y25_g7l12o15b2e5There should be an update within the next couple days, @Robin


















Recently, there's been an influx of posts that have been entirely AI-generated in response to a question, particularly using the ChatGPT bot.
There have recently been some big advances in the capabilities of various AIs to generate content, including art and answers to questions. This is naturally exciting to us as AI enthusiasts. However, with these advances, there have been some negative side effects. One of those is writing AI-generated answers.
AI-generated answers, especially with the ChatGPT bot, can look very convincing at first glance. They're generally well-written, well-formatted, and sound like they know what they're talking about. They're convincing. However, upon closer inspection by a subject matter expert, it is often evident that the answer is blatantly incorrect and thus misleading. These "answers" are also extremely quick to generate; it takes a matter of seconds to copy-paste a question, recieve an answer from the bot, and copy-paste that into the answer field. (There have been https://meta.stackoverflow.com/q/421831/4946380thousands posted and deleted on Stack Overflow.)
The aim of Artifical Intelligence Stack Exchange is to provide a repository of high-quality questions and answers about the subject of artifical intelligence. Having misleading, mass-generated answers that sound high-quality but are actually incorrect runs counter to that goal. We are a site about Artificial Intelligence, not a site run by artificial intelligence; let's try to keep it that way.
b2A1I9n14a1r18y25_g7l12o15b2e5Please do not post AI-generated content as actual postsb2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5How about just banning people posting misleading/incorrect answers, regardless of who/what wrote it?b2A1I9n14a1r18y25_g7l12o15b2e5@FranckDernoncourt - If someone consistently writes low-quality posts, and show no signs of improvement, a suspension eventually will be issued. That is, however, a different problem than using a tool to automatically generate answers without even attempting to create quality content. One is simply poor contributions, the other is abuse of the site.b2A1I9n14a1r18y25_g7l12o15b2e5I don't think we can ever reliably prevent AI generated answers, but what we **can** do, is trying to ensure that the answers provided also cite or are made by a reliable source. It's of course very easy to just ban someone, but that is not improving the platform, and make it more reactive than pro-active. In this day and age with a majority of non-technical people asking and wanting to answer, this would become a problem, and a rather negative such. E.g. even some of the creators of MML's doesn't know exactly how it works, and it's behaviors. I think we need to be a bit more flexible here.


















I noticed a very large number of questions seem to think they are asking a question to an AI, not understanding that this is a human Q and A about the topic of AI. Especially after chatGPT being released, this has seen an uptick. I saw 3 such questions today, and many more this past week.
What can we do to make new users realize that they are not asking a question to an AI?
For example see this post:
https://ai.stackexchange.com/questions/38316/can-you-give-me-a-video-game-ideacan you give me a video game idea
I tried to link more to examples but the posts have since been deleted by moderators. Other questions I saw asked for stock predictions, world cup predictions, writing an essay, etc.
b2A1I9n14a1r18y25_g7l12o15b2e5Attracting fewer spam postsb2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5It's worth noting that this has been happening long before ChatGPT came around. We've been deleting these on sight for quite a while. I did some digging one day and couldn't find any connection between the various posts, but could be I missed something.b2A1I9n14a1r18y25_g7l12o15b2e5Yup I've noticed it for a while too. I just think it'd gotten worse the past week. I've been closing a lot of them too.


















Artificial Intelligence Stack Exchange comes https://ai.meta.stackexchange.com/a/1144/145from the "Science" category of Area 51. The site as a whole is designed for questions from a scientific, theoretical, social, historical, and ethical point of view; implementation and technical questions were not part of that.
As the scope has evolved over the years, we've allowed more questions about the technical aspects of different AI and ML systems, but general consensus, as far as I understand, has remained that debugging and technical support questions are off-topic.
The well-received questions about ChatGPT that you've linked are about the scientific background of the AI. Questions about how the backend works are coming from a scientific "how does this work". Questions about using the interface are coming from a technical "how do I use this". "how does this work" questions are generally on-topic; "how do I use this" are typically not.

I migrated the question to Web Applications after browsing your https://webapps.stackexchange.com/help/on-topicon-topic page. I saw that "...any other website which behaves like an application" was on-topic, and troubleshooting / errors didn't appear in the list of off-topic subjects. I'd recommend updating that page if such questions are indeed off-topic.
The question has attracted about 50k views in its time being bounced across sites, so it's obviously a question that people are searching for. It's just unfortunate that there doesn't seem to be a SE site that it fits on.
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5When in doubt to which site to migrate, it might be good idea just to close the post, at least temporarily until one finds the right site to migrate to, and maybe by locking it to prevent more interactions (e.g. if it has historical significance). The most we can do is just comment that the question/problem is off-topic and tell the user that it might be on-topic somewhere else.



















As we say goodbye to the old year and welcome the new one, we have https://ai.meta.stackexchange.com/search?q=%22year+in+moderation%22+is%3Aquestiona tradition of sharing moderation stats for the preceding calendar year.
As most of you here are aware, sites on the Stack Exchange network are moderated somewhat differently to other sites on the web:

We designed the Stack Exchange network engine to be mostly self-regulating, in that we amortize the overall moderation cost of the system across thousands of teeny-tiny slices of effort contributed by regular, everyday users.
-- http://blog.stackoverflow.com/2009/05/a-theory-of-moderation/A Theory of Moderation

That doesn't eliminate the need for having https://stackoverflow.blog/2018/11/21/our-theory-of-moderation-re-visited/moderators altogether, but it does mean that the bulk of moderation work is carried out by regular folks. Every bit of time and effort y'all contribute to the site gives you access to more privileges you can use to help in this effort, all of which produce a cumulative effect that makes a big difference.
So as we say goodbye to 2022 (and where did January go, right?) and dive head first into 2023, let us look back at what we accomplished as a community... by looking at some https://i.stack.imgur.com/V0TPg.gifexciting stats. Below is a breakdown of moderation actions performed on Artificial Intelligence over the past 12 months:




Action
Moderators
Community¹




All comments on a post moved to chat
5
0


Answer flags handled
166
15


Answers flagged
2
179


Comment flags handled
95
22


Comments deleted⁷
428
605


Comments flagged
0
117


Comments undeleted
9
0


Escalations to the Community Manager team
5
0


Posts bumped
0
1,827


Posts deleted⁶
396
1,577


Posts locked
4
24


Posts undeleted
30
59


Posts unlocked
1
3


Question flags handled⁵
213
175


Questions closed
185
620


Questions flagged⁵
10
387


Questions migrated
5
3


Questions protected
1
3


Questions reopened
8
3


Tag synonyms created
13
0


Tag synonyms proposed
13
0


Tags merged
7
0


Tasks reviewed⁴: "Close votes" queue
9
1,239


Tasks reviewed⁴: "First answers" queue
0
429


Tasks reviewed⁴: "First questions" queue
0
1,738


Tasks reviewed⁴: "Late answers" queue
0
139


Tasks reviewed⁴: "Low quality posts" queue
6
53


Tasks reviewed⁴: "Reopen votes" queue
5
42


Tasks reviewed⁴: "Suggested edits" queue
79
374


User banned from review
1
0


User suspensions lifted early
2
0


Users contacted
20
0


Users deleted
1
0


Users destroyed³
1,268
0


Users suspended²
11
27



Footnotes
¹ "Community" here refers both to https://ai.stackexchange.com/usersthe membership of Artificial Intelligence without https://ai.stackexchange.com/users?tab=moderatorsdiamonds next to their names, and to the automated systems otherwise known as https://ai.stackexchange.com/users/-1user #-1.
² The system will suspend users under three circumstances: when a user is recreated after being previously suspended, when a user is recreated after being destroyed for spam or abuse, and when a network-wide suspension is in effect on an account.
³ A "destroyed" user is deleted along with all that they had posted: questions, answers, comments. https://meta.stackexchange.com/questions/88994/what-is-the-difference-between-a-deleted-user-and-a-destroyed-userGenerally used as an expedient way of getting rid of spam.
⁴ This counts every review that was submitted (not skipped) - so the 2 suggested edits reviews needed to approve an edit would count as 2, the goal being to indicate the frequency of moderation actions. This also applies to flags, etc.
⁵ Includes close flags (but not close or reopen votes). Community can handle these flags by at least one person voting to close a question that has a close flag.
⁶ This ignores numerous deletions that happen automatically in response to some other action.
⁷ This includes comments deleted by their own authors (which also account for some number of handled comment flags).
Further reading:

Wanna see how these numbers have changed over time? We posted a similar report here last year: https://ai.meta.stackexchange.com/questions/2853/2021-a-year-in-moderation2021: a year in moderation

You can also check out https://stackexchange.com/search?q=title%3A%222022%3A+a+year+in+moderation%22this report on other sites

Or peruse https://meta.stackexchange.com/q/386090/208518detailed information on the number of questions closed and reopened across all sites


Wishing everyone a happy 2023! ^_^
b2A1I9n14a1r18y25_g7l12o15b2e52022: a year in moderationb2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Thanks for sharing this. I already said this in the past, but I'll suggest it again. It would have been a lot better to have a tool that allows us to automatically compare these numbers and see how they evolve over time. I'm sure this would not be so difficult to implement. If this data could be fetched with an API, at least, people could create some API to do that. Is there a way to fetch these numbers with an API? What's prevent you from providing such API or comparison tool?b2A1I9n14a1r18y25_g7l12o15b2e5You can use [SEDE](https://data.stackexchange.com/) to get this data, approximately. I'm not sure if you'll be able to get the exact same data out of it, and some bits (like CM escalations, for instance) will definitely be missing. We currently don't have any plans of making this data retrievable on demand, though, as much as I would like to see this available on a dashboard, for instance.


















MathOverflow has a nice https://mathoverflow.net/questions/439652/perceptron-logistic-regression-accuracy-on-the-n-bit-parity-problemquestion about the n-bit XOR accuracy of a linear perceptron. Should it be imported somehow to AI.SE or otherwise linked?
b2A1I9n14a1r18y25_g7l12o15b2e5How to link to an AI question on MathOverflow?b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5The question could be migrated to our site, but I think it's also fine to leave it there, because it's asking for a proof. In general, I would encourage any theoretical AI question to be asked on our site, but, unfortunately, many people still don't use our site to ask questions like the one you're mentioning. I'd love to see more of those questions on our site.


















Sure, creating a new tag like that sounds good to me. Short answer, but don't really have anything else to say... if you'd like to, please go ahead :)
b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5b2A1I9n14a1r18y25_g7l12o15b2e5Thanks @Dennis Soemers. Should I go through the 16 questions with the [batch-learning] tag and retag the ~8 or so to [offline-reinfo